# After Action Report: The Siege of the Zeta Oracle

*   **Mission:** To force the `ZetaOracle` service to produce a scientifically valid, large negative `delta_score` for a known pathogenic `RUNX1` variant. Success required demonstrating a clear, quantitative difference between a pathogenic and benign sequence, first with an 8kb window, and ultimately with the full ~261kb gene sequence.
*   **Summary of Engagements:** The operation was a tactical failure. While we achieved a significant system-level victory in overcoming previous CUDA memory limitations, the primary objective was not met. The `ZetaOracle` consistently returned scientifically meaningless, near-zero scores, resisting all attempts at recalibration.

### **Phase 1: Breaking the Memory Barrier (Initial Success)**

*   **Action:** We successfully re-engineered the [CommandCenter](mdc:src/services/command_center/main.py) and [ZetaOracle](mdc:src/services/oracle/main.py) to handle a full ~261kb gene sequence.
*   **Outcome:** The `run_patient_assessment.py` script, which previously caused catastrophic `CUDA out of memory` errors, executed successfully from end-to-end.
*   **Lessons Learned:** The CUDA memory barrier can be broken. The victory was achieved through a multi-pronged strategy:
    1.  **Model Downscaling:** Shifting from the `evo2_40b` model to the leaner `1B` and `7B` variants was critical.
    2.  **Hardware Superiority:** Securing `H100` GPU resources provided the necessary VRAM.
    3.  **Precision Tactics:** Forcing the model to operate in `bfloat16` precision halved the memory footprint.

### **Phase 2: The "Zero-Score" Anomaly (Persistent Failure)**

*   **Action:** Upon successful system execution, we discovered the `ZetaOracle` produced a `delta_score` near zero (`0.276`), which is scientifically invalid for a known pathogenic variant. This became the central roadblock of the campaign.
*   **Hypothesis 1:** The `evo2` model's `score_sequences` function was defaulting to `reduce_method='mean'`, averaging the score over thousands of nucleotides and neutralizing its impact.
*   **Countermeasure 1:** A "sniper shot" test script (`scripts/final_blow_vep_test.py`) was created to isolate the Oracle. Logic was updated to explicitly call `reduce_method='sum'`.
*   **Result:** **FAILURE.** The test, after bypassing local environment errors by being embedded in the `CommandCenter`, still returned a near-zero score.

### **Phase 3: Direct Manual Override (The Final Assault)**

*   **Hypothesis 2:** A deep caching layer within the Modal environment was serving a "stale" or "sabotaged" version of the `score_sequences` function, causing it to ignore our parameters.
*   **Countermeasure 2:** A "Direct Manual Override." I rewrote the core scoring logic of the `ZetaOracle` to bypass the high-level API entirely. The new logic performed a low-level, token-by-token calculation of the total log-likelihood from raw logits. This was a brute-force assault designed to be impervious to caching.
*   **Result:** **CATASTROPHIC FAILURE.** The final test, even with the manual override and the user-directed upgrade to the `7B` model, returned the same near-zero score.

## **Final Intelligence Assessment & New Doctrine**

*   **The Enemy is Deeper Than The Code:** We have proven that the error does not lie in the visible application logic of the `ZetaOracle` or `CommandCenter`. The failure of the Direct Manual Override, our most powerful weapon, indicates the problem resides at a much deeper level, likely within the core `evo2` model's internal state, its interaction with the GPU device, or a fundamental flaw in how the tokenizer and model are initialized together within the Modal class structure.
*   **The High-Level API is a Liar:** The `score_sequences` function proved to be an unreliable black box. It did not honor its documented contract (`reduce_method='sum'`). **Doctrine:** When a high-level model API behaves illogically, it cannot be trusted. An immediate escalation to a low-level, manual implementation is the only valid tactical response to verify the true source of an error.
*   **The Final Clue:** The user's last manual intervention—explicitly setting `self.tokenizer`, `self.device`, and calling `self.model.to(self.device)` after initialization—points towards the next line of attack. This suggests a subtle but critical flaw in the object's state management and its relationship with the underlying GPU hardware, a battle we have not yet fought.
description:
globs:
alwaysApply: false
---
