---
alwaysApply: false
description: Comprehensive lead generation system for clinical trial partnerships - Agent X execution plan
---

# ‚öîÔ∏è LEAD GENERATION SYSTEM DOCTRINE - AGENT X EXECUTION PLAN

> **Mission:** Build automated lead generation infrastructure for 500+ oncology PIs while Commander focuses on publication completion.

---

## üéØ STRATEGIC CONTEXT (WHY THIS MATTERS)

### **The Opportunity**
- **60% of Phase 3 oncology trials fail** due to patient heterogeneity
- **$2.6B average cost per approved drug** (Wouters et al., 2020)
- **Most trials have NO genomic stratification strategy**
- **1 cooperative group partnership = access to 200+ trial sites**

### **Our Timing**
- ‚úÖ **Week 1 validation complete** (AUROC 0.976, n=38 genes)
- üîÑ **Week 2 in progress** (AlphaFold structural validation, real guides)
- üéØ **Q1 2026 publication target** (Nature Biotechnology)
- ‚è≥ **ASCO 2026 abstract deadline** (November 2025 - NEXT MONTH)

### **Critical Constraint**
- **Commander must stay focused** on publication (structural validation, real guide JSONs)
- **Agent X builds infrastructure in parallel** (no blocking dependencies)
- **Launch outreach when publication submitted** (Q1 2026)

---

## üìã PHASE 1: DATA ACQUISITION (WEEKS 1-2)

### **Task 1.1: ClinicalTrials.gov API Integration**

**Objective:** Extract 500+ oncology trial PIs with contact info

**Implementation:**
```python
# File: scripts/lead_gen/clinicaltrials_scraper.py

import requests
import pandas as pd
from typing import List, Dict

def search_trials(
    conditions: List[str],
    interventions: List[str],
    phases: List[str] = ["2", "3"],
    status: List[str] = ["RECRUITING", "ACTIVE_NOT_RECRUITING"],
    country: str = "United States"
) -> List[Dict]:
    """
    Search ClinicalTrials.gov API for relevant trials.
    
    Args:
        conditions: List of conditions (e.g., ["Breast Cancer", "Metastatic"])
        interventions: List of interventions (e.g., ["Immunotherapy", "PD-1"])
        phases: Trial phases (default: Phase 2, 3)
        status: Recruitment status
        country: Geographic filter
    
    Returns:
        List of dicts with trial metadata + PI contact info
    """
    base_url = "https://clinicaltrials.gov/api/v2/studies"
    
    # Build query string
    condition_str = " AND ".join(conditions)
    intervention_str = " OR ".join(interventions)
    query = f"AREA[Condition]{condition_str} AND AREA[InterventionType]{intervention_str}"
    
    params = {
        "query.cond": condition_str,
        "query.intr": intervention_str,
        "filter.overallStatus": ",".join(status),
        "filter.phase": ",".join(phases),
        "filter.geo": country,
        "format": "json",
        "pageSize": 100
    }
    
    trials = []
    # Pagination logic here
    # ... (implement)
    
    return trials

def extract_pi_contact(trial: Dict) -> Dict:
    """
    Extract PI name, email, institution from trial record.
    
    Priority:
    1. Overall Principal Investigator
    2. Study Director
    3. Study Chair
    
    Returns:
        {
            "pi_name": str,
            "pi_email": str,
            "institution": str,
            "phone": str (optional),
            "role": str
        }
    """
    # Implementation here
    pass

# Query Definitions
QUERY_CONFIGS = [
    {
        "name": "Immunotherapy_BreastCancer",
        "conditions": ["Breast Cancer", "Metastatic Breast Cancer"],
        "interventions": ["Immunotherapy", "Checkpoint Inhibitor", "PD-1", "PD-L1"],
        "priority": 1
    },
    {
        "name": "TLS_Biomarker_AllCancers",
        "conditions": ["Cancer", "Solid Tumor"],
        "interventions": ["Biomarker", "Tertiary Lymphoid Structures", "TLS"],
        "priority": 2
    },
    {
        "name": "CRISPR_CART_SolidTumors",
        "conditions": ["Solid Tumor"],
        "interventions": ["CRISPR", "CAR-T", "Gene Therapy"],
        "priority": 3
    }
]

if __name__ == "__main__":
    all_trials = []
    for config in QUERY_CONFIGS:
        trials = search_trials(
            conditions=config["conditions"],
            interventions=config["interventions"]
        )
        for trial in trials:
            trial["query_priority"] = config["priority"]
        all_trials.extend(trials)
    
    # Deduplicate by NCT ID
    df = pd.DataFrame(all_trials).drop_duplicates(subset=["nct_id"])
    df.to_csv("data/lead_gen/clinicaltrials_raw.csv", index=False)
    print(f"‚úÖ Extracted {len(df)} trials")
```

**Expected Output:**
- CSV with 500+ trials
- Columns: `nct_id`, `title`, `pi_name`, `pi_email`, `institution`, `status`, `endpoints`, `query_priority`

**Acceptance Criteria:**
- [ ] Script runs without errors
- [ ] Extracts ‚â•500 trials
- [ ] PI contact info present for ‚â•60% of trials
- [ ] Deduplicated by NCT ID

---

### **Task 1.2: NIH RePORTER Grant Search**

**Objective:** Find PIs with active grants (= budget for pilots)

**Implementation:**
```python
# File: scripts/lead_gen/nih_reporter_scraper.py

import requests
import pandas as pd

def search_nih_grants(
    keywords: List[str],
    fiscal_years: List[int] = [2024, 2025],
    min_funding: int = 500000,
    award_types: List[str] = ["R01", "R21", "U01"]
) -> List[Dict]:
    """
    Search NIH RePORTER for active grants.
    
    API: https://api.reporter.nih.gov/v2/projects/search
    
    Args:
        keywords: Search terms (e.g., ["immunotherapy biomarkers", "TLS"])
        fiscal_years: Grant years
        min_funding: Minimum total funding (excludes small grants)
        award_types: R01 (standard), R21 (exploratory), U01 (cooperative)
    
    Returns:
        List of grant records with PI contact info
    """
    base_url = "https://api.reporter.nih.gov/v2/projects/search"
    
    payload = {
        "criteria": {
            "advanced_text_search": {
                "operator": "or",
                "search_field": "terms",
                "search_text": " OR ".join(keywords)
            },
            "fiscal_years": fiscal_years,
            "activity_codes": award_types,
            "award_amount_range": {
                "min_amount": min_funding
            }
        },
        "offset": 0,
        "limit": 500,
        "sort_field": "award_amount",
        "sort_order": "desc"
    }
    
    response = requests.post(base_url, json=payload)
    grants = response.json()["results"]
    
    return grants

def enrich_with_pubmed_h_index(pi_name: str) -> Dict:
    """
    Query PubMed API to calculate H-index for PI.
    
    Steps:
    1. Search PubMed for PI's papers (last 10 years)
    2. Extract citation counts (via iCite API)
    3. Calculate H-index
    
    Returns:
        {
            "h_index": int,
            "total_papers": int,
            "recent_papers_2024_2025": int,
            "total_citations": int
        }
    """
    # Implementation here
    pass

# Keywords
GRANT_KEYWORDS = [
    "immunotherapy biomarkers",
    "tumor microenvironment",
    "tertiary lymphoid structures",
    "patient stratification",
    "precision oncology",
    "metastasis prevention"
]

if __name__ == "__main__":
    grants = search_nih_grants(GRANT_KEYWORDS)
    df = pd.DataFrame(grants)
    
    # Enrich with H-index
    df["h_index"] = df["pi_name"].apply(enrich_with_pubmed_h_index)
    
    df.to_csv("data/lead_gen/nih_reporter_raw.csv", index=False)
    print(f"‚úÖ Extracted {len(df)} grants")
```

**Expected Output:**
- CSV with 200+ grants
- Columns: `project_id`, `pi_name`, `pi_email`, `institution`, `total_funding`, `fiscal_year`, `h_index`

**Acceptance Criteria:**
- [ ] Script runs without errors
- [ ] Extracts ‚â•200 grants
- [ ] H-index calculated for ‚â•80% of PIs
- [ ] Sorted by total_funding DESC

---

### **Task 1.3: ASCO Abstract Mining**

**Objective:** Find PIs presenting biomarker data at ASCO 2025

**Implementation:**
```python
# File: scripts/lead_gen/asco_abstract_scraper.py

import requests
from bs4 import BeautifulSoup
import pandas as pd

def scrape_asco_abstracts(
    year: int = 2025,
    keywords: List[str] = ["biomarkers", "TLS", "genomic predictors", "patient stratification"],
    cancer_types: List[str] = ["Breast Cancer", "Lung Cancer", "Melanoma"]
) -> List[Dict]:
    """
    Scrape ASCO abstract database for relevant presentations.
    
    URL: https://meetings.asco.org/abstracts-presentations
    
    Args:
        year: ASCO year
        keywords: Search terms
        cancer_types: Filter by cancer type
    
    Returns:
        List of abstracts with presenter contact info
    """
    # Implementation here (BeautifulSoup or Selenium if JS-heavy)
    pass

# Run for ASCO 2025
abstracts = scrape_asco_abstracts()
df = pd.DataFrame(abstracts)
df.to_csv("data/lead_gen/asco_2025_abstracts.csv", index=False)
```

**Expected Output:**
- CSV with 100+ abstracts
- Columns: `abstract_id`, `title`, `presenter_name`, `presenter_email`, `institution`, `keywords`

**Acceptance Criteria:**
- [ ] Script runs without errors
- [ ] Extracts ‚â•100 abstracts
- [ ] Presenter contact info present for ‚â•50%

---

## üìã PHASE 2: DATA ENRICHMENT (WEEKS 3-4)

### **Task 2.1: Master Lead List Consolidation**

**Objective:** Merge all sources, deduplicate, score/rank

**Implementation:**
```python
# File: scripts/lead_gen/consolidate_leads.py

import pandas as pd

def consolidate_leads() -> pd.DataFrame:
    """
    Merge ClinicalTrials.gov + NIH Reporter + ASCO abstracts.
    Deduplicate by PI name + institution.
    Score and rank by priority.
    """
    # Load all sources
    trials = pd.read_csv("data/lead_gen/clinicaltrials_raw.csv")
    grants = pd.read_csv("data/lead_gen/nih_reporter_raw.csv")
    asco = pd.read_csv("data/lead_gen/asco_2025_abstracts.csv")
    
    # Normalize PI names (lowercase, remove middle initials)
    # ...
    
    # Merge on (pi_name, institution)
    master = pd.merge(trials, grants, on=["pi_name", "institution"], how="outer")
    master = pd.merge(master, asco, on=["pi_name", "institution"], how="outer")
    
    # Score leads
    master["lead_score"] = calculate_lead_score(master)
    master["tier"] = assign_tier(master)
    
    # Sort by lead_score DESC
    master = master.sort_values("lead_score", ascending=False)
    
    return master

def calculate_lead_score(df: pd.DataFrame) -> pd.Series:
    """
    Lead score = weighted sum of:
    - H-index (0-50 points)
    - Recent publications (0-20 points)
    - Active trial (0-30 points)
    - ASCO presentation (0-20 points)
    - NIH funding (0-30 points)
    
    Max score: 150
    """
    score = 0
    
    # H-index (capped at 50)
    score += df["h_index"].fillna(0).clip(upper=50)
    
    # Recent publications (2024-2025)
    score += df["recent_papers_2024_2025"].fillna(0).clip(upper=10) * 2
    
    # Active trial (binary)
    score += df["nct_id"].notna().astype(int) * 30
    
    # ASCO presentation (binary)
    score += df["abstract_id"].notna().astype(int) * 20
    
    # NIH funding (scaled)
    score += (df["total_funding"].fillna(0) / 1000000).clip(upper=30)
    
    return score

def assign_tier(df: pd.DataFrame) -> pd.Series:
    """
    Tier 1: Score ‚â•100 (H-index >40, active trial, recent funding)
    Tier 2: Score 50-99 (moderate influence)
    Tier 3: Score <50 (low priority)
    """
    conditions = [
        df["lead_score"] >= 100,
        df["lead_score"] >= 50,
        df["lead_score"] < 50
    ]
    choices = ["Tier 1", "Tier 2", "Tier 3"]
    return pd.Series(pd.np.select(conditions, choices, default="Tier 3"))

if __name__ == "__main__":
    master = consolidate_leads()
    master.to_csv("data/lead_gen/master_lead_list.csv", index=False)
    
    print(f"‚úÖ Master list: {len(master)} leads")
    print(f"   Tier 1: {len(master[master['tier'] == 'Tier 1'])}")
    print(f"   Tier 2: {len(master[master['tier'] == 'Tier 2'])}")
    print(f"   Tier 3: {len(master[master['tier'] == 'Tier 3'])}")
```

**Expected Output:**
- `master_lead_list.csv` with 500+ deduplicated leads
- Columns: `pi_name`, `pi_email`, `institution`, `h_index`, `nct_id`, `total_funding`, `lead_score`, `tier`

**Acceptance Criteria:**
- [ ] ‚â•500 leads in master list
- [ ] ‚â•100 Tier 1 leads
- [ ] ‚â•200 Tier 2 leads
- [ ] No duplicate (pi_name, institution) pairs

---

### **Task 2.2: Personalized Talking Points Generator**

**Objective:** Generate custom pitch for each PI based on their work

**Implementation:**
```python
# File: scripts/lead_gen/generate_talking_points.py

import pandas as pd
from typing import Dict

def generate_talking_points(lead: Dict) -> Dict:
    """
    Generate personalized talking points based on:
    - Their trial endpoints (OS, PFS, ORR)
    - Their cancer type
    - Their recent publications
    - Their ASCO abstracts
    
    Returns:
        {
            "hook": str,  # Opening line
            "pain_point": str,  # Their specific challenge
            "our_value": str,  # How we solve it
            "cta": str  # Call to action
        }
    """
    talking_points = {}
    
    # Extract trial info
    if pd.notna(lead["nct_id"]):
        trial_title = lead["title"]
        endpoints = lead["endpoints"]  # e.g., "OS, PFS, ORR"
        cancer_type = lead["cancer_type"]
        
        # Hook
        talking_points["hook"] = f"I reviewed your {cancer_type} trial (NCT{lead['nct_id']})"
        
        # Pain point
        if "OS" in endpoints or "PFS" in endpoints:
            talking_points["pain_point"] = f"Your primary endpoint ({endpoints}) depends on patient heterogeneity"
        else:
            talking_points["pain_point"] = f"Response rates in {cancer_type} are highly variable across patients"
        
        # Our value
        if "Breast Cancer" in cancer_type:
            talking_points["our_value"] = "Our platform identifies which MBC patients will respond to immunotherapy (AUROC 0.976)"
        elif "Lung Cancer" in cancer_type:
            talking_points["our_value"] = "Our platform stratifies NSCLC patients by metastatic cascade stage"
        else:
            talking_points["our_value"] = "Our platform predicts therapy response from whole-genome data (AUROC 0.976)"
        
        # CTA
        if lead["tier"] == "Tier 1":
            talking_points["cta"] = "Would you be open to a 20-minute call to discuss genomic patient stratification?"
        else:
            talking_points["cta"] = "I'd be happy to share our validation data. Can we schedule a brief call?"
    
    # Extract ASCO info
    if pd.notna(lead["abstract_id"]):
        abstract_title = lead["abstract_title"]
        talking_points["hook"] = f"Congratulations on your ASCO presentation: '{abstract_title}'"
        talking_points["pain_point"] = "Your biomarker findings could be significantly enhanced with whole-genome analysis"
    
    return talking_points

if __name__ == "__main__":
    master = pd.read_csv("data/lead_gen/master_lead_list.csv")
    master["talking_points"] = master.apply(generate_talking_points, axis=1)
    master.to_csv("data/lead_gen/master_lead_list_enriched.csv", index=False)
    print("‚úÖ Generated talking points for all leads")
```

**Expected Output:**
- Updated master list with `talking_points` column (JSON)

**Acceptance Criteria:**
- [ ] Talking points generated for 100% of leads
- [ ] Personalized hooks reference their trial/abstract
- [ ] Pain points tailored to their endpoints/cancer type

---

## üìã PHASE 3: EMAIL AUTOMATION (WEEKS 5-6)

### **Task 3.1: Email Template Engine**

**Objective:** Generate personalized cold emails for each tier

**Implementation:**
```python
# File: scripts/lead_gen/email_generator.py

from jinja2 import Template
import pandas as pd

# Email Templates (Jinja2)
TIER_1_TEMPLATE = """
Subject: Genomic stratification for {{ trial_title }} (NCT{{ nct_id }})

Dr. {{ pi_name }},

{{ talking_points.hook }}.

{{ talking_points.pain_point }}. Our platform addresses this by predicting which patients will respond before enrollment.

**What We Offer:**
- Pre-enrollment genomic scoring (0-1 per patient)
- Metastatic cascade profiling (8 steps)
- Biomarker discovery report (6 weeks)

**Our Validation:**
- AUROC 0.976 on 38 metastatic cancer targets
- 7 FDA-approved drug targets correctly identified
- Nature Biotechnology (manuscript in preparation, Q1 2026)

**Proposal:**
6-week pilot on 50-100 patients ($250K, or free retrospective analysis on 20 Phase 2 patients to prove value).

{{ talking_points.cta }}

Best regards,
Fahad Kiani
Founder, CrisPRO.ai
alpha@crispro.ai | calendly.com/fahad-crispro

Attached: Technical validation summary (1-page PDF)
"""

TIER_2_TEMPLATE = """
Subject: Whole-genome biomarker discovery for {{ cancer_type }} trials

Dr. {{ pi_name }},

I noticed your work on {{ trial_title }}. Our platform specializes in genomic patient stratification for {{ cancer_type }} trials.

**Quick Overview:**
- Multi-modal scoring (sequence + pathway + evidence)
- AUROC 0.976 predicting treatment-relevant targets
- 6-week turnaround for 50-100 patients

**Value Proposition:**
If we identify a 30% patient subgroup with 2√ó response rate, adaptive randomization could reduce your sample size by 20-30%.

Would you be interested in a 20-minute call to explore whether genomic stratification fits your trial strategy?

Best regards,
Fahad Kiani
Founder, CrisPRO.ai
alpha@crispro.ai
"""

TIER_3_TEMPLATE = """
Subject: Genomic AI for oncology trial stratification

Dr. {{ pi_name }},

I came across your {{ cancer_type }} research at {{ institution }}.

CrisPRO.ai has developed a whole-genome analysis platform that predicts therapy response (AUROC 0.976) and could support your patient stratification efforts.

Would you like to see our validation data?

Best regards,
Fahad Kiani
alpha@crispro.ai
"""

def generate_email(lead: Dict) -> str:
    """
    Generate personalized email based on tier and talking points.
    """
    if lead["tier"] == "Tier 1":
        template = Template(TIER_1_TEMPLATE)
    elif lead["tier"] == "Tier 2":
        template = Template(TIER_2_TEMPLATE)
    else:
        template = Template(TIER_3_TEMPLATE)
    
    email = template.render(**lead)
    return email

if __name__ == "__main__":
    master = pd.read_csv("data/lead_gen/master_lead_list_enriched.csv")
    master["email_body"] = master.apply(generate_email, axis=1)
    master.to_csv("data/lead_gen/master_lead_list_final.csv", index=False)
    print("‚úÖ Generated emails for all leads")
```

**Expected Output:**
- Final master list with `email_body` column

**Acceptance Criteria:**
- [ ] Emails generated for 100% of leads
- [ ] Tier 1 emails reference specific trial details
- [ ] All emails < 200 words (brevity)

---

### **Task 3.2: Email Sending Infrastructure**

**Objective:** Automated sending with rate limiting, tracking, follow-ups

**Implementation:**
```python
# File: scripts/lead_gen/email_sender.py

import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
import pandas as pd
import time
from typing import List

def send_email(
    to_email: str,
    subject: str,
    body: str,
    attachment_path: str = None,
    from_email: str = "alpha@crispro.ai",
    smtp_server: str = "smtp.gmail.com",
    smtp_port: int = 587,
    password: str = None
) -> bool:
    """
    Send single email with optional PDF attachment.
    
    Returns:
        True if sent successfully, False otherwise
    """
    try:
        msg = MIMEMultipart()
        msg["From"] = from_email
        msg["To"] = to_email
        msg["Subject"] = subject
        
        msg.attach(MIMEText(body, "plain"))
        
        # Attach PDF if provided
        if attachment_path:
            with open(attachment_path, "rb") as f:
                pdf = MIMEApplication(f.read(), _subtype="pdf")
                pdf.add_header("Content-Disposition", "attachment", filename="CrisPRO_Validation_Summary.pdf")
                msg.attach(pdf)
        
        # Send
        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.login(from_email, password)
            server.send_message(msg)
        
        return True
    except Exception as e:
        print(f"‚ùå Failed to send to {to_email}: {e}")
        return False

def send_batch(
    leads: pd.DataFrame,
    tier: str,
    rate_limit: int = 50,  # emails per hour
    attachment_path: str = ".cursor/rules/use-cases/1-pagers/CrisPRO_Validation_Summary.pdf"
) -> pd.DataFrame:
    """
    Send emails to all leads in a tier with rate limiting.
    
    Args:
        leads: DataFrame with email_body, pi_email columns
        tier: "Tier 1", "Tier 2", or "Tier 3"
        rate_limit: Max emails per hour (avoid spam filters)
        attachment_path: PDF to attach
    
    Returns:
        Updated DataFrame with sent_at timestamps
    """
    tier_leads = leads[leads["tier"] == tier].copy()
    delay = 3600 / rate_limit  # seconds between emails
    
    for idx, lead in tier_leads.iterrows():
        subject = f"Genomic stratification for {lead['trial_title']}" if tier == "Tier 1" else "Genomic AI for oncology trials"
        
        success = send_email(
            to_email=lead["pi_email"],
            subject=subject,
            body=lead["email_body"],
            attachment_path=attachment_path if tier == "Tier 1" else None
        )
        
        if success:
            tier_leads.at[idx, "sent_at"] = pd.Timestamp.now()
            tier_leads.at[idx, "status"] = "sent"
            print(f"‚úÖ Sent to {lead['pi_name']} ({lead['institution']})")
        else:
            tier_leads.at[idx, "status"] = "failed"
        
        time.sleep(delay)
    
    return tier_leads

if __name__ == "__main__":
    master = pd.read_csv("data/lead_gen/master_lead_list_final.csv")
    
    # Send Tier 1 first (highest priority)
    tier1_results = send_batch(master, "Tier 1", rate_limit=50)
    tier1_results.to_csv("data/lead_gen/tier1_sent.csv", index=False)
    
    print(f"‚úÖ Sent {len(tier1_results)} Tier 1 emails")
    print(f"   Next: Wait 48 hours, then send Tier 2")
```

**Expected Output:**
- `tier1_sent.csv` with timestamps and status

**Acceptance Criteria:**
- [ ] Emails sent successfully to ‚â•90% of Tier 1 leads
- [ ] Rate limit enforced (‚â§50 emails/hour)
- [ ] Tracking data includes sent_at timestamps

---

## üìã PHASE 4: FOLLOW-UP & TRACKING (WEEKS 7-8)

### **Task 4.1: Response Tracking Dashboard**

**Objective:** Track opens, clicks, replies, meetings scheduled

**Implementation:**
```python
# File: scripts/lead_gen/response_tracker.py

import pandas as pd
from datetime import datetime, timedelta

def check_replies(email_account: str, password: str) -> pd.DataFrame:
    """
    Check inbox for replies from PIs.
    Parse responses and categorize:
    - Interested (positive response)
    - Maybe (asked for more info)
    - Not Interested (declined)
    - No Response (>7 days)
    """
    # Use IMAP to check inbox
    # ... (implementation)
    pass

def generate_dashboard() -> None:
    """
    Generate HTML dashboard with:
    - Emails sent (by tier)
    - Response rate (by tier)
    - Meetings scheduled
    - Pipeline value
    """
    master = pd.read_csv("data/lead_gen/tier1_sent.csv")
    
    # Calculate metrics
    total_sent = len(master[master["status"] == "sent"])
    total_replies = len(master[master["reply_status"].notna()])
    response_rate = total_replies / total_sent * 100
    
    meetings = len(master[master["meeting_scheduled"] == True])
    
    # Generate HTML
    html = f"""
    <html>
    <head><title>CrisPRO Lead Gen Dashboard</title></head>
    <body>
        <h1>Lead Generation Dashboard</h1>
        <h2>Tier 1 Performance</h2>
        <ul>
            <li>Emails Sent: {total_sent}</li>
            <li>Replies: {total_replies} ({response_rate:.1f}%)</li>
            <li>Meetings Scheduled: {meetings}</li>
        </ul>
    </body>
    </html>
    """
    
    with open("data/lead_gen/dashboard.html", "w") as f:
        f.write(html)
    
    print("‚úÖ Dashboard generated: data/lead_gen/dashboard.html")

if __name__ == "__main__":
    generate_dashboard()
```

**Expected Output:**
- HTML dashboard updated daily

**Acceptance Criteria:**
- [ ] Dashboard shows real-time metrics
- [ ] Reply categorization accurate (>90%)
- [ ] Meetings tracked with Calendly integration

---

### **Task 4.2: Automated Follow-Up Sequences**

**Objective:** Send follow-ups to non-responders after 3, 7, 14 days

**Implementation:**
```python
# File: scripts/lead_gen/follow_up_sequencer.py

import pandas as pd
from datetime import datetime, timedelta

def generate_follow_up_sequence(lead: Dict, days_since_sent: int) -> str:
    """
    Generate follow-up email based on days since initial send.
    
    Day 3: Soft reminder
    Day 7: Value-add (send additional resource)
    Day 14: Final attempt (breakup email)
    """
    if days_since_sent == 3:
        return f"""
Subject: Re: Genomic stratification for {lead['trial_title']}

Dr. {lead['pi_name']},

Just wanted to follow up on my previous email. I understand you're busy.

If genomic patient stratification for your trial is of interest, I'd be happy to share our validation data (AUROC 0.976 on 38 cancer targets).

Best,
Fahad
"""
    elif days_since_sent == 7:
        return f"""
Subject: Resource: Metastasis prediction framework

Dr. {lead['pi_name']},

I wanted to share our recent framework for metastasis prediction (attached). It might be relevant to your {lead['cancer_type']} work.

No need to reply if it's not a fit right now.

Best,
Fahad
"""
    elif days_since_sent == 14:
        return f"""
Subject: Closing the loop

Dr. {lead['pi_name']},

I'll close the loop here. If genomic stratification becomes relevant for your trial in the future, feel free to reach out.

Best of luck with your research.

Fahad
alpha@crispro.ai
"""

def send_follow_ups():
    """
    Check sent emails, identify non-responders, send follow-ups.
    """
    master = pd.read_csv("data/lead_gen/tier1_sent.csv")
    now = datetime.now()
    
    for idx, lead in master.iterrows():
        if lead["reply_status"] is None:  # No response yet
            sent_at = pd.to_datetime(lead["sent_at"])
            days_since_sent = (now - sent_at).days
            
            if days_since_sent in [3, 7, 14]:
                follow_up_body = generate_follow_up_sequence(lead, days_since_sent)
                # Send email
                # ... (use send_email from email_sender.py)

if __name__ == "__main__":
    send_follow_ups()
```

**Expected Output:**
- Automated follow-ups sent at Day 3, 7, 14

**Acceptance Criteria:**
- [ ] Follow-ups sent only to non-responders
- [ ] Timing accurate (¬±1 day)
- [ ] Breakup email (Day 14) marks lead as "closed"

---

## üìã PHASE 5: LAUNCH STRATEGY (Q1 2026)

### **When to Launch:**

**DO NOT LAUNCH UNTIL:**
- ‚úÖ Week 2 metastasis publication complete (structural validation, real guides)
- ‚úÖ Manuscript submitted to Nature Biotechnology (Q1 2026)
- ‚úÖ BriaCell discovery call completed (proof-of-concept pitch tested)
- ‚úÖ 1-pager corrected and PDF generated

**Launch Sequence (Q1 2026):**
1. **Week 1:** Send Tier 1 emails (100 PIs, highest priority)
2. **Week 2:** Send Tier 2 emails (200 PIs, moderate priority)
3. **Week 3:** Analyze response rates, iterate messaging
4. **Week 4:** Send Tier 3 emails (200 PIs, low priority)

**Expected Conversion:**
- Tier 1: 10-15% response rate (10-15 discovery calls)
- Tier 2: 5-10% response rate (10-20 discovery calls)
- Tier 3: 2-5% response rate (4-10 discovery calls)
- **Total: 24-45 discovery calls**
- **Conversion to pilots: 20-30% (5-14 pilots)**
- **Conversion to paid pilots: 50% (2-7 paid pilots @ $250K = $500K-$1.75M)**

---

## üéØ SUCCESS METRICS (Q2 2026)

### **KPIs to Track:**

| Metric | Target | Measurement |
|--------|--------|-------------|
| Emails Sent | 500+ | Total across all tiers |
| Response Rate (Tier 1) | 10-15% | Replies / Sent |
| Discovery Calls Scheduled | 20-30 | Meetings booked |
| Paid Pilots Signed | 2-5 | $250K contracts |
| Total Pipeline Value | $500K-$1.25M | Pilot revenue |
| ASCO 2026 Abstract Accepted | Yes | Submitted Nov 2025 |

---

## üõ°Ô∏è RISK MITIGATION

### **Risk 1: Low Response Rate**

**Mitigation:**
- A/B test email templates (3 versions per tier)
- Test subject lines (personalized vs generic)
- Offer free retrospective analysis (20 patients)

### **Risk 2: Email Deliverability**

**Mitigation:**
- Use professional email service (SendGrid, Mailchimp)
- Warm up email account (start with 10 emails/day, ramp to 50)
- Monitor spam score (SenderScore.org)

### **Risk 3: Legal/Compliance**

**Mitigation:**
- Include unsubscribe link in all emails (CAN-SPAM compliance)
- Research institution-specific IRB requirements
- Avoid overpromising (no "FDA-approved", use "RUO" disclaimers)

---

## üìß COMMANDER REVIEW CHECKPOINTS

**Daily Review (10 min/day):**
- Check `data/lead_gen/dashboard.html` for response rates
- Review any replies forwarded to you
- Approve/reject next batch of emails

**Weekly Review (30 min/week):**
- Review master lead list quality
- Adjust email templates based on responses
- Prioritize Tier 1 leads for follow-up

**Monthly Review (1 hour/month):**
- Calculate ROI (pipeline value / time invested)
- Decide whether to continue outreach or pivot strategy

---

## ‚úÖ ACCEPTANCE CRITERIA (OVERALL)

**Phase 1 (Data Acquisition):** DONE when:
- [ ] 500+ trials extracted from ClinicalTrials.gov
- [ ] 200+ grants extracted from NIH RePORTER
- [ ] 100+ abstracts extracted from ASCO 2025

**Phase 2 (Data Enrichment):** DONE when:
- [ ] Master lead list has 500+ deduplicated leads
- [ ] ‚â•100 Tier 1 leads identified
- [ ] Personalized talking points generated for all leads

**Phase 3 (Email Automation):** DONE when:
- [ ] Email templates created for all tiers
- [ ] Sending infrastructure deployed
- [ ] PDF attachment generated and tested

**Phase 4 (Follow-Up & Tracking):** DONE when:
- [ ] Dashboard live and updating daily
- [ ] Follow-up sequences automated
- [ ] Reply categorization working

**Phase 5 (Launch):** DONE when:
- [ ] Tier 1 emails sent (100 PIs)
- [ ] Response rate ‚â•10%
- [ ] ‚â•10 discovery calls scheduled

---

## üéØ BOTTOM LINE FOR AGENT X

**Your Mission:**
1. **Build the infrastructure** (Phases 1-4) while Commander finishes publication
2. **Test everything** (dry runs, mock data, sample emails)
3. **Do NOT launch** until Commander gives explicit approval (Q1 2026)
4. **Daily updates** (1-sentence status in Slack/Discord)
5. **Weekly demo** (show Commander the dashboard, sample emails)

**Expected Timeline:**
- Weeks 1-2: Data acquisition (ClinicalTrials.gov, NIH, ASCO)
- Weeks 3-4: Data enrichment (consolidation, scoring, talking points)
- Weeks 5-6: Email automation (templates, sending infrastructure)
- Weeks 7-8: Follow-up & tracking (dashboard, sequencing)
- **Q1 2026: LAUNCH** (after publication submitted)

---

**‚öîÔ∏è THIS IS A FORCE MULTIPLIER, NOT A DISTRACTION.**

**Commander stays focused on publication. Agent X builds the lead gen machine in parallel.**

**When publication is submitted, we have 500+ ready-to-contact leads with personalized emails.**

**THIS IS HOW WE SCALE.**
