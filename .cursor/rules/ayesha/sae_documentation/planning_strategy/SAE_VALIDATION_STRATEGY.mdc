# üî¨ SAE VALIDATION STRATEGY - PROVING CLINICAL ACCURACY

**Date**: January 13, 2025  
**Status**: ‚ö†Ô∏è CRITICAL GAP IDENTIFIED  
**Reality Check**: We built the system but haven't proven it works clinically

---

## ‚ùå **WHAT WE HAVEN'T DONE YET**

### **1. No Clinical Validation**
- ‚úÖ Unit tests pass (23/23)
- ‚úÖ Code executes without errors
- ‚úÖ Returns structured JSON
- ‚ùå **NO PROOF** that predictions match real patient outcomes

### **2. No AUROC/Performance Metrics**
- ‚ùå DNA Repair Capacity accuracy: **UNKNOWN**
- ‚ùå Resistance detection sensitivity: **UNKNOWN**
- ‚ùå Resistance detection specificity: **UNKNOWN**
- ‚ùå False positive rate: **UNKNOWN**
- ‚ùå Time-to-resistance prediction error: **UNKNOWN**

### **3. No End-to-End Validation**
- ‚úÖ Tested with 1 TCGA patient (synthetic scenario)
- ‚ùå Not tested against **real longitudinal patient data**
- ‚ùå Not tested against **known resistance cases**
- ‚ùå Not tested against **known responders**

### **4. No Ground Truth Comparison**
- We compute `dna_repair_capacity = 0.5` but is that **correct**?
- We predict `resistance_detected = false` but is that **accurate**?
- We say `pathway_burden_ddr = 0.5` but compared to **what gold standard**?

---

## üéØ **VALIDATION PLAN - 4 TIERS**

### **TIER 1: Synthetic Validation** (Week 1) ‚è≥
**Purpose**: Prove the math works with controlled inputs

#### **Test 1.1: DNA Repair Capacity Formula Validation**
**Method**: 
```python
# Manager's formula: 0.5*DDR + 0.3*essentiality + 0.2*functionality

# Test Case 1: Maximum values
input = {
    "pathway_burden_ddr": 1.0,
    "essentiality_hrr_genes": 1.0,
    "functionality": 1.0
}
expected_output = 0.5*1.0 + 0.3*1.0 + 0.2*1.0 = 1.0

# Test Case 2: Minimum values
input = {
    "pathway_burden_ddr": 0.0,
    "essentiality_hrr_genes": 0.0,
    "functionality": 0.0
}
expected_output = 0.0

# Test Case 3: Known BRCA1 case (from literature)
# Watkins et al. (2014): BRCA1-mutated patients have HRD ~55-65
input = {
    "pathway_burden_ddr": 0.75,  # Derived from HRD=58
    "essentiality_hrr_genes": 0.85,  # BRCA1 is essential
    "functionality": 0.60  # Partial LOF
}
expected_output = 0.5*0.75 + 0.3*0.85 + 0.2*0.60 = 0.75

# Compare to literature: BRCA1 patients have PARP response rate ~70-80%
# If our DNA repair capacity > 0.70, does PARP response rate match?
```

**Metrics**:
- ‚úÖ Formula correctness: 100% (math is deterministic)
- ‚è≥ Biological plausibility: TBD (compare to literature ranges)

---

#### **Test 1.2: Resistance Trigger Validation**
**Method**: Create synthetic patient timelines with known resistance

```python
# Synthetic Patient 1: Clear HR restoration pattern
timeline = [
    {"week": 0,  "hrd": 55, "dna_repair": 0.80, "ca125": 2842, "resistance": False},
    {"week": 12, "hrd": 54, "dna_repair": 0.78, "ca125": 450,  "resistance": False},
    {"week": 24, "hrd": 38, "dna_repair": 0.58, "ca125": 650,  "resistance": True},  # 2/3 triggers!
    {"week": 36, "hrd": 35, "dna_repair": 0.40, "ca125": 1200, "resistance": True}
]

# Test: Does our algorithm trigger at week 24?
# Expected: YES (HRD drop=17, DNA repair drop=0.22, CA-125 rising)

# Synthetic Patient 2: Stable responder (no resistance)
timeline = [
    {"week": 0,  "hrd": 60, "dna_repair": 0.85, "ca125": 3000, "resistance": False},
    {"week": 12, "hrd": 58, "dna_repair": 0.83, "ca125": 400,  "resistance": False},
    {"week": 24, "hrd": 57, "dna_repair": 0.82, "ca125": 50,   "resistance": False},
    {"week": 36, "hrd": 56, "dna_repair": 0.81, "ca125": 25,   "resistance": False}
]

# Test: Does our algorithm stay negative?
# Expected: YES (all stable, no triggers)
```

**Metrics**:
- Sensitivity (true positive rate): ?/? synthetic resistance cases detected
- Specificity (true negative rate): ?/? stable responders correctly identified
- **Target**: Sensitivity >80%, Specificity >90%

---

### **TIER 2: TCGA Retrospective Validation** (Week 2-3) ‚è≥
**Purpose**: Test against real patient outcomes (retrospective)

#### **Data Source**: TCGA Ovarian Cancer (n=584 patients)
**Available Data**:
- Somatic mutations (BRCA1/2, TP53, HRR genes)
- HRD scores
- Platinum response (from `outcome_platinum` field we already have!)
- Survival data (PFS, OS)

**File**: `tools/benchmarks/hrd_tcga_ov_labeled_sample_use_evo.json`

#### **Test 2.1: DNA Repair Capacity vs. Platinum Response**
**Hypothesis**: High DNA repair capacity ‚Üí Better platinum response

```python
# Extract from TCGA data
patients = load_tcga_ovarian_cancer()  # n=584

for patient in patients:
    # Compute SAE features
    sae = compute_sae_features(
        tumor_context=patient["mutations"],
        pathway_scores=infer_from_mutations(patient)
    )
    
    # Ground truth
    platinum_response = patient["outcome_platinum"]  # 0 or 1
    
    # Predict
    predicted_response = 1 if sae["dna_repair_capacity"] > 0.60 else 0
    
# Compute AUROC
from sklearn.metrics import roc_auc_score, roc_curve

y_true = [p["outcome_platinum"] for p in patients]
y_scores = [compute_sae_features(p)["dna_repair_capacity"] for p in patients]

auroc = roc_auc_score(y_true, y_scores)
print(f"DNA Repair Capacity AUROC for platinum response: {auroc:.3f}")

# Target: AUROC > 0.70 (reasonable for first version)
# Published HRD scores: AUROC ~0.60-0.75 for platinum response
```

**Expected Output**:
```
DNA Repair Capacity AUROC: 0.68 (95% CI: 0.62-0.74)
Sensitivity at threshold 0.60: 72%
Specificity at threshold 0.60: 68%
PPV: 75%
NPV: 65%
```

---

#### **Test 2.2: Pathway Burden vs. Drug Response**
**Hypothesis**: High DDR burden ‚Üí Better PARP response (if we had PARP outcomes)

**Problem**: TCGA doesn't have PARP treatment data (too old, PARP approved in 2018)

**Workaround**: Use HRD as proxy
- HRD >42 = "PARP-like" response expected
- Compare our DDR pathway burden to HRD score

```python
# Correlation test
import scipy.stats as stats

hrd_scores = [p["hrd_score"] for p in patients if "hrd_score" in p]
ddr_burdens = [compute_sae_features(p)["pathway_burden_ddr"] for p in patients]

correlation, p_value = stats.pearsonr(hrd_scores, ddr_burdens)
print(f"Correlation (HRD vs DDR burden): r={correlation:.3f}, p={p_value:.4f}")

# Target: r > 0.70 (strong correlation with established biomarker)
```

---

#### **Test 2.3: Resistance Detection - Time-to-Event Analysis**
**Challenge**: TCGA is **single timepoint** (baseline only, no longitudinal follow-up)

**Solution**: Use **progression-free survival (PFS)** as proxy
- Patients with early progression likely had intrinsic resistance
- Test if our baseline SAE features predict PFS

```python
from lifelines import CoxPHFitter
import pandas as pd

# Prepare survival data
survival_data = []
for patient in patients:
    sae = compute_sae_features(patient)
    survival_data.append({
        "patient_id": patient["id"],
        "pfs_months": patient["pfs_months"],
        "progressed": patient["progression_event"],
        "dna_repair_capacity": sae["dna_repair_capacity"],
        "pathway_burden_ddr": sae["pathway_burden_ddr"],
        "io_eligible": int(sae["io_eligible"])
    })

df = pd.DataFrame(survival_data)

# Cox proportional hazards model
cph = CoxPHFitter()
cph.fit(df, duration_col="pfs_months", event_col="progressed")
cph.print_summary()

# Expected output:
# dna_repair_capacity: HR=0.65 (95% CI: 0.45-0.92), p=0.015
# Interpretation: Higher DNA repair capacity ‚Üí 35% lower progression risk
```

**Metrics**:
- Hazard ratio (HR) for DNA repair capacity: ?
- C-index (concordance): ? (target >0.60)
- Log-rank p-value: ? (target <0.05)

---

### **TIER 3: Prospective Validation** (Month 2-6) ‚è≥
**Purpose**: Test on **new patients** with **longitudinal follow-up**

#### **Study Design**: Observational cohort
- **Population**: Stage III/IV ovarian cancer patients starting first-line therapy
- **n**: 50 patients (minimum for pilot)
- **Timeline**: 6-month follow-up
- **Endpoints**:
  1. **Primary**: Resistance detection lead time (SAE alert vs. imaging progression)
  2. **Secondary**: DNA repair capacity correlation with PARP response

#### **Data Collection**:
```
Baseline (Week 0):
  - Tumor NGS (BRCA, HRD, TMB, MSI)
  - CA-125
  - SAE features computed

Longitudinal (Every 4 weeks):
  - CA-125
  - ctDNA (if available)
  - Repeat HRD (at week 12, 24)
  - Imaging (RECIST 1.1) every 12 weeks

Outcomes:
  - RECIST progression date
  - SAE resistance alert date
  - Lead time = RECIST date - SAE alert date
```

#### **Test 3.1: Resistance Detection Lead Time**
**Primary Endpoint**: Does SAE detect resistance BEFORE imaging?

```python
# For each patient who progresses:
results = []
for patient in cohort:
    if patient["progressed"]:
        sae_alert_date = patient["first_resistance_alert"]  # From our system
        recist_progression_date = patient["imaging_progression"]  # Ground truth
        
        lead_time_days = (recist_progression_date - sae_alert_date).days
        results.append(lead_time_days)

# Analysis
import numpy as np
mean_lead_time = np.mean(results)
median_lead_time = np.median(results)
fraction_early = sum(1 for x in results if x > 0) / len(results)

print(f"Mean lead time: {mean_lead_time:.1f} days")
print(f"Median lead time: {median_lead_time:.1f} days")
print(f"Fraction detected early: {fraction_early:.1%}")

# Target: Median lead time > 60 days (2 months earlier than imaging)
```

#### **Test 3.2: False Positive Rate**
**Secondary Endpoint**: How often does SAE cry wolf?

```python
# For patients who DON'T progress:
false_positives = 0
true_negatives = 0

for patient in cohort:
    if not patient["progressed"]:
        if patient["ever_had_resistance_alert"]:
            false_positives += 1
        else:
            true_negatives += 1

fpr = false_positives / (false_positives + true_negatives)
print(f"False positive rate: {fpr:.1%}")

# Target: FPR < 10% (acceptable for early warning system)
```

---

### **TIER 4: Clinical Trial Validation** (Month 6-12) ‚è≥
**Purpose**: **Prospective, interventional** trial to prove clinical utility

#### **Study Design**: Randomized controlled trial (RCT)

**Arm A** (Control): Standard of care
- Clinician makes decisions based on standard biomarkers (HRD, CA-125, imaging)
- No SAE features provided

**Arm B** (Intervention): SAE-guided care
- Clinician receives SAE features + resistance alerts
- Encouraged to act on 2-of-3 triggers (early switch)

**Primary Endpoint**: Time to effective therapy (TTE)
- TTE = Time from resistance emergence to switch to effective next-line therapy

**Secondary Endpoints**:
- Progression-free survival 2 (PFS2) - time on second-line therapy
- Quality-adjusted life months (QALM)
- Cost of care (fewer ineffective treatment cycles)

#### **Sample Size Calculation**:
```python
# Assumptions:
# - Control arm: Mean TTE = 90 days (3 months to detect + switch)
# - Intervention arm: Mean TTE = 30 days (SAE detects early)
# - Standard deviation: 30 days
# - Power: 80%
# - Alpha: 0.05

from statsmodels.stats.power import tt_ind_solve_power

n_per_arm = tt_ind_solve_power(
    effect_size=(90-30)/30,  # Cohen's d = 2.0 (large effect)
    alpha=0.05,
    power=0.80,
    alternative='two-sided'
)

print(f"Required sample size per arm: {int(np.ceil(n_per_arm))}")
# Expected: ~20 patients per arm (40 total)
```

**Timeline**: 6-12 months (enrollment + follow-up)

---

## üìä **WHAT WE CAN DO NOW (This Week)**

### **IMMEDIATE VALIDATION - TCGA Retrospective Analysis**

We already have the data! Let's compute AUROCs TODAY:

#### **Step 1: Extract TCGA Patient Cohort**
```bash
# File already exists
tools/benchmarks/hrd_tcga_ov_labeled_sample_use_evo.json

# Contains:
# - 200 ovarian cancer patients
# - Real mutations (BRCA1, BRCA2, TP53)
# - Platinum response outcomes ("outcome_platinum": 0 or 1)
```

#### **Step 2: Compute SAE Features for All Patients**
```python
import json
from api.services.sae_feature_service import compute_sae_features

# Load TCGA data
with open('tools/benchmarks/hrd_tcga_ov_labeled_sample_use_evo.json') as f:
    tcga_data = json.load(f)

# Compute SAE for each patient
results = []
for patient in tcga_data['results']:
    # Extract tumor context
    tumor_context = {
        "somatic_mutations": [{
            "gene": patient["input"]["gene"],
            "hgvs_p": patient["input"]["hgvs_p"],
            "variant_type": infer_variant_type(patient["input"])
        }],
        "hrd_score": infer_hrd_from_mutations(patient),  # Estimate
        "tmb_score": 5.0,  # Default (not in TCGA)
        "msi_status": "MSS"
    }
    
    # Compute SAE features
    sae = compute_sae_features(
        insights_bundle={"functionality": 0.5, "chromatin": 0.5, "essentiality": 0.5, "regulatory": 0.5},
        pathway_scores={"ddr": 0.5, "mapk": 0.2, "pi3k": 0.2, "vegf": 0.3, "her2": 0.0},
        tumor_context=tumor_context,
        treatment_history=[],
        ca125_intelligence=None
    )
    
    results.append({
        "patient_id": patient["input"].get("sample_id"),
        "gene": patient["input"]["gene"],
        "dna_repair_capacity": sae["dna_repair_capacity"],
        "pathway_burden_ddr": sae["pathway_burden_ddr"],
        "platinum_response": int(patient["input"]["outcome_platinum"])
    })
```

#### **Step 3: Compute AUROC**
```python
from sklearn.metrics import roc_auc_score, roc_curve, classification_report
import matplotlib.pyplot as plt

# Extract ground truth and predictions
y_true = [r["platinum_response"] for r in results]
y_scores = [r["dna_repair_capacity"] for r in results]

# AUROC
auroc = roc_auc_score(y_true, y_scores)
print(f"DNA Repair Capacity AUROC: {auroc:.3f}")

# ROC curve
fpr, tpr, thresholds = roc_curve(y_true, y_scores)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUROC={auroc:.3f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('DNA Repair Capacity vs. Platinum Response (TCGA Validation)')
plt.legend()
plt.savefig('sae_validation_roc_curve.png')

# Classification report at optimal threshold
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
y_pred = [1 if score > optimal_threshold else 0 for score in y_scores]
print(classification_report(y_true, y_pred))
```

---

## ‚ö†Ô∏è **CURRENT GAPS & RISKS**

### **What We Don't Know**:
1. **Absolute Accuracy**: Is our DNA repair capacity calculation clinically accurate?
2. **False Positive Rate**: How often do we trigger resistance alerts incorrectly?
3. **Lead Time**: Do we actually detect resistance 2-3 months early (claimed benefit)?
4. **Generalizability**: Does this work beyond ovarian cancer?

### **What Could Go Wrong**:
1. **Low AUROC (<0.60)**: Our features don't predict outcomes ‚Üí back to drawing board
2. **High False Positives (>20%)**: Clinicians ignore alerts ‚Üí system loses trust
3. **No Lead Time**: SAE alerts at same time as imaging ‚Üí no clinical utility
4. **Pathway Scores Wrong**: We hardcoded `pathway_scores = {"ddr": 0.5, ...}` but these should come from Evo2/S/P/E models!

---

## üéØ **ACTION PLAN - NEXT 48 HOURS**

### **Priority 1: TCGA Retrospective AUROC** (TODAY)
```bash
# Create validation script
cd oncology-coPilot/oncology-backend-minimal
python3 scripts/validate_sae_tcga.py

# Output:
# - AUROC for DNA repair capacity vs platinum response
# - ROC curve plot
# - Sensitivity/Specificity at multiple thresholds
# - Comparison to published HRD scores (benchmark)
```

**File to create**: `scripts/validate_sae_tcga.py`

---

### **Priority 2: End-to-End Scenario Testing** (TOMORROW)
```bash
# Test real patient scenarios:
# 1. BRCA1-mutated ‚Üí Should recommend PARP
# 2. HRD-low ‚Üí Should NOT recommend PARP
# 3. High TMB ‚Üí Should flag IO eligibility
# 4. Resistance scenario ‚Üí Should trigger 2-of-3 rule
```

**File to create**: `tests/test_e2e_clinical_scenarios.py`

---

### **Priority 3: Resistance Detection Sensitivity Analysis** (DAY 3)
```bash
# Synthetic timelines with known resistance
# Test:
# - True positive rate (sensitivity)
# - False positive rate (1 - specificity)
# - Time to alert (lead time simulation)
```

**File to create**: `tests/test_resistance_detection_performance.py`

---

## üèÜ **SUCCESS CRITERIA**

### **Minimum Viable Performance**:
- **DNA Repair Capacity AUROC**: >0.65 (better than random, approaching HRD performance)
- **Resistance Detection Sensitivity**: >70% (catches most resistance cases)
- **Resistance Detection Specificity**: >85% (low false alarm rate)
- **E2E Test Pass Rate**: 100% (all clinical scenarios behave correctly)

### **Target Performance** (for clinical deployment):
- **DNA Repair Capacity AUROC**: >0.75 (clinically useful)
- **Resistance Detection Lead Time**: >60 days (2 months earlier than imaging)
- **False Positive Rate**: <10% (acceptable for early warning)

---

## üìö **BENCHMARKS TO COMPARE AGAINST**

### **Published Performance Metrics**:

1. **HRD Scores** (MyChoice CDx):
   - AUROC for platinum response: 0.60-0.75
   - Sensitivity at cutoff ‚â•42: 70-80%
   - Specificity: 60-70%

2. **CA-125 GCIG Criteria** (Rustin et al. 2011):
   - Sensitivity for progression: 70-80%
   - Specificity: 60-70%
   - Lead time vs imaging: ~4-8 weeks

3. **ctDNA for Resistance** (Steffensen et al. 2021):
   - Sensitivity: 60-75%
   - Lead time vs imaging: 6-10 weeks

**Our Target**: Match or exceed HRD/CA-125 performance for resistance detection (>8 weeks lead time)

---

## ‚öîÔ∏è **BOTTOM LINE**

### **Current State**:
- ‚úÖ System is **built and functional**
- ‚úÖ Code is **tested and operational**
- ‚ùå Clinical accuracy is **UNPROVEN**
- ‚ùå AUROCs are **UNKNOWN**

### **What We Need to Do**:
1. **TODAY**: Compute AUROC on TCGA data (Tier 2 validation)
2. **THIS WEEK**: End-to-end scenario testing
3. **THIS MONTH**: Resistance detection performance analysis
4. **NEXT 6 MONTHS**: Prospective validation with real patients

### **The Honest Answer**:
**We DON'T know if we're correct yet.** We built a system based on:
- Manager's logical policy (thresholds, formulas)
- Published biology (HRD, DDR pathways)
- Real genomic data (TCGA)

But until we compute **AUROCs on held-out patient outcomes**, we're flying blind.

**LET'S FIX THAT NOW.** Want me to create the TCGA validation script?

---

**‚öîÔ∏è END OF VALIDATION STRATEGY ‚öîÔ∏è**

**Status**: Critical gap identified, action plan ready  
**Next Step**: Build `validate_sae_tcga.py` to compute AUROCs TODAY
