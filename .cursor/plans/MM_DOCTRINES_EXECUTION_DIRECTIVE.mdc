---
title: MM Doctrines Execution Directive
description: Enhanced execution plan for TCell, TCF1, TLS, and TOX doctrines with validated patterns from MBD4+TP53, SOTA benchmarks, Ayesha universalization, and Proxy SAE validation plans
alwaysApply: false
---

# MM Doctrines Execution Directive

**Created:** January 2025  
**Status:** Planning Phase - Pattern Synthesis Complete  
**Purpose:** Execute TCell, TCF1, TLS, and TOX doctrines with validated patterns from proven analysis plans

---

## Executive Summary

This directive synthesizes critical learnings from four proven analysis plans:

1. **MBD4+TP53 Analysis Plan**: Pathway score extraction patterns, mechanism vector conversion requirements, endpoint integration patterns
2. **SOTA Benchmarks Plan**: Test-driven validation methodology, validation gates, known biology test cases, benchmark dataset structure
3. **Ayesha Universalization Plan**: Code reference verification patterns, mutation format validation, test checkpoint methodology, baseline verification approach
4. **Proxy SAE Validation Plan**: Benchmark dataset creation, validation metrics framework, 8-question clinical framework, known biology validation

**Key Pattern Learnings:**
- **Pathway Score Extraction**: Extract from `pathway_disruption` passed to SAE service (orchestrator.py:360), NOT from `confidence_breakdown` (that's different structure)
- **Mechanism Vector Conversion**: Already referenced in `advanced_trial_queries.py:164` - service expected but may be empty
- **Test-Driven Development**: Validation gates at each phase, known biology test cases, code reference verification
- **Baseline Verification**: Test current behavior first, then enhance (Ayesha pattern)

---

## Current State Analysis (Code-Verified)

### What EXISTS (Verified in Codebase)

1. **Pathway Aggregation**: `api/services/pathway/aggregation.py:7-45`
   - Function: `aggregate_pathways(seq_scores)` → returns `Dict[str, float]`
   - Pathway names: lowercase with underscores (`ddr`, `ras_mapk`, `tp53`, `pi3k`, `vegf`)
   - Called automatically in orchestrator: `orchestrator.py:105`

2. **Pathway Scores in Orchestrator**: `api/services/efficacy_orchestrator/orchestrator.py:360`
   - Pathway scores passed to SAE service as `pathway_disruption=pathway_scores`
   - Structure: `Dict[str, float]` (e.g., `{"ddr": 0.5, "ras_mapk": 0.3}`)
   - **NOT in confidence_breakdown**: That structure is different (S/P/E contributions, not raw pathway scores)

3. **Mechanism Vector Structure**: `api/services/sae_feature_service.py:206-214`
   - 7D vector: `[DDR, MAPK, PI3K, VEGF, HER2, IO, Efflux]`
   - IO eligibility: `1.0 if (tmb >= 20 or msi_high) else 0.0` (line 200)
   - Used by: `api/services/mechanism_fit_ranker.py:89` (expects 7D List[float])

4. **Mechanism Vector Service Reference**: `api/routers/advanced_trial_queries.py:164`
   - Imports: `from api.services.pathway_to_mechanism_vector import convert_pathway_scores_to_mechanism_vector`
   - Expected signature: `convert_pathway_scores_to_mechanism_vector(pathway_scores, tumor_context, use_7d)`
   - Returns: `(mechanism_vector, provenance_dict)` tuple
   - **Status**: File exists but appears empty - needs implementation

5. **Test Patterns**: `tests/test_sae_phase2_services.py`, `tests/test_advanced_trial_queries.py`
   - Known biology test cases (BRCA1 → DDR, KRAS → MAPK)
   - Manager-approved formula validation
   - Code reference verification patterns

### What DOES NOT EXIST (Needs Building)

1. **MM Doctrine Endpoints**: NONE found
   - No `/api/recruitment/*` endpoints
   - No `/api/tcf1/*` endpoints
   - No `/api/tls/*` endpoints
   - No `/api/tox/*` or `/api/triad/*` endpoints

2. **Pathway Score Extractor**: Not found as standalone utility
   - Pathway scores exist internally in orchestrator
   - No utility to extract from efficacy response for downstream use

3. **Deconvolution Service**: CIBERSORT/TIMER2 integration not found

4. **NetMHCpan Integration**: Not found

5. **Spatial Data Processing**: Visium/CODEX parsers not found

---

## Phase 0: Foundation Validation (Week 0 - IMMEDIATE)

**Goal:** Validate current system capabilities and create blocking dependencies before Phase 1.

### Task 0.1: Verify/Complete Mechanism Vector Conversion Function (P0 - BLOCKING)

**Current State:**
- File exists: `api/services/pathway_to_mechanism_vector.py` (empty or incomplete)
- Referenced in: `api/routers/advanced_trial_queries.py:164`
- Expected by: `tests/test_advanced_trial_queries.py:70` (test exists)

**Code References:**
- Mechanism vector structure: `api/services/sae_feature_service.py:206-214`
- IO eligibility logic: `api/services/sae_feature_service.py:200`
- Mechanism fit ranker: `api/services/mechanism_fit_ranker.py:89` (expects 7D List[float])
- Advanced trial queries usage: `api/routers/advanced_trial_queries.py:155-172`

**Implementation Pattern (from MBD4+TP53 plan):**
- DDR: `ddr + 0.5 * tp53` (TP53 contributes 50% to DDR)
- MAPK: `ras_mapk`
- PI3K: `pi3k`
- VEGF: `vegf`
- HER2: `her2` (default 0.0)
- IO: `1.0 if (tmb >= 20 or msi_high) else 0.0`
- Efflux: `cross_resistance_risk` (default 0.0)

**Expected Interface (from advanced_trial_queries.py:166):**
```python
mechanism_vector, provenance = convert_pathway_scores_to_mechanism_vector(
    pathway_scores=pathway_scores,
    tumor_context=tumor_context,
    use_7d=False  # Default to 6D, auto-detects 7D if HER2 present
)
```

**Test Checkpoint:**
- Verify existing test: `tests/test_advanced_trial_queries.py:70`
- Test with known pathway scores → verify 7D vector format
- Test IO eligibility logic (TMB/MSI thresholds)
- Test TP53 contribution to DDR (50% rule)

**Validation Gate:** Function exists, passes existing tests, and matches expected interface.

---

### Task 0.2: Create Pathway Score Extraction Utility (P0 - CRITICAL)

**Issue:** MM doctrines need to extract pathway scores from `/api/efficacy/predict` responses for downstream use.

**Code Reference (Actual Structure):**
- Pathway scores computed: `api/services/efficacy_orchestrator/orchestrator.py:105`
- Pathway scores passed to SAE: `api/services/efficacy_orchestrator/orchestrator.py:360` as `pathway_disruption=pathway_scores`
- Pathway scores structure: `Dict[str, float]` (e.g., `{"ddr": 0.5, "ras_mapk": 0.3}`)
- **NOT in confidence_breakdown**: That's S/P/E contributions, not raw pathway scores

**Implementation Pattern (from Ayesha universalization plan Q2):**
- Extract from SAE features if available: `response.sae_features.pathway_burden_*`
- Extract from rationale breakdown (limited): `response.drugs[0].rationale` (only ras_mapk, tp53)
- Extract from calibration snapshot: `response.provenance.calibration_snapshot.pathway_scores`
- Priority: SAE features > calibration snapshot > rationale breakdown

**Files to Create:**
- `oncology-coPilot/oncology-backend-minimal/api/services/pathway_score_extractor.py`

**Test Checkpoint:**
- Create `tests/test_pathway_score_extractor.py`
- Test extraction from mock efficacy response with SAE features
- Test extraction from rationale breakdown (fallback)
- Test extraction from calibration snapshot (fallback)
- Test priority order (SAE > calibration > rationale)

**Validation Gate:** Extraction utility works and handles all response structures.

---

### Task 0.3: Create Known Biology Validation Test Suite (P0 - CRITICAL)

**Reference:** SOTA benchmarks plan shows test cases for BRCA1 (DDR), KRAS (MAPK), HER2 (HER2 pathway).

**Test Pattern (from test_sae_phase2_services.py):**
- Known biology assertions: BRCA1 → high DDR, KRAS → high MAPK
- Manager-approved formula validation
- Code reference verification

**Files to Create:**
- `tests/test_mm_doctrines_known_biology.py`

**Test Cases (Placeholder Structure - Implement When Endpoints Built):**
1. **T-Cell Recruitment**: High chemokine signature → responder prediction
   - Known biology: CXCL9/CXCL10 high → checkpoint responder
   - Test: Verify recruitment_score > 0.6 for high chemokine tumors

2. **TCF1/Tox Signature**: High TCF1 + High Tox → checkpoint responder
   - Known biology: TCF1-high CD8 cells → better persistence
   - Test: Verify tcf1_tox_score > 0.7 for responder phenotype

3. **TLS Readiness**: High C-MSC sabotage → low TLS score
   - Known biology: C-MSC infiltration → TLS suppression
   - Test: Verify sabotaged_stroma_score > 0.6 → tls_readiness_score < 0.4

**Validation Gate:** Test suite structure created, ready for implementation when endpoints built.

---

## Phase 1: Foundation - Proxy Classifiers (Weeks 1-6)

**Goal:** Build defensible, literature-validated predictors using public data. No partner dependencies.

### Week 1-2: T-Cell Recruitment Proxy (`/api/recruitment/predict_response_proxy`)

**Pattern to Follow (Code-Verified):**
- Router pattern: `api/routers/care.py:30-93` (Pydantic BaseModel Request/Response schemas)
- Service pattern: `api/services/resistance_playbook_service.py:30-73` (dataclass-based service)
- Schema pattern: `api/schemas/safety.py` (Pydantic models with Field descriptions)
- Error handling: `api/routers/care.py:229-234` (HTTPException with logging)

**Code References:**
- Router structure: `api/routers/care.py:22-23` (APIRouter with prefix and tags)
- Service call: `api/routers/care.py:174` (call service function, convert to response models)
- Response conversion: `api/routers/care.py:183-227` (convert dataclasses to Pydantic models)

**Tasks:**
1. **TCGA Data Access:** Check if existing TCGA extractors exist
   - Search for "tcga" in codebase
   - If not: Use cBioPortal API or download from GDC
   - Extract chemokine signatures (CXCL9, CXCL10, CCL5, CCR5, CXCR3) from bulk RNA-seq

2. **Literature Meta-Analysis:** Use existing `api/services/evidence/literature_client.py` pattern
   - Code Reference: `api/services/evidence/literature_client.py:51-66` (async literature function)
   - Aggregate checkpoint response rates from 10+ published studies
   - Store in structured format (JSON or database)

3. **Train Classifier:** Logistic regression (scikit-learn)
   - Chemokine-high → responder prediction
   - Validate correlation with survival (target: r > 0.40)

4. **Build API Endpoint:** Follow `care.py` router pattern
   - Request: `RecruitmentProxyRequest` (bulk_rnaseq, disease_type)
   - Response: `RecruitmentProxyResponse` (recruitment_score, bottleneck_prediction, confidence, rationale, provenance)
   - Confidence flag: MED (r = 0.3-0.5)

**Test Checkpoint 1.1:**
- Create `tests/test_recruitment_proxy_classifier.py`
- Test with known biology case (high chemokine → responder)
- Test with low chemokine case (non-responder)
- Verify confidence flags (MED for r = 0.3-0.5)

**Validation Gate:** Endpoint operational, tests pass, known biology validated.

---

### Week 2-3: TCF1/Tox Signature (`/api/tcf1/predict_phenotype_proxy`)

**Gap Identified:**
- **Deconvolution Service:** CIBERSORT/TIMER2 integration NOT found in codebase
- **Solution:** Build lightweight deconvolution wrapper OR use existing Python packages (CIBERSORTx, TIMER2)

**Tasks:**
1. **Deconvolution Integration:**
   - Option A: Use CIBERSORTx Python package (if available)
   - Option B: Build wrapper around CIBERSORT web API (if needed)
   - Option C: Use TIMER2 (simpler, fewer cell types)
   - Extract TIL fractions from TCGA bulk RNA-seq

2. **Gene Expression Extraction:**
   - Extract TCF1 (TCF7), Tox, RORγt, IL-23R expression from TIL populations
   - Use existing gene expression processing patterns

3. **Literature Meta-Analysis:** Reuse `literature_client.py`
   - Code Reference: `api/services/evidence/literature_client.py:51-66`
   - Search: "TCF1 checkpoint response" (15+ studies)
   - Aggregate outcomes data

4. **Train Signature:** Logistic regression
   - High TCF1 + High Tox → responder
   - Low TCF1 + Low Tox → non-responder
   - Validate against published checkpoint trial cohorts (target: r > 0.50)

5. **Build API Endpoint:** Follow same pattern as recruitment

**Test Checkpoint 2.1:**
- Create `tests/test_tcf1_signature_classifier.py`
- Test with known biology case (high TCF1 + high Tox → responder)
- Test with low TCF1 + low Tox → non-responder
- Verify confidence flags (HIGH for r > 0.50)

**Validation Gate:** Endpoint operational, tests pass, known biology validated.

---

### Week 3-4: TLS Readiness Score v1 (`/api/tls/score_readiness_v1`)

**Gap Identified:**
- **Spatial Data Processing:** No spatial transcriptomics tools found
- **Solution:** Build basic Visium/CODEX parser OR use existing Python packages (scanpy, squidpy)

**Tasks:**
1. **Spatial Data Access:**
   - Download MSK public Visium datasets (GEO, partial access)
   - Build parser for Visium H5 format (use scanpy or squidpy)
   - Extract TLS density, GC counts from spatial annotations

2. **Bulk RNA Matching:**
   - Match spatial data to bulk RNA-seq (same patient samples)
   - Use patient ID or sample ID matching

3. **Train Model:** Logistic regression
   - Bulk gene signatures → TLS/GC probability
   - Features: B-cell markers, T-cell markers, C-MSC signatures, FDC markers

4. **Validate on TCGA:**
   - Does predicted TLS score correlate with survival? (target: r > 0.35)
   - Use existing survival data processing (if available)

5. **Build API Endpoint:** Same pattern

**Test Checkpoint 3.1:**
- Create `tests/test_tls_readiness_scorer.py`
- Test with known biology case (high C-MSC sabotage → low TLS score)
- Test with low sabotage → high TLS score
- Verify confidence flags (LOW for bulk proxy only)

**Validation Gate:** Endpoint operational, tests pass, known biology validated.

---

## Phase 2: Design Tools - 12 Endpoints (Weeks 5-10)

**Goal:** Build all design tool endpoints. Reuse existing design router patterns.

### Enhanced Pattern: Test-Driven Design Tool Development

**Reference:** Ayesha universalization plan shows test checkpoints after each implementation step.

**Code References:**
- Design router: `api/routers/design.py:14` (APIRouter with prefix `/api/design`)
- Feature flag check: `api/routers/design.py:17-21` (`_ensure_enabled()` pattern)
- Evo2 integration: `api/routers/design.py:87-100` (httpx.AsyncClient to `/api/evo/score`)
- Provenance tracking: `api/routers/design.py:262-276` (SpacerEfficacyProvenance pattern)

**For Each Design Tool Endpoint:**

1. **Create Service Module** (e.g., `api/services/design/chemokine_cassette.py`)
2. **Create Test Checkpoint** (e.g., `tests/test_chemokine_cassette.py`)
3. **Validate Against Known Biology** (if applicable)
4. **Integration Test** (end-to-end with Evo2, safety service)

**Example: `/api/design/generate_chemokine_cassette`**

**Code References:**
- Evo2 API call: `api/routers/design.py:87-100` (httpx.AsyncClient pattern)
- Safety preview: `api/services/safety_service.py:59-91` (off_target_preview endpoint)
- Provenance: `api/routers/design.py:262-276` (provenance tracking pattern)

**Test Checkpoint 4.1:**
- Create `tests/test_chemokine_cassette.py`
- Test Evo2 integration (codon optimization)
- Test safety preview integration
- Test promoter library selection
- Verify provenance tracking

**Validation Gate:** All 12 design endpoints operational, safety-scanned, tests pass.

---

## Phase 3: TOX Doctrine Endpoints (Weeks 11-14)

### Enhanced Pattern: Mechanism Vector Integration

**Reference:** MBD4+TP53 plan shows mechanism vector needed for trial matching.

**Code References:**
- Mechanism vector structure: `api/services/sae_feature_service.py:206-214`
- Mechanism fit ranker: `api/services/mechanism_fit_ranker.py:77-172` (rank_trials method)
- Pathway score extraction: Use `pathway_score_extractor.py` from Phase 0
- Mechanism vector conversion: Use `pathway_to_mechanism_vector.py` from Phase 0

**For `/api/triad/score_architecture`:**

1. **Compute Triad Scores** (lethal, suppressive, net cytotoxicity)
2. **Extract Pathway Scores** (use pathway_score_extractor from Phase 0)
3. **Convert to Mechanism Vector** (use pathway_to_mechanism_vector from Phase 0)
4. **Return with Provenance** (include mechanism vector in response)

**Test Checkpoint 5.1:**
- Create `tests/test_triad_scorer.py`
- Test triad score computation
- Test mechanism vector conversion
- Test confidence flags (LOW/MED/HIGH based on data type)

**Validation Gate:** TOX endpoints operational, mechanism vector integration verified.

---

## Phase 4: Orchestration & Unified Flows (Weeks 15-18)

### Enhanced Pattern: Code Reference Verification

**Reference:** Ayesha universalization plan emphasizes code reference verification (file:line).

**Code References:**
- Orchestrator pattern: `api/services/efficacy_orchestrator/orchestrator.py:40-48` (class-based orchestrator)
- Service coordination: `api/services/efficacy_orchestrator/orchestrator.py:94-105` (sequence → pathway → evidence)
- Error handling: `api/services/efficacy_orchestrator/orchestrator.py` (try/except with logging)

**For Each Orchestrator:**

1. **Document Code References** (file:line for each service call)
2. **Create Integration Tests** (end-to-end with all services)
3. **Validate Data Flow** (capture actual input→output at each stage)

**Example: `/api/recruitment/orchestrate`**

**Code References:**
- Orchestrator class: `api/services/efficacy_orchestrator/orchestrator.py:40-48`
- Service calls: `api/services/efficacy_orchestrator/orchestrator.py:94-105`
- Response structure: `api/services/efficacy_orchestrator/models.py:35-45`

**Test Checkpoint 6.1:**
- Create `tests/test_recruitment_orchestrator.py`
- Test complete flow: bottleneck diagnostic → C-MSC mining → cassette design → safety gates
- Verify code references (document file:line for each service)
- Capture actual input→output for verification

**Validation Gate:** All orchestrators operational, code references documented, integration tests pass.

---

## Phase 5: Tier 1 Feedback Infrastructure (Weeks 19-20)

### Enhanced Pattern: Benchmark Dataset Creation

**Reference:** Proxy SAE validation plan shows benchmark dataset structure.

**Code References:**
- Calibration pattern: `api/services/compound_calibration.py` (calibration service pattern)
- Provenance tracking: `api/services/efficacy_orchestrator/orchestrator.py:330-339` (provenance structure)

**For Feedback Database:**

1. **Create Benchmark Dataset** (`data/validation/mm_doctrines_benchmark.json`)
2. **Structure Test Cases** (known biology cases for each doctrine)
3. **Validation Metrics** (accuracy, correlation, confidence calibration)

**Test Checkpoint 7.1:**
- Create `tests/test_feedback_infrastructure.py`
- Test feedback ingestion APIs
- Test calibration updates
- Test immutable provenance

**Validation Gate:** Feedback infrastructure operational, benchmark dataset created, validation metrics reported.

---

## Phase 6: Spatial/Timestamp Integration (Weeks 21-24)

### Enhanced Pattern: Validation Test Suite

**Reference:** SOTA benchmarks plan shows comprehensive test suite structure.

**For Spatial Validation:**

1. **Create Validation Test Suite** (`tests/test_spatial_validation.py`)
2. **Test Confidence Upgrades** (LOW → MED → HIGH with spatial data)
3. **Test Known Biology Cases** (spatial TLS density → survival correlation)

**Validation Gate:** Spatial validation operational, confidence upgrades verified, test suite passes.

---

## Implementation Dependencies - Code-Verified

### Reusable Services (Confirmed Exist)

- **Evo2 API:** `/api/evo/*` (operational)
  - Pattern: `api/services/sequence_scorers/evo2_scorer.py:14-334`
  - Code Reference: `api/routers/design.py:87-100` (httpx.AsyncClient to `/api/evo/score`)

- **Safety Service:** `/api/safety/*` (operational)
  - Pattern: `api/services/safety_service.py:26-167`
  - Code Reference: `api/routers/safety.py:29-56` (toxicity_risk endpoint)

- **Literature Client:** `api/services/evidence/literature_client.py` (exists)
  - Code Reference: `api/services/evidence/literature_client.py:51-66` (async literature function)

- **Pathway Aggregation:** `api/services/pathway/aggregation.py` (exists)
  - Code Reference: `api/services/pathway/aggregation.py:7-45` (aggregate_pathways function)

- **Mechanism Fit Ranker:** `api/services/mechanism_fit_ranker.py` (exists)
  - Code Reference: `api/services/mechanism_fit_ranker.py:77-172` (rank_trials method)

### Services That Need Verification/Completion

- **Mechanism Vector Conversion:** `api/services/pathway_to_mechanism_vector.py` (EXISTS but may be empty - verify first)
- **Pathway Score Extractor:** `api/services/pathway_score_extractor.py` (NEW - Phase 0)

### New Services Needed (Phase 0 Blockers)

- **Deconvolution Service:** CIBERSORT/TIMER2 wrapper (NEW - Phase 1)
- **NetMHCpan Integration:** MHC binding prediction (NEW - Phase 3)
- **Spatial Data Processing:** Visium/CODEX parsers (NEW - Phase 1)

---

## Success Criteria - Code-Verified

### Phase 0 (Foundation Validation)

- Mechanism vector conversion function verified/complete and passes tests
- Pathway score extractor exists and passes tests
- Known biology test suite created and baseline tests pass

### Phase 1 (Proxy Classifiers)

- 3 APIs operational with confidence flags
- TCGA validation complete (r > 0.35 for all)
- Literature meta-analysis complete (using existing literature client)
- Known biology validation tests pass

### Phase 2 (Design Tools)

- 12 endpoints operational
- Safety-scanned (using existing safety service + heuristics)
- All designs include provenance + RUO disclaimers
- Test checkpoints pass for each endpoint

### Phase 3 (TOX Endpoints)

- 7 TOX APIs operational
- Mechanism vector integration verified
- Test checkpoints pass

### Phase 4 (Orchestration)

- 3 orchestrators operational
- Code references documented (file:line)
- Integration tests pass

### Phase 5 (Feedback)

- Feedback ingestion APIs operational
- Benchmark dataset created
- Validation metrics reported

### Phase 6 (Spatial/Timestamp)

- Spatial validation operational
- Confidence upgrades verified
- Test suite passes

---

## Key Learnings Integrated from 4 Plans

### From MBD4+TP53 Analysis Plan

1. **Pathway Score Extraction Pattern:**
   - Pathway scores passed to SAE as `pathway_disruption` (orchestrator.py:360)
   - NOT in `confidence_breakdown` (that's S/P/E contributions)
   - Structure: `Dict[str, float]` with lowercase underscores

2. **Mechanism Vector Conversion Pattern:**
   - DDR: `ddr + 0.5 * tp53` (TP53 contributes 50% to DDR)
   - IO: `1.0 if (tmb >= 20 or msi_high) else 0.0`
   - 7D vector: `[DDR, MAPK, PI3K, VEGF, HER2, IO, Efflux]`

3. **Endpoint Integration Pattern:**
   - Use existing router/service/schema patterns
   - Follow proven error handling patterns
   - Include provenance tracking

### From SOTA Benchmarks Plan

1. **Test-Driven Development:**
   - Validation gates at each phase
   - Known biology test cases (BRCA1 → DDR, KRAS → MAPK)
   - Benchmark dataset structure

2. **Validation Methodology:**
   - Test with known biology cases first
   - Verify confidence flags match expected ranges
   - Document actual vs expected results

3. **Success Criteria:**
   - Clear metrics (AUROC, correlation, accuracy)
   - Minimum vs target thresholds
   - Regression prevention

### From Ayesha Universalization Plan

1. **Code Reference Verification:**
   - Document file:line for all patterns
   - Verify against actual code structure
   - No assumptions - code evidence required

2. **Test Checkpoint Methodology:**
   - Test after each implementation step
   - Capture actual input→output
   - Verify against code references

3. **Baseline Verification:**
   - Test current behavior first (if applicable)
   - Document what works vs what's broken
   - Then enhance/fix

4. **Mutation Format Validation:**
   - Normalize mutations to WIWFM format
   - Handle gene lists, mutation dicts, HGVS strings
   - Validate structure before processing

### From Proxy SAE Validation Plan

1. **Benchmark Dataset Structure:**
   - Known biology test cases
   - Expected vs computed comparisons
   - Validation metrics framework

2. **8-Question Clinical Framework:**
   - Variant impact prediction
   - Functional annotation
   - Pathway analysis
   - Drug prediction
   - Trial matching
   - Metastasis prediction
   - Immunogenicity
   - Nutritional therapies

3. **Validation Metrics:**
   - Accuracy (vs known biology)
   - Correlation (vs clinical outcomes)
   - Confidence calibration

---

## Critical Corrections from Plan Review

### Correction 1: Pathway Score Extraction Location

**Original Plan Assumption:** Extract from `confidence_breakdown["pathway_disruption"]`

**Actual Code Structure:**
- Pathway scores computed: `orchestrator.py:105`
- Pathway scores passed to SAE: `orchestrator.py:360` as `pathway_disruption=pathway_scores`
- `confidence_breakdown` structure: S/P/E contributions, NOT raw pathway scores

**Corrected Approach:**
- Extract from SAE features: `response.sae_features.pathway_burden_*`
- Extract from calibration snapshot: `response.provenance.calibration_snapshot.pathway_scores`
- Extract from rationale breakdown (limited): `response.drugs[0].rationale` (only ras_mapk, tp53)

### Correction 2: Mechanism Vector Service Status

**Original Plan Assumption:** Function doesn't exist

**Actual Code State:**
- File exists: `api/services/pathway_to_mechanism_vector.py` (may be empty)
- Referenced in: `api/routers/advanced_trial_queries.py:164`
- Test exists: `tests/test_advanced_trial_queries.py:70`

**Corrected Approach:**
- **First**: Verify what exists in the file
- **Then**: Complete implementation to match expected interface
- **Verify**: Existing test passes

### Correction 3: Test-Driven Development Pattern

**Original Plan:** Create tests after implementation

**Corrected Approach (from Ayesha plan):**
- **Baseline Verification**: Test current behavior first (if applicable)
- **Test Checkpoints**: After each implementation step
- **Code Reference Verification**: Verify against actual code structure
- **Known Biology Tests**: Use proven biology cases (BRCA1, KRAS, HER2)

---

## Next Steps - Immediate Actions (Planning Phase)

1. **Verify Current State:**
   - Check `api/services/pathway_to_mechanism_vector.py` - what exists?
   - Verify `tests/test_advanced_trial_queries.py:70` - what does it test?
   - Check pathway score extraction patterns in actual code

2. **Document Actual Patterns:**
   - Map actual pathway score flow (orchestrator → SAE)
   - Document mechanism vector usage in existing code
   - Identify test patterns from existing test files

3. **Create Enhanced Plan:**
   - Integrate verified patterns from 4 plans
   - Add code references (file:line) for all patterns
   - Include baseline verification steps
   - Add test checkpoint methodology

---

**Status:** Planning phase - pattern synthesis complete, ready for implementation planning
