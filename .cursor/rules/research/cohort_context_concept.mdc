---
alwaysApply: false
description: Cohort Context ‚Äì Execution Doctrine (Sept 2025). Plain‚Äëlanguage website copy + execution plan for in‚Äësilico cohort overlays (study selection, metrics, artifacts, mapping) with JSON schemas (RUO).                                
globs: 
---

# Cohort Context Concept - Data Source Integration

## Overview
This document defines the execution doctrine for cohort data acquisition, validation, and integration across multiple data sources for biomarker validation (e.g., KELIM Resurrection).

## Data Sources

### 1. cBioPortal
**Stat‚úÖ Integrated
**Client:** `scripts/data_acquisition/utils/cbioportal_client.py`
**Capabilities:**
- List studies by cancer type
- Extract clinical data (biomarkers, outcomes)
- Patient-level mutation data
- Clinical attributes scanning

**Usage:**
```python
from scripts.data_acquisition.utils.cbioportal_client import CBioportalClient
client = CBioportalClient()
studies = client.list_studies()
clinical = client.get_clinical_data(study_id, entity_type="PATIENT")
```

### 2. ClinicalTrials.gov
**Status:** ‚úÖ Integrated
**Client:** `api/services/ctgov_query_builder.py`
**Capabilities:**
- Multi-criteria trial search
- PI contact extraction
- Trial metadata (phase, status, enrollment)
- Site information

**Usage:**
```python
from api.services.ctgov_query_builder import CTGovQueryBuilder, execute_query
builder = CTGovQueryBuilder()
builder.add_condition("ovarian cancer").add_keyword("CA-125")
trials = await execute_query(builder, max_results=1000)
```

### 3. PubMed / pubmearch
**Status:** ‚úÖ Integrated
**Fram** `.github/frameworks/pubmearch-main/`
**Capabilities:**
- Advanced literature search
- Keyword analysis
- Trend tracking
- Researcher identification

**Usage:**
```python
from api.services.research_intelligence.portals.pubmed_enhanced import EnhancedPubMedPortal
portal = EnhancedPubMedPortal()
results = portal.search_kelim_researchers()
```

### 4. Project Data Sphere ‚≠ê NEW
**Status:** ‚úÖ Connected & Explored
**Client:** `scripts/data_acquisition/utils/project_data_sphere_client.py`
**Authentication:** SAS CAS API (username: `mpm0fxk2`, password: PDS password)
**CAS URL:** `https://mpmprodvdmml.ondemand.sas.com/cas-shared-default-http/`
**SSL Certificate:** `/Users/fahadkiani/Desktop/development/crispr-assistant-main/data/certs/trustedcerts.pem`

**Capabilities:**
- Access to 102 caslibs (data libraries)
- Clinical trial patient-level data
- De-identified clinical datasets
- Case report forms and data dictionaries
- Table loading and data extraction

**Current Findings:**
- **Total Caslibs:** 102
- **Cr Types:** Prostate (19), Breast (17), Colorectal (16), Lung (15), Pancreatic (6), Multiple (6), Others (19)
- **Ovarian Cancer:** No dedicated caslibs found
- **Note:** Ovarian cancer data may be in "Multiple" caslibs or require searching clinical data tables

**Usage:**
```python
from scripts.data_acquisition.utils.project_data_sphere_client import ProjectDataSphereClient

client = ProjectDataSphereClient(
    cas_url="https://mpmprodvdmml.ondemand.sas.com/cas-shared-default-http/",
    ssl_cert_path="/path/to/trustedcerts.pem"
)

if client.connect(username="mpm0fxk2", password="your_password"):
    # List all caslibs
    caslibs = client.list_caslibs()
    
    # List files in a caslib
    files = client.list_files_in_caslib("caslib_name")
    
    # Search for ovarian cancer data
    ovarian_data = client.search_for_ovarian_cancer_data()
    
    # Load a table (example)
    # core_train = client.conn.CASTable('core_train', replace=True, caslib='CASUSER')
    # client.conn.table.loadTable(
    #     sourceCaslib="caslib_name",
    #     casOut=core_train,
    #     path="path/to/file.csv"
    # )
    # print(core_train.head())
    # core_train.to_csv('output.csv')
    
    client.disconnect()
```

**Data Structure:**
- **Caslibs:** Data libraries organized by cancer type and sponsor
- **Format:** `CancerType_Sponsor_Year_ID` (e.g., `Breast_Pfizer_2006_112`)
- **File Types:** CSV, SAS datasets (.sas7bdat), PDFs (case report forms), Excel, Word docs
- **Tables:** Clinical data, biomarker data, outcomes, case report forms

**Implementation Plan for Another Agent:**

#### Phase 1: Data Discovery (2-3 hours)
1. **Explore "Multiple" Caslibs**
   - List all files in "Multiple" cancer type caslibs
   - Check data dictionaries for ovarian cancer mentions
   - Identify potential ovarian cancer datasets

2. **Search Clinical Data Tables**
   - Load sample tables from accessible caslibs
   - Examine column names for CA-125, PFI, ovarian cancer indicators
   - Create mapping of available fields

3. **Data Dictionary Review**
   - Extract data dictionaries from caslibs
   - Map field names to KELIM requirements (CA-125, PFI)
   - Identify data quality and completeness

#### Phase 2: Data Extraction (3-4 hours)
4. **Table Loading Pipeline**
   - Create function to load tables from caslibs
   - Handle different file formats (CSV, SAS)
   - Convert to standardized JSON format

5. **CA-125 Data Extraction**
   - Search for CA-125 columns across all tables
   - Extract serial CA-125 measurements
   - Validate data quality (missing values, outliers)

6. **PFI Outcome Extraction**
   - Extract platinum-free interval from clinical data
   - Calculate PFI from treatment dates if needed
   - Validate PFI < 6 months threshold

#### Phase 3: Integration (2-3 hours)
7. **Data Schema Mapping**
   - Map Project Data Sphere fields to KELIM validation schema
   - Create transformation functions
   - Handle data type conversions

8. **Quality Validation**
   - Check data completeness
   - Validate CA-125 measurement frequency
   - Verify PFI calculation accuracy

9. **Integration with Validation Harness**
   - Convert extracted data to validation harness format
   - Create cohort artifacts
   - Generate data quality reports

**Deliverables:**
- `project_data_sphere_extractor.py` - Main extraction script
- `pds_data_mapping.json` - Field mapping schema
- `pds_ovarian_cohorts.json` - Extracted ovarian cancer cohorts
- `pds_data_quality_report.json` - Data quality assessment

**Next Steps:**
1. Explore "Multiple" caslibs for ovarian cancer data
2. Load and examine sample clinical data tables
3. Create extraction pipeline for CA-125 and PFI data
4. Integrate with existing validation harness

## Data Source Prioritization

**For KELIM Validation:**
1. **Project Data Sphere** - High priority if ovarian data found in "Multiple" caslibs
2. **cBioPortal** - Medium priority (no CA-125 found in initial scan)
3. **ClinicalTrials.gov** - High priority for PI outreach
4. **PubMed** - Medium priority for researcher identification

## Integration Pattern

All data sources follow this pattern:
1. **Discovery** - List/search available data
2. **Extraction** - Load and parse data
3. **Transformation** - Map to validation schema
4. **Validation** - Quality checks
5. **Integration** - Feed into validation harness

## JSON Schema (RUO)

```json
{
  "cohort": {
    "source": "project_data_sphere",
    "caslib": "caslib_name",
    "study_id": "study_identifier",
    "patients": [
      {
        "patient_id": "P001",
        "ca125_measurements": [
          {"day": 0, "value": 450.0},
          {"day": 21, "value": 320.0},
          {"day": 42, "value": 280.0}
        ],
        "pfi_months": 4.5,
        "pfi_category": "resistant",
        "treatment": "carboplatin + paclitaxel"
      }
    ],
    "metadata": {
      "extraction_date": "2025-01-28",
      "data_quality": "high",
      "completeness": 0.85
    }
  }
}
```
---

## üß¨ Pharmacogenomics Data Acquisition (Dosing Guidance Validation)

**Status:** Production-Ready  
**Added:** January 2025  
**Purpose:** Support dosing guidance validation through framework integration

### Overview

The Cohort Context Framework has been extended to support **pharmacogenomics data acquisition** for dosing guidance validation. This enables reuse of existing infrastructure (PubMed, cBioPortal, Project Data Sphere) for extracting pharmacogene variants, treatment history, and toxicity outcomes.

### Extended Capabilities

#### 1. PubMed Portal - Pharmacogenomics Search

**Location:** `api/services/resech_intelligence/portals/pubmed_enhanced.py`

**New Method:**
```python
def search_pharmacogenomics_cases(
    self,
    gene: str,
    drug: str,
    max_results: int = 50
) -> List[Dict]:
    """
    Search PubMed for pharmacogenomics case reports.
    
    Args:
        gene: Pharmacogene symbol (e.g., "DPYD", "UGT1A1", "TPMT")
        drug: Drug name (e.g., "fluoropyrimidine", "irinotecan")
        max_results: Maximum number of results to return
    
    Returns:
        List of PubMed results with abstracts
    """
    query = f'"{gene} deficiency" AND "{drug}" AND "case report"'
    return self.search(query, max_results=max_results)
```

**Usage Example:**
```python
from api.services.research_intelligence.portals.pubmed_enhanced import EnhancedPubMedPortal

portal = EnhancedPubMedPortal()
dpyd_cases = portal.search_pharmacogenomics_cases(
    gene="DPYD",
    drug="fluoropyrimidine",
    max_results=50
)
```

**Production Features:**
- ‚úÖ Rate limiting (3 requests/second)
- ‚úÖ Automatic retrieth exponential backoff
- ‚úÖ Error handling and graceful degradation
- ‚úÖ Provenance tracking (query, timestamp, result count)

---

#### 2. cBioPortal Client - Pharmacogene Filtering

**Location:** `scripts/data_acquisition/utils/cbioportal_client.py`

**New Method:**
```python
def filter_pharmacogenes(
    self,
    study_id: str,
    genes: List[str] = ['DPYD', 'UGT1A1', 'TPMT']
) -> Dict:
    """
    Extract patients with pharmacogene variants from a study.
    
    Args:
        study_id: cBioPortal study ID (e.g., "msk_impact_2017")
        genes: List of pharmacogene symbols to filter
    
    Returns:
        Dictionary with filtered patient data and variant information
    """
    clinical = self.get_clinical_data(study_id, entity_type="PATIENT")
    molecular = self.get_molecular_data(study_id, molecular_profile_id="mutations")
    
    # Filter for pharmacogene variants
    filtered_patients = []
    for patient in clinical:
        patient_id = patient.get('PATIENT_ID')
        variants =for v in molecular if v.get('PATIENT_ID') == patient_id 
                   and v.get('HUGO_SYMBOL') in genes]
        if variants:
            filtered_patients.append({
                'patient_id': patient_id,
                'clinical': patient,
                'variants': variants
            })
    
    return {
        'study_id': study_id,
        'pharmacogenes': genes,
        'patients': filtered_patients,
        'count': len(filtered_patients)
    }
```

**Usage Example:**
```python
from scripts.data_acquisition.utils.cbioportal_client import CBioportalClient

client = CBioportalClient()
msk_studies = [s for s in client.list_studies() if 'msk_impact' in s['study_id'].lower()]

for study in msk_studies:
    pharmacogene_data = client.filter_pharmacogenes(
        study_id=study['study_id'],
        genes=['DPYD', 'UGT1A1', 'TPMT']
    )
    print(f"Found {pharmacogene_data['count']} patients with pharmacogene variants")
```

**Production Features:**
- ‚úÖ Standardized API interface
- ‚úÖ Error hing for missing studies
- ‚úÖ Data quality validation
- ‚úÖ Provenance tracking

---

#### 3. Extended Cohort Schema - Pharmacogenomics Fields

**Extended JSON Schema:**
```json
{
  "cohort": {
    "source": "cbioportal",
    "study_id": "msk_impact_2017",
    "patients": [
      {
        "patient_id": "P001",
        "pharmacogenomics": {
          "gene": "DPYD",
          "variant": "c.1905+1G>A (*2A)",
          "zygosity": "heterozygous",
          "predicted_phenotype": "Intermediate Metabolizer",
          "pharmvar_id": "DPYD*2A",
          "cpic_level": "A"
        },
        "treatment": {
          "drug": "5-fluorouracil",
          "standard_dose": "400 mg/m¬≤",
          "actual_dose_given": "400 mg/m¬≤",
          "dose_reduction": false,
          "dose_reduction_reason": null
        },
        "outcome": {
          "toxicity_occurred": true,
          "toxicity_grade": 4,
          "toxicity_type": "neutropenia",
          "toxicity_onset_days": 7,
          "hospitalization_required": t      }
      }
    ],
    "metadata": {
      "extraction_date": "2025-01-28",
      "data_quality": "high",
      "completeness": 0.95,
      "source_version": "cbioportal_v3.0"
    }
  }
}
```

**Schema Validation:**
- ‚úÖ Required fields: `gene`, `variant`, `drug`, `outcome`
- ‚úÖ Optional fields: `pharmvar_id`, `cpic_level`, `dose_reduction_reason`
- ‚úÖ Data quality scoring: `completeness` (0.0-1.0)
- ‚úÖ Provenance tracking: `extraction_date`, `source_version`

---

#### 4. GDC Client (New Addition)

**Location:** `scripts/data_acquisition/utils/gdc_client.py` (NEW)

**Implementation Pattern:**
```python
class GDCClient:
    """
    Client for GDC (Genomic Data Commons) API.
    Follows same pattern as CBioportalClient and ProjectDataSphereClient.
    """
    
    def __init__(self, api_base: str = "https://api.gdc.cancer.gov"):
        self.api_base = api_base
        self.session = httpx.AsyncClient(timeout=60.0)
    
    async def query_projects(self, disease_type: str = None) -> List[Dict]: """List available GDC projects."""
        # Implementation follows framework pattern
    
    async def query_variants(
        self,
        gene: str,
        project: str,
        variant_type: str = "germline"
    ) -> List[Dict]:
        """Query variants for a specific gene in a project."""
        # Implementation follows framework pattern
```

**Production Features:**
- ‚úÖ Standardized interface (matches framework pattern)
- ‚úÖ Async/await for performance
- ‚úÖ Error handling and retries
- ‚úÖ Provenance tracking

---

### Integration Pattern for Pharmacogenomics

The framework's **5-step integration pattern** applies to pharmacogenomics data:

1. **Discovery:** Search PubMed for case reports, list cBioPortal studies with pharmacogenomics data
2. **Extraction:** Extract case details from PubMed abstracts, extract variants from cBioPortal/GDC
3. **Transformation:** Map to extended cohort schema with pharmacogenomics fields
4. **Validation:** Validate variant nomenclature (PharmVar ali treatment-outcome linkage
5. **Integration:** Feed validation cases into metrics calculator

### Use Cases

1. **Dosing Guidance Validation:** Extract literature cases and public dataset cases for validation
2. **Pharmacogenomics Research:** Query multiple data sources for pharmacogene-drug interactions
3. **Clinical Decision Support:** Integrate pharmacogenomics data into dosing recommendations

### Documentation

- **Integration Analysis:** `.cursor/plans/COHORT_FRAMEWORK_DOSING_VALIDATION_INTEGRATION.md`
- **Validation Plan:** `.cursor/plans/DOSING_GUIDANCE_VALIDATION_PLAN.md`
- **Code Examples:** See framework integration sections in validation plan

---

**Status:** PRODUCTION-READY - All capabilities reusable and repeatable  
**Last Updated:** January 2025  
**Maintained By:** Framework team (Zo + Agent Jr)
