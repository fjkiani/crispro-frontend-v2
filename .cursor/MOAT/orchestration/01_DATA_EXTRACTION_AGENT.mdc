# ðŸ“„ MODULE 01: DATA EXTRACTION AGENT

**Purpose:** Parse uploaded files (NGS PDFs, VCF, MAF, clinical notes) and extract structured patient data  
**Priority:** ðŸ”´ CRITICAL | **Dependencies:** None | **Consumers:** All downstream agents

---

## ðŸŽ¯ MISSION

Build an intelligent data extraction agent that can:
1. Accept any file format (PDF, VCF, MAF, JSON, TXT)
2. Extract mutations, clinical data, and demographics
3. Validate data quality and flag issues
4. Output a structured `PatientProfile` object

---

## ðŸ“¥ INPUTS

### Accepted File Types

| Format | Description | Parser Needed |
|--------|-------------|---------------|
| **VCF** | Variant Call Format | Standard VCF parser |
| **MAF** | Mutation Annotation Format | Tab-delimited parser |
| **PDF** | NGS reports from labs | LLM-based extraction |
| **JSON** | Structured mutation data | JSON parser |
| **TXT/CSV** | Clinical notes, lab results | Text extraction |

### Example Input

```json
{
  "file": "binary_file_content",
  "file_type": "pdf",
  "file_name": "Foundation_One_Report.pdf",
  "metadata": {
    "lab": "Foundation Medicine",
    "report_date": "2025-01-15"
  }
}
```

---

## ðŸ“¤ OUTPUTS

### PatientProfile Schema

```python
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
from enum import Enum

class Zygosity(Enum):
    HETEROZYGOUS = "heterozygous"
    HOMOZYGOUS = "homozygous"
    HEMIZYGOUS = "hemizygous"
    UNKNOWN = "unknown"

class MutationSource(Enum):
    NGS = "ngs"
    IHC = "ihc"
    FISH = "fish"
    PCR = "pcr"
    INFERRED = "inferred"

@dataclass
class Mutation:
    gene: str
    variant: str                    # e.g., "c.1239delA" or "p.V600E"
    hgvs_c: Optional[str] = None    # Coding change
    hgvs_p: Optional[str] = None    # Protein change
    chromosome: Optional[str] = None
    position: Optional[int] = None
    ref: Optional[str] = None
    alt: Optional[str] = None
    vaf: Optional[float] = None     # Variant allele frequency
    coverage: Optional[int] = None
    zygosity: Zygosity = Zygosity.UNKNOWN
    source: MutationSource = MutationSource.NGS
    classification: Optional[str] = None  # Pathogenic, VUS, Benign

@dataclass
class GermlinePanel:
    genes_tested: List[str]
    pathogenic: Dict[str, str]      # gene -> variant
    vus: Dict[str, str]
    negative: List[str]
    panel_name: Optional[str] = None
    test_date: Optional[datetime] = None

@dataclass
class ClinicalData:
    stage: Optional[str] = None         # e.g., "IVB"
    histology: Optional[str] = None     # e.g., "high_grade_serous"
    grade: Optional[str] = None
    ecog_ps: Optional[int] = None       # Performance status
    biomarkers: Dict[str, any] = None   # CA-125, HER2, etc.
    prior_treatments: List[str] = None
    current_treatment: Optional[str] = None

@dataclass
class Demographics:
    age: Optional[int] = None
    sex: Optional[str] = None
    ethnicity: Optional[str] = None

@dataclass
class PatientProfile:
    patient_id: str
    disease: str                        # e.g., "ovarian_cancer"
    mutations: List[Mutation]
    germline_panel: Optional[GermlinePanel] = None
    clinical_data: Optional[ClinicalData] = None
    demographics: Optional[Demographics] = None
    data_quality_flags: List[str] = None  # ["ca125_missing", "hrd_pending"]
    extraction_provenance: Dict[str, any] = None  # Source, confidence, method
    created_at: datetime = None
    updated_at: datetime = None
```

---

## ðŸ—ï¸ IMPLEMENTATION

### File Structure

```
api/services/extraction/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ extraction_agent.py          # Main agent logic
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vcf_parser.py            # VCF file parsing
â”‚   â”œâ”€â”€ maf_parser.py            # MAF file parsing
â”‚   â”œâ”€â”€ pdf_parser.py            # PDF extraction with LLM
â”‚   â”œâ”€â”€ json_parser.py           # JSON parsing
â”‚   â””â”€â”€ text_parser.py           # Clinical notes extraction
â”œâ”€â”€ validators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mutation_validator.py    # Validate mutation format
â”‚   â”œâ”€â”€ gene_validator.py        # Validate gene names
â”‚   â””â”€â”€ quality_checker.py       # Data quality assessment
â”œâ”€â”€ normalizers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hgvs_normalizer.py       # Normalize HGVS notation
â”‚   â”œâ”€â”€ gene_normalizer.py       # Normalize gene symbols
â”‚   â””â”€â”€ disease_normalizer.py    # Normalize disease terms
â””â”€â”€ tests/
    â”œâ”€â”€ test_vcf_parser.py
    â”œâ”€â”€ test_pdf_parser.py
    â””â”€â”€ test_integration.py
```

### Core Agent Implementation

```python
# api/services/extraction/extraction_agent.py

from typing import Union, BinaryIO
from pathlib import Path
import logging

from .parsers import VCFParser, MAFParser, PDFParser, JSONParser, TextParser
from .validators import MutationValidator, GeneValidator, QualityChecker
from .normalizers import HGVSNormalizer, GeneNormalizer, DiseaseNormalizer
from ..models import PatientProfile, Mutation, DataQualityFlag

logger = logging.getLogger(__name__)

class DataExtractionAgent:
    """
    Intelligent agent for extracting structured patient data from various file formats.
    
    Capabilities:
    - Multi-format parsing (VCF, MAF, PDF, JSON, TXT)
    - Mutation validation and normalization
    - Data quality assessment
    - Provenance tracking
    """
    
    def __init__(self):
        # Initialize parsers
        self.parsers = {
            'vcf': VCFParser(),
            'maf': MAFParser(),
            'pdf': PDFParser(),  # Uses LLM for extraction
            'json': JSONParser(),
            'txt': TextParser(),
            'csv': TextParser(),
        }
        
        # Initialize validators
        self.mutation_validator = MutationValidator()
        self.gene_validator = GeneValidator()
        self.quality_checker = QualityChecker()
        
        # Initialize normalizers
        self.hgvs_normalizer = HGVSNormalizer()
        self.gene_normalizer = GeneNormalizer()
        self.disease_normalizer = DiseaseNormalizer()
    
    async def extract(
        self,
        file: Union[BinaryIO, bytes, str],
        file_type: str,
        metadata: dict = None
    ) -> PatientProfile:
        """
        Main extraction entry point.
        
        Args:
            file: File content (binary, bytes, or path)
            file_type: One of 'vcf', 'maf', 'pdf', 'json', 'txt', 'csv'
            metadata: Optional metadata (lab, date, patient_id)
        
        Returns:
            PatientProfile with extracted data
        """
        logger.info(f"Starting extraction for file_type={file_type}")
        
        # Step 1: Parse file
        parser = self.parsers.get(file_type.lower())
        if not parser:
            raise ValueError(f"Unsupported file type: {file_type}")
        
        raw_data = await parser.parse(file, metadata)
        
        # Step 2: Extract mutations
        mutations = self._extract_mutations(raw_data)
        
        # Step 3: Validate mutations
        validated_mutations = []
        for mut in mutations:
            if self.mutation_validator.validate(mut):
                validated_mutations.append(mut)
            else:
                logger.warning(f"Invalid mutation skipped: {mut}")
        
        # Step 4: Normalize mutations
        normalized_mutations = [
            self._normalize_mutation(mut) for mut in validated_mutations
        ]
        
        # Step 5: Extract clinical data
        clinical_data = self._extract_clinical_data(raw_data)
        
        # Step 6: Extract demographics
        demographics = self._extract_demographics(raw_data)
        
        # Step 7: Check data quality
        quality_flags = self.quality_checker.check(
            mutations=normalized_mutations,
            clinical_data=clinical_data
        )
        
        # Step 8: Build PatientProfile
        profile = PatientProfile(
            patient_id=metadata.get('patient_id', self._generate_id()),
            disease=self.disease_normalizer.normalize(
                raw_data.get('disease', 'unknown')
            ),
            mutations=normalized_mutations,
            clinical_data=clinical_data,
            demographics=demographics,
            data_quality_flags=quality_flags,
            extraction_provenance={
                'source': file_type,
                'lab': metadata.get('lab'),
                'extraction_method': parser.__class__.__name__,
                'confidence': self._calculate_confidence(raw_data)
            }
        )
        
        logger.info(f"Extraction complete: {len(normalized_mutations)} mutations")
        return profile
    
    def _extract_mutations(self, raw_data: dict) -> List[Mutation]:
        """Extract mutation objects from raw parsed data."""
        mutations = []
        
        for mut_data in raw_data.get('mutations', []):
            mutation = Mutation(
                gene=mut_data.get('gene', ''),
                variant=mut_data.get('variant', ''),
                hgvs_c=mut_data.get('hgvs_c'),
                hgvs_p=mut_data.get('hgvs_p'),
                chromosome=mut_data.get('chrom'),
                position=mut_data.get('pos'),
                ref=mut_data.get('ref'),
                alt=mut_data.get('alt'),
                vaf=mut_data.get('vaf'),
                coverage=mut_data.get('coverage'),
                zygosity=self._parse_zygosity(mut_data.get('zygosity')),
                source=self._parse_source(mut_data.get('source')),
                classification=mut_data.get('classification')
            )
            mutations.append(mutation)
        
        return mutations
    
    def _normalize_mutation(self, mutation: Mutation) -> Mutation:
        """Normalize gene names and HGVS notation."""
        mutation.gene = self.gene_normalizer.normalize(mutation.gene)
        
        if mutation.hgvs_c:
            mutation.hgvs_c = self.hgvs_normalizer.normalize(mutation.hgvs_c)
        if mutation.hgvs_p:
            mutation.hgvs_p = self.hgvs_normalizer.normalize(mutation.hgvs_p)
        
        return mutation
```

### PDF Parser (LLM-Based)

```python
# api/services/extraction/parsers/pdf_parser.py

from typing import BinaryIO, Union
import io
import logging

# PDF extraction
import fitz  # PyMuPDF
from google import genai  # Gemini for intelligent extraction

logger = logging.getLogger(__name__)

class PDFParser:
    """
    Extract mutation and clinical data from PDF reports using LLM.
    
    Supports:
    - Foundation Medicine reports
    - Tempus reports
    - Guardant Health reports
    - Generic lab reports
    """
    
    EXTRACTION_PROMPT = """
    You are a clinical genomics expert. Extract all mutations and clinical data from this report.
    
    Return JSON with this structure:
    {
        "patient_id": "string or null",
        "disease": "cancer type",
        "mutations": [
            {
                "gene": "BRAF",
                "variant": "V600E",
                "hgvs_p": "p.Val600Glu",
                "hgvs_c": "c.1799T>A",
                "vaf": 0.45,
                "classification": "Pathogenic"
            }
        ],
        "clinical_data": {
            "stage": "IVB",
            "histology": "adenocarcinoma",
            "prior_treatments": ["carboplatin", "paclitaxel"],
            "biomarkers": {
                "TMB": 10.2,
                "MSI": "Stable",
                "PD-L1": "50%"
            }
        },
        "germline_mutations": [],
        "lab_name": "Foundation Medicine",
        "report_date": "2025-01-15"
    }
    
    IMPORTANT:
    - Extract ALL mutations listed, including VUS
    - Use standard HGVS notation
    - Normalize gene symbols to HGNC
    - If data is unclear, mark as null
    
    Report text:
    {report_text}
    """
    
    def __init__(self, model_id: str = "gemini-2.0-flash"):
        self.client = genai.Client()
        self.model_id = model_id
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes],
        metadata: dict = None
    ) -> dict:
        """
        Parse PDF report and extract structured data.
        
        Args:
            file: PDF file content
            metadata: Optional metadata
        
        Returns:
            Dict with extracted data
        """
        # Step 1: Extract text from PDF
        text = self._extract_text(file)
        logger.info(f"Extracted {len(text)} characters from PDF")
        
        # Step 2: Use LLM to extract structured data
        prompt = self.EXTRACTION_PROMPT.format(report_text=text[:50000])  # Limit
        
        response = self.client.models.generate_content(
            model=self.model_id,
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.1  # Low temperature for accuracy
            }
        )
        
        # Step 3: Parse JSON response
        import json
        try:
            extracted = json.loads(response.text)
        except json.JSONDecodeError:
            logger.error("Failed to parse LLM response as JSON")
            extracted = {"mutations": [], "error": "parse_failed"}
        
        # Step 4: Add provenance
        extracted['extraction_method'] = 'llm_pdf_extraction'
        extracted['source_text_length'] = len(text)
        
        return extracted
    
    def _extract_text(self, file: Union[BinaryIO, bytes]) -> str:
        """Extract text content from PDF."""
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        
        return text
```

### VCF Parser

```python
# api/services/extraction/parsers/vcf_parser.py

from typing import BinaryIO, Union, List, Dict
import io

class VCFParser:
    """
    Parse VCF (Variant Call Format) files.
    
    Supports:
    - VCF 4.1, 4.2, 4.3
    - Multi-sample VCFs (uses first sample)
    - Gzipped VCF files
    """
    
    def __init__(self):
        self.required_fields = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes, str],
        metadata: dict = None
    ) -> dict:
        """Parse VCF file and extract mutations."""
        
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        mutations = []
        header_info = {}
        
        for line in file:
            if isinstance(line, bytes):
                line = line.decode('utf-8')
            line = line.strip()
            
            # Parse header
            if line.startswith('##'):
                self._parse_header_line(line, header_info)
                continue
            
            # Parse column header
            if line.startswith('#CHROM'):
                columns = line.split('\t')
                continue
            
            # Parse variant line
            if line and not line.startswith('#'):
                mutation = self._parse_variant_line(line, columns)
                if mutation:
                    mutations.append(mutation)
        
        return {
            'mutations': mutations,
            'vcf_header': header_info,
            'mutation_count': len(mutations)
        }
    
    def _parse_variant_line(self, line: str, columns: List[str]) -> Dict:
        """Parse a single variant line."""
        fields = line.split('\t')
        
        mutation = {
            'chrom': fields[0],
            'pos': int(fields[1]),
            'id': fields[2] if fields[2] != '.' else None,
            'ref': fields[3],
            'alt': fields[4],
            'qual': float(fields[5]) if fields[5] != '.' else None,
            'filter': fields[6],
            'info': self._parse_info(fields[7]) if len(fields) > 7 else {}
        }
        
        # Extract gene and variant from INFO field
        info = mutation['info']
        mutation['gene'] = info.get('GENE', info.get('Gene', ''))
        mutation['hgvs_c'] = info.get('HGVSc', info.get('HGVS_c', ''))
        mutation['hgvs_p'] = info.get('HGVSp', info.get('HGVS_p', ''))
        mutation['variant'] = mutation['hgvs_p'] or f"{mutation['ref']}>{mutation['alt']}"
        
        # Extract VAF if available
        if len(fields) > 9:  # Has sample data
            format_fields = fields[8].split(':')
            sample_data = fields[9].split(':')
            format_dict = dict(zip(format_fields, sample_data))
            
            if 'AF' in format_dict:
                mutation['vaf'] = float(format_dict['AF'])
            elif 'AD' in format_dict:
                # Calculate from allele depth
                ad = [int(x) for x in format_dict['AD'].split(',')]
                if sum(ad) > 0:
                    mutation['vaf'] = ad[1] / sum(ad)
        
        return mutation
    
    def _parse_info(self, info_str: str) -> Dict:
        """Parse INFO field into dictionary."""
        info = {}
        for item in info_str.split(';'):
            if '=' in item:
                key, value = item.split('=', 1)
                info[key] = value
            else:
                info[item] = True
        return info
```

---

## ðŸ§ª TESTING

### Unit Tests

```python
# api/services/extraction/tests/test_vcf_parser.py

import pytest
from ..parsers.vcf_parser import VCFParser

@pytest.fixture
def vcf_content():
    return b"""##fileformat=VCFv4.2
##INFO=<ID=GENE,Number=1,Type=String,Description="Gene name">
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
chr17\t7674872\t.\tG\tA\t.\tPASS\tGENE=TP53;HGVSp=p.Arg175His\tGT:AF\t0/1:0.62
"""

@pytest.mark.asyncio
async def test_vcf_parser_basic(vcf_content):
    parser = VCFParser()
    result = await parser.parse(vcf_content)
    
    assert result['mutation_count'] == 2
    assert result['mutations'][0]['gene'] == 'BRAF'
    assert result['mutations'][0]['hgvs_p'] == 'p.Val600Glu'
    assert result['mutations'][0]['vaf'] == 0.45

@pytest.mark.asyncio
async def test_vcf_parser_missing_vaf(vcf_content):
    # Test handling of missing VAF
    content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF
"""
    parser = VCFParser()
    result = await parser.parse(content)
    
    assert result['mutations'][0]['vaf'] is None
```

### Integration Test

```python
# api/services/extraction/tests/test_integration.py

import pytest
from ..extraction_agent import DataExtractionAgent

@pytest.fixture
def agent():
    return DataExtractionAgent()

@pytest.mark.asyncio
async def test_full_extraction_flow(agent):
    # Test with sample VCF
    vcf_content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
"""
    
    profile = await agent.extract(
        file=vcf_content,
        file_type='vcf',
        metadata={'patient_id': 'TEST-001'}
    )
    
    assert profile.patient_id == 'TEST-001'
    assert len(profile.mutations) == 1
    assert profile.mutations[0].gene == 'BRAF'
    assert profile.extraction_provenance['source'] == 'vcf'
```

---

## ðŸ“‹ IMPLEMENTATION CHECKLIST

### Phase 1: Core Parsers
- [ ] Implement VCF parser (standard format)
- [ ] Implement MAF parser (tab-delimited)
- [ ] Implement JSON parser (structured input)
- [ ] Unit tests for each parser

### Phase 2: PDF Extraction
- [ ] Set up PyMuPDF for text extraction
- [ ] Create LLM extraction prompt
- [ ] Handle Foundation Medicine reports
- [ ] Handle Tempus reports
- [ ] Handle generic reports
- [ ] Unit tests for PDF extraction

### Phase 3: Validation & Normalization
- [ ] Gene name validation (HGNC)
- [ ] HGVS notation validation
- [ ] Zygosity inference
- [ ] Data quality flagging
- [ ] Unit tests for validators

### Phase 4: Integration
- [ ] Create DataExtractionAgent class
- [ ] Wire up all parsers
- [ ] Add provenance tracking
- [ ] Integration tests
- [ ] Performance testing (100 files/minute target)

---

## ðŸ”— DEPENDENCIES

### Python Packages

```txt
# requirements_extraction.txt
PyMuPDF>=1.23.0          # PDF text extraction
google-genai>=0.3.0      # LLM for PDF extraction
pydantic>=2.0.0          # Data validation
hgvs>=1.5.4              # HGVS notation parsing
```

### External Services

| Service | Purpose | Required |
|---------|---------|----------|
| Gemini API | PDF extraction | Yes (for PDF) |
| HGNC API | Gene symbol validation | Optional |

---

## ðŸ“¡ API ENDPOINT

```yaml
POST /api/agents/extract
Content-Type: multipart/form-data

Request:
  file: binary
  file_type: string  # vcf, maf, pdf, json
  metadata: json     # optional

Response:
  patient_profile: PatientProfile
  extraction_time_ms: number
  warnings: string[]
```

---

## âœ… ACCEPTANCE CRITERIA

1. âœ… Can parse VCF files with >95% accuracy
2. âœ… Can parse MAF files with >95% accuracy
3. âœ… Can extract mutations from PDF reports with >85% accuracy
4. âœ… All gene names normalized to HGNC
5. âœ… All HGVS notation validated
6. âœ… Data quality flags generated for missing data
7. âœ… Provenance tracked for all extractions
8. âœ… Processing time <10 seconds for typical files
9. âœ… Unit test coverage >80%

---

---

## ðŸŽ¯ MISSION

Build an intelligent data extraction agent that can:
1. Accept any file format (PDF, VCF, MAF, JSON, TXT)
2. Extract mutations, clinical data, and demographics
3. Validate data quality and flag issues
4. Output a structured `PatientProfile` object

---

## ðŸ“¥ INPUTS

### Accepted File Types

| Format | Description | Parser Needed |
|--------|-------------|---------------|
| **VCF** | Variant Call Format | Standard VCF parser |
| **MAF** | Mutation Annotation Format | Tab-delimited parser |
| **PDF** | NGS reports from labs | LLM-based extraction |
| **JSON** | Structured mutation data | JSON parser |
| **TXT/CSV** | Clinical notes, lab results | Text extraction |

### Example Input

```json
{
  "file": "binary_file_content",
  "file_type": "pdf",
  "file_name": "Foundation_One_Report.pdf",
  "metadata": {
    "lab": "Foundation Medicine",
    "report_date": "2025-01-15"
  }
}
```

---

## ðŸ“¤ OUTPUTS

### PatientProfile Schema

```python
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
from enum import Enum

class Zygosity(Enum):
    HETEROZYGOUS = "heterozygous"
    HOMOZYGOUS = "homozygous"
    HEMIZYGOUS = "hemizygous"
    UNKNOWN = "unknown"

class MutationSource(Enum):
    NGS = "ngs"
    IHC = "ihc"
    FISH = "fish"
    PCR = "pcr"
    INFERRED = "inferred"

@dataclass
class Mutation:
    gene: str
    variant: str                    # e.g., "c.1239delA" or "p.V600E"
    hgvs_c: Optional[str] = None    # Coding change
    hgvs_p: Optional[str] = None    # Protein change
    chromosome: Optional[str] = None
    position: Optional[int] = None
    ref: Optional[str] = None
    alt: Optional[str] = None
    vaf: Optional[float] = None     # Variant allele frequency
    coverage: Optional[int] = None
    zygosity: Zygosity = Zygosity.UNKNOWN
    source: MutationSource = MutationSource.NGS
    classification: Optional[str] = None  # Pathogenic, VUS, Benign

@dataclass
class GermlinePanel:
    genes_tested: List[str]
    pathogenic: Dict[str, str]      # gene -> variant
    vus: Dict[str, str]
    negative: List[str]
    panel_name: Optional[str] = None
    test_date: Optional[datetime] = None

@dataclass
class ClinicalData:
    stage: Optional[str] = None         # e.g., "IVB"
    histology: Optional[str] = None     # e.g., "high_grade_serous"
    grade: Optional[str] = None
    ecog_ps: Optional[int] = None       # Performance status
    biomarkers: Dict[str, any] = None   # CA-125, HER2, etc.
    prior_treatments: List[str] = None
    current_treatment: Optional[str] = None

@dataclass
class Demographics:
    age: Optional[int] = None
    sex: Optional[str] = None
    ethnicity: Optional[str] = None

@dataclass
class PatientProfile:
    patient_id: str
    disease: str                        # e.g., "ovarian_cancer"
    mutations: List[Mutation]
    germline_panel: Optional[GermlinePanel] = None
    clinical_data: Optional[ClinicalData] = None
    demographics: Optional[Demographics] = None
    data_quality_flags: List[str] = None  # ["ca125_missing", "hrd_pending"]
    extraction_provenance: Dict[str, any] = None  # Source, confidence, method
    created_at: datetime = None
    updated_at: datetime = None
```

---

## ðŸ—ï¸ IMPLEMENTATION

### File Structure

```
api/services/extraction/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ extraction_agent.py          # Main agent logic
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vcf_parser.py            # VCF file parsing
â”‚   â”œâ”€â”€ maf_parser.py            # MAF file parsing
â”‚   â”œâ”€â”€ pdf_parser.py            # PDF extraction with LLM
â”‚   â”œâ”€â”€ json_parser.py           # JSON parsing
â”‚   â””â”€â”€ text_parser.py           # Clinical notes extraction
â”œâ”€â”€ validators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mutation_validator.py    # Validate mutation format
â”‚   â”œâ”€â”€ gene_validator.py        # Validate gene names
â”‚   â””â”€â”€ quality_checker.py       # Data quality assessment
â”œâ”€â”€ normalizers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hgvs_normalizer.py       # Normalize HGVS notation
â”‚   â”œâ”€â”€ gene_normalizer.py       # Normalize gene symbols
â”‚   â””â”€â”€ disease_normalizer.py    # Normalize disease terms
â””â”€â”€ tests/
    â”œâ”€â”€ test_vcf_parser.py
    â”œâ”€â”€ test_pdf_parser.py
    â””â”€â”€ test_integration.py
```

### Core Agent Implementation

```python
# api/services/extraction/extraction_agent.py

from typing import Union, BinaryIO
from pathlib import Path
import logging

from .parsers import VCFParser, MAFParser, PDFParser, JSONParser, TextParser
from .validators import MutationValidator, GeneValidator, QualityChecker
from .normalizers import HGVSNormalizer, GeneNormalizer, DiseaseNormalizer
from ..models import PatientProfile, Mutation, DataQualityFlag

logger = logging.getLogger(__name__)

class DataExtractionAgent:
    """
    Intelligent agent for extracting structured patient data from various file formats.
    
    Capabilities:
    - Multi-format parsing (VCF, MAF, PDF, JSON, TXT)
    - Mutation validation and normalization
    - Data quality assessment
    - Provenance tracking
    """
    
    def __init__(self):
        # Initialize parsers
        self.parsers = {
            'vcf': VCFParser(),
            'maf': MAFParser(),
            'pdf': PDFParser(),  # Uses LLM for extraction
            'json': JSONParser(),
            'txt': TextParser(),
            'csv': TextParser(),
        }
        
        # Initialize validators
        self.mutation_validator = MutationValidator()
        self.gene_validator = GeneValidator()
        self.quality_checker = QualityChecker()
        
        # Initialize normalizers
        self.hgvs_normalizer = HGVSNormalizer()
        self.gene_normalizer = GeneNormalizer()
        self.disease_normalizer = DiseaseNormalizer()
    
    async def extract(
        self,
        file: Union[BinaryIO, bytes, str],
        file_type: str,
        metadata: dict = None
    ) -> PatientProfile:
        """
        Main extraction entry point.
        
        Args:
            file: File content (binary, bytes, or path)
            file_type: One of 'vcf', 'maf', 'pdf', 'json', 'txt', 'csv'
            metadata: Optional metadata (lab, date, patient_id)
        
        Returns:
            PatientProfile with extracted data
        """
        logger.info(f"Starting extraction for file_type={file_type}")
        
        # Step 1: Parse file
        parser = self.parsers.get(file_type.lower())
        if not parser:
            raise ValueError(f"Unsupported file type: {file_type}")
        
        raw_data = await parser.parse(file, metadata)
        
        # Step 2: Extract mutations
        mutations = self._extract_mutations(raw_data)
        
        # Step 3: Validate mutations
        validated_mutations = []
        for mut in mutations:
            if self.mutation_validator.validate(mut):
                validated_mutations.append(mut)
            else:
                logger.warning(f"Invalid mutation skipped: {mut}")
        
        # Step 4: Normalize mutations
        normalized_mutations = [
            self._normalize_mutation(mut) for mut in validated_mutations
        ]
        
        # Step 5: Extract clinical data
        clinical_data = self._extract_clinical_data(raw_data)
        
        # Step 6: Extract demographics
        demographics = self._extract_demographics(raw_data)
        
        # Step 7: Check data quality
        quality_flags = self.quality_checker.check(
            mutations=normalized_mutations,
            clinical_data=clinical_data
        )
        
        # Step 8: Build PatientProfile
        profile = PatientProfile(
            patient_id=metadata.get('patient_id', self._generate_id()),
            disease=self.disease_normalizer.normalize(
                raw_data.get('disease', 'unknown')
            ),
            mutations=normalized_mutations,
            clinical_data=clinical_data,
            demographics=demographics,
            data_quality_flags=quality_flags,
            extraction_provenance={
                'source': file_type,
                'lab': metadata.get('lab'),
                'extraction_method': parser.__class__.__name__,
                'confidence': self._calculate_confidence(raw_data)
            }
        )
        
        logger.info(f"Extraction complete: {len(normalized_mutations)} mutations")
        return profile
    
    def _extract_mutations(self, raw_data: dict) -> List[Mutation]:
        """Extract mutation objects from raw parsed data."""
        mutations = []
        
        for mut_data in raw_data.get('mutations', []):
            mutation = Mutation(
                gene=mut_data.get('gene', ''),
                variant=mut_data.get('variant', ''),
                hgvs_c=mut_data.get('hgvs_c'),
                hgvs_p=mut_data.get('hgvs_p'),
                chromosome=mut_data.get('chrom'),
                position=mut_data.get('pos'),
                ref=mut_data.get('ref'),
                alt=mut_data.get('alt'),
                vaf=mut_data.get('vaf'),
                coverage=mut_data.get('coverage'),
                zygosity=self._parse_zygosity(mut_data.get('zygosity')),
                source=self._parse_source(mut_data.get('source')),
                classification=mut_data.get('classification')
            )
            mutations.append(mutation)
        
        return mutations
    
    def _normalize_mutation(self, mutation: Mutation) -> Mutation:
        """Normalize gene names and HGVS notation."""
        mutation.gene = self.gene_normalizer.normalize(mutation.gene)
        
        if mutation.hgvs_c:
            mutation.hgvs_c = self.hgvs_normalizer.normalize(mutation.hgvs_c)
        if mutation.hgvs_p:
            mutation.hgvs_p = self.hgvs_normalizer.normalize(mutation.hgvs_p)
        
        return mutation
```

### PDF Parser (LLM-Based)

```python
# api/services/extraction/parsers/pdf_parser.py

from typing import BinaryIO, Union
import io
import logging

# PDF extraction
import fitz  # PyMuPDF
from google import genai  # Gemini for intelligent extraction

logger = logging.getLogger(__name__)

class PDFParser:
    """
    Extract mutation and clinical data from PDF reports using LLM.
    
    Supports:
    - Foundation Medicine reports
    - Tempus reports
    - Guardant Health reports
    - Generic lab reports
    """
    
    EXTRACTION_PROMPT = """
    You are a clinical genomics expert. Extract all mutations and clinical data from this report.
    
    Return JSON with this structure:
    {
        "patient_id": "string or null",
        "disease": "cancer type",
        "mutations": [
            {
                "gene": "BRAF",
                "variant": "V600E",
                "hgvs_p": "p.Val600Glu",
                "hgvs_c": "c.1799T>A",
                "vaf": 0.45,
                "classification": "Pathogenic"
            }
        ],
        "clinical_data": {
            "stage": "IVB",
            "histology": "adenocarcinoma",
            "prior_treatments": ["carboplatin", "paclitaxel"],
            "biomarkers": {
                "TMB": 10.2,
                "MSI": "Stable",
                "PD-L1": "50%"
            }
        },
        "germline_mutations": [],
        "lab_name": "Foundation Medicine",
        "report_date": "2025-01-15"
    }
    
    IMPORTANT:
    - Extract ALL mutations listed, including VUS
    - Use standard HGVS notation
    - Normalize gene symbols to HGNC
    - If data is unclear, mark as null
    
    Report text:
    {report_text}
    """
    
    def __init__(self, model_id: str = "gemini-2.0-flash"):
        self.client = genai.Client()
        self.model_id = model_id
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes],
        metadata: dict = None
    ) -> dict:
        """
        Parse PDF report and extract structured data.
        
        Args:
            file: PDF file content
            metadata: Optional metadata
        
        Returns:
            Dict with extracted data
        """
        # Step 1: Extract text from PDF
        text = self._extract_text(file)
        logger.info(f"Extracted {len(text)} characters from PDF")
        
        # Step 2: Use LLM to extract structured data
        prompt = self.EXTRACTION_PROMPT.format(report_text=text[:50000])  # Limit
        
        response = self.client.models.generate_content(
            model=self.model_id,
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.1  # Low temperature for accuracy
            }
        )
        
        # Step 3: Parse JSON response
        import json
        try:
            extracted = json.loads(response.text)
        except json.JSONDecodeError:
            logger.error("Failed to parse LLM response as JSON")
            extracted = {"mutations": [], "error": "parse_failed"}
        
        # Step 4: Add provenance
        extracted['extraction_method'] = 'llm_pdf_extraction'
        extracted['source_text_length'] = len(text)
        
        return extracted
    
    def _extract_text(self, file: Union[BinaryIO, bytes]) -> str:
        """Extract text content from PDF."""
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        
        return text
```

### VCF Parser

```python
# api/services/extraction/parsers/vcf_parser.py

from typing import BinaryIO, Union, List, Dict
import io

class VCFParser:
    """
    Parse VCF (Variant Call Format) files.
    
    Supports:
    - VCF 4.1, 4.2, 4.3
    - Multi-sample VCFs (uses first sample)
    - Gzipped VCF files
    """
    
    def __init__(self):
        self.required_fields = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes, str],
        metadata: dict = None
    ) -> dict:
        """Parse VCF file and extract mutations."""
        
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        mutations = []
        header_info = {}
        
        for line in file:
            if isinstance(line, bytes):
                line = line.decode('utf-8')
            line = line.strip()
            
            # Parse header
            if line.startswith('##'):
                self._parse_header_line(line, header_info)
                continue
            
            # Parse column header
            if line.startswith('#CHROM'):
                columns = line.split('\t')
                continue
            
            # Parse variant line
            if line and not line.startswith('#'):
                mutation = self._parse_variant_line(line, columns)
                if mutation:
                    mutations.append(mutation)
        
        return {
            'mutations': mutations,
            'vcf_header': header_info,
            'mutation_count': len(mutations)
        }
    
    def _parse_variant_line(self, line: str, columns: List[str]) -> Dict:
        """Parse a single variant line."""
        fields = line.split('\t')
        
        mutation = {
            'chrom': fields[0],
            'pos': int(fields[1]),
            'id': fields[2] if fields[2] != '.' else None,
            'ref': fields[3],
            'alt': fields[4],
            'qual': float(fields[5]) if fields[5] != '.' else None,
            'filter': fields[6],
            'info': self._parse_info(fields[7]) if len(fields) > 7 else {}
        }
        
        # Extract gene and variant from INFO field
        info = mutation['info']
        mutation['gene'] = info.get('GENE', info.get('Gene', ''))
        mutation['hgvs_c'] = info.get('HGVSc', info.get('HGVS_c', ''))
        mutation['hgvs_p'] = info.get('HGVSp', info.get('HGVS_p', ''))
        mutation['variant'] = mutation['hgvs_p'] or f"{mutation['ref']}>{mutation['alt']}"
        
        # Extract VAF if available
        if len(fields) > 9:  # Has sample data
            format_fields = fields[8].split(':')
            sample_data = fields[9].split(':')
            format_dict = dict(zip(format_fields, sample_data))
            
            if 'AF' in format_dict:
                mutation['vaf'] = float(format_dict['AF'])
            elif 'AD' in format_dict:
                # Calculate from allele depth
                ad = [int(x) for x in format_dict['AD'].split(',')]
                if sum(ad) > 0:
                    mutation['vaf'] = ad[1] / sum(ad)
        
        return mutation
    
    def _parse_info(self, info_str: str) -> Dict:
        """Parse INFO field into dictionary."""
        info = {}
        for item in info_str.split(';'):
            if '=' in item:
                key, value = item.split('=', 1)
                info[key] = value
            else:
                info[item] = True
        return info
```

---

## ðŸ§ª TESTING

### Unit Tests

```python
# api/services/extraction/tests/test_vcf_parser.py

import pytest
from ..parsers.vcf_parser import VCFParser

@pytest.fixture
def vcf_content():
    return b"""##fileformat=VCFv4.2
##INFO=<ID=GENE,Number=1,Type=String,Description="Gene name">
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
chr17\t7674872\t.\tG\tA\t.\tPASS\tGENE=TP53;HGVSp=p.Arg175His\tGT:AF\t0/1:0.62
"""

@pytest.mark.asyncio
async def test_vcf_parser_basic(vcf_content):
    parser = VCFParser()
    result = await parser.parse(vcf_content)
    
    assert result['mutation_count'] == 2
    assert result['mutations'][0]['gene'] == 'BRAF'
    assert result['mutations'][0]['hgvs_p'] == 'p.Val600Glu'
    assert result['mutations'][0]['vaf'] == 0.45

@pytest.mark.asyncio
async def test_vcf_parser_missing_vaf(vcf_content):
    # Test handling of missing VAF
    content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF
"""
    parser = VCFParser()
    result = await parser.parse(content)
    
    assert result['mutations'][0]['vaf'] is None
```

### Integration Test

```python
# api/services/extraction/tests/test_integration.py

import pytest
from ..extraction_agent import DataExtractionAgent

@pytest.fixture
def agent():
    return DataExtractionAgent()

@pytest.mark.asyncio
async def test_full_extraction_flow(agent):
    # Test with sample VCF
    vcf_content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
"""
    
    profile = await agent.extract(
        file=vcf_content,
        file_type='vcf',
        metadata={'patient_id': 'TEST-001'}
    )
    
    assert profile.patient_id == 'TEST-001'
    assert len(profile.mutations) == 1
    assert profile.mutations[0].gene == 'BRAF'
    assert profile.extraction_provenance['source'] == 'vcf'
```

---

## ðŸ“‹ IMPLEMENTATION CHECKLIST

### Phase 1: Core Parsers
- [ ] Implement VCF parser (standard format)
- [ ] Implement MAF parser (tab-delimited)
- [ ] Implement JSON parser (structured input)
- [ ] Unit tests for each parser

### Phase 2: PDF Extraction
- [ ] Set up PyMuPDF for text extraction
- [ ] Create LLM extraction prompt
- [ ] Handle Foundation Medicine reports
- [ ] Handle Tempus reports
- [ ] Handle generic reports
- [ ] Unit tests for PDF extraction

### Phase 3: Validation & Normalization
- [ ] Gene name validation (HGNC)
- [ ] HGVS notation validation
- [ ] Zygosity inference
- [ ] Data quality flagging
- [ ] Unit tests for validators

### Phase 4: Integration
- [ ] Create DataExtractionAgent class
- [ ] Wire up all parsers
- [ ] Add provenance tracking
- [ ] Integration tests
- [ ] Performance testing (100 files/minute target)

---

## ðŸ”— DEPENDENCIES

### Python Packages

```txt
# requirements_extraction.txt
PyMuPDF>=1.23.0          # PDF text extraction
google-genai>=0.3.0      # LLM for PDF extraction
pydantic>=2.0.0          # Data validation
hgvs>=1.5.4              # HGVS notation parsing
```

### External Services

| Service | Purpose | Required |
|---------|---------|----------|
| Gemini API | PDF extraction | Yes (for PDF) |
| HGNC API | Gene symbol validation | Optional |

---

## ðŸ“¡ API ENDPOINT

```yaml
POST /api/agents/extract
Content-Type: multipart/form-data

Request:
  file: binary
  file_type: string  # vcf, maf, pdf, json
  metadata: json     # optional

Response:
  patient_profile: PatientProfile
  extraction_time_ms: number
  warnings: string[]
```

---

## âœ… ACCEPTANCE CRITERIA

1. âœ… Can parse VCF files with >95% accuracy
2. âœ… Can parse MAF files with >95% accuracy
3. âœ… Can extract mutations from PDF reports with >85% accuracy
4. âœ… All gene names normalized to HGNC
5. âœ… All HGVS notation validated
6. âœ… Data quality flags generated for missing data
7. âœ… Provenance tracked for all extractions
8. âœ… Processing time <10 seconds for typical files
9. âœ… Unit test coverage >80%

---

---

## ðŸŽ¯ MISSION

Build an intelligent data extraction agent that can:
1. Accept any file format (PDF, VCF, MAF, JSON, TXT)
2. Extract mutations, clinical data, and demographics
3. Validate data quality and flag issues
4. Output a structured `PatientProfile` object

---

## ðŸ“¥ INPUTS

### Accepted File Types

| Format | Description | Parser Needed |
|--------|-------------|---------------|
| **VCF** | Variant Call Format | Standard VCF parser |
| **MAF** | Mutation Annotation Format | Tab-delimited parser |
| **PDF** | NGS reports from labs | LLM-based extraction |
| **JSON** | Structured mutation data | JSON parser |
| **TXT/CSV** | Clinical notes, lab results | Text extraction |

### Example Input

```json
{
  "file": "binary_file_content",
  "file_type": "pdf",
  "file_name": "Foundation_One_Report.pdf",
  "metadata": {
    "lab": "Foundation Medicine",
    "report_date": "2025-01-15"
  }
}
```

---

## ðŸ“¤ OUTPUTS

### PatientProfile Schema

```python
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
from enum import Enum

class Zygosity(Enum):
    HETEROZYGOUS = "heterozygous"
    HOMOZYGOUS = "homozygous"
    HEMIZYGOUS = "hemizygous"
    UNKNOWN = "unknown"

class MutationSource(Enum):
    NGS = "ngs"
    IHC = "ihc"
    FISH = "fish"
    PCR = "pcr"
    INFERRED = "inferred"

@dataclass
class Mutation:
    gene: str
    variant: str                    # e.g., "c.1239delA" or "p.V600E"
    hgvs_c: Optional[str] = None    # Coding change
    hgvs_p: Optional[str] = None    # Protein change
    chromosome: Optional[str] = None
    position: Optional[int] = None
    ref: Optional[str] = None
    alt: Optional[str] = None
    vaf: Optional[float] = None     # Variant allele frequency
    coverage: Optional[int] = None
    zygosity: Zygosity = Zygosity.UNKNOWN
    source: MutationSource = MutationSource.NGS
    classification: Optional[str] = None  # Pathogenic, VUS, Benign

@dataclass
class GermlinePanel:
    genes_tested: List[str]
    pathogenic: Dict[str, str]      # gene -> variant
    vus: Dict[str, str]
    negative: List[str]
    panel_name: Optional[str] = None
    test_date: Optional[datetime] = None

@dataclass
class ClinicalData:
    stage: Optional[str] = None         # e.g., "IVB"
    histology: Optional[str] = None     # e.g., "high_grade_serous"
    grade: Optional[str] = None
    ecog_ps: Optional[int] = None       # Performance status
    biomarkers: Dict[str, any] = None   # CA-125, HER2, etc.
    prior_treatments: List[str] = None
    current_treatment: Optional[str] = None

@dataclass
class Demographics:
    age: Optional[int] = None
    sex: Optional[str] = None
    ethnicity: Optional[str] = None

@dataclass
class PatientProfile:
    patient_id: str
    disease: str                        # e.g., "ovarian_cancer"
    mutations: List[Mutation]
    germline_panel: Optional[GermlinePanel] = None
    clinical_data: Optional[ClinicalData] = None
    demographics: Optional[Demographics] = None
    data_quality_flags: List[str] = None  # ["ca125_missing", "hrd_pending"]
    extraction_provenance: Dict[str, any] = None  # Source, confidence, method
    created_at: datetime = None
    updated_at: datetime = None
```

---

## ðŸ—ï¸ IMPLEMENTATION

### File Structure

```
api/services/extraction/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ extraction_agent.py          # Main agent logic
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vcf_parser.py            # VCF file parsing
â”‚   â”œâ”€â”€ maf_parser.py            # MAF file parsing
â”‚   â”œâ”€â”€ pdf_parser.py            # PDF extraction with LLM
â”‚   â”œâ”€â”€ json_parser.py           # JSON parsing
â”‚   â””â”€â”€ text_parser.py           # Clinical notes extraction
â”œâ”€â”€ validators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mutation_validator.py    # Validate mutation format
â”‚   â”œâ”€â”€ gene_validator.py        # Validate gene names
â”‚   â””â”€â”€ quality_checker.py       # Data quality assessment
â”œâ”€â”€ normalizers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hgvs_normalizer.py       # Normalize HGVS notation
â”‚   â”œâ”€â”€ gene_normalizer.py       # Normalize gene symbols
â”‚   â””â”€â”€ disease_normalizer.py    # Normalize disease terms
â””â”€â”€ tests/
    â”œâ”€â”€ test_vcf_parser.py
    â”œâ”€â”€ test_pdf_parser.py
    â””â”€â”€ test_integration.py
```

### Core Agent Implementation

```python
# api/services/extraction/extraction_agent.py

from typing import Union, BinaryIO
from pathlib import Path
import logging

from .parsers import VCFParser, MAFParser, PDFParser, JSONParser, TextParser
from .validators import MutationValidator, GeneValidator, QualityChecker
from .normalizers import HGVSNormalizer, GeneNormalizer, DiseaseNormalizer
from ..models import PatientProfile, Mutation, DataQualityFlag

logger = logging.getLogger(__name__)

class DataExtractionAgent:
    """
    Intelligent agent for extracting structured patient data from various file formats.
    
    Capabilities:
    - Multi-format parsing (VCF, MAF, PDF, JSON, TXT)
    - Mutation validation and normalization
    - Data quality assessment
    - Provenance tracking
    """
    
    def __init__(self):
        # Initialize parsers
        self.parsers = {
            'vcf': VCFParser(),
            'maf': MAFParser(),
            'pdf': PDFParser(),  # Uses LLM for extraction
            'json': JSONParser(),
            'txt': TextParser(),
            'csv': TextParser(),
        }
        
        # Initialize validators
        self.mutation_validator = MutationValidator()
        self.gene_validator = GeneValidator()
        self.quality_checker = QualityChecker()
        
        # Initialize normalizers
        self.hgvs_normalizer = HGVSNormalizer()
        self.gene_normalizer = GeneNormalizer()
        self.disease_normalizer = DiseaseNormalizer()
    
    async def extract(
        self,
        file: Union[BinaryIO, bytes, str],
        file_type: str,
        metadata: dict = None
    ) -> PatientProfile:
        """
        Main extraction entry point.
        
        Args:
            file: File content (binary, bytes, or path)
            file_type: One of 'vcf', 'maf', 'pdf', 'json', 'txt', 'csv'
            metadata: Optional metadata (lab, date, patient_id)
        
        Returns:
            PatientProfile with extracted data
        """
        logger.info(f"Starting extraction for file_type={file_type}")
        
        # Step 1: Parse file
        parser = self.parsers.get(file_type.lower())
        if not parser:
            raise ValueError(f"Unsupported file type: {file_type}")
        
        raw_data = await parser.parse(file, metadata)
        
        # Step 2: Extract mutations
        mutations = self._extract_mutations(raw_data)
        
        # Step 3: Validate mutations
        validated_mutations = []
        for mut in mutations:
            if self.mutation_validator.validate(mut):
                validated_mutations.append(mut)
            else:
                logger.warning(f"Invalid mutation skipped: {mut}")
        
        # Step 4: Normalize mutations
        normalized_mutations = [
            self._normalize_mutation(mut) for mut in validated_mutations
        ]
        
        # Step 5: Extract clinical data
        clinical_data = self._extract_clinical_data(raw_data)
        
        # Step 6: Extract demographics
        demographics = self._extract_demographics(raw_data)
        
        # Step 7: Check data quality
        quality_flags = self.quality_checker.check(
            mutations=normalized_mutations,
            clinical_data=clinical_data
        )
        
        # Step 8: Build PatientProfile
        profile = PatientProfile(
            patient_id=metadata.get('patient_id', self._generate_id()),
            disease=self.disease_normalizer.normalize(
                raw_data.get('disease', 'unknown')
            ),
            mutations=normalized_mutations,
            clinical_data=clinical_data,
            demographics=demographics,
            data_quality_flags=quality_flags,
            extraction_provenance={
                'source': file_type,
                'lab': metadata.get('lab'),
                'extraction_method': parser.__class__.__name__,
                'confidence': self._calculate_confidence(raw_data)
            }
        )
        
        logger.info(f"Extraction complete: {len(normalized_mutations)} mutations")
        return profile
    
    def _extract_mutations(self, raw_data: dict) -> List[Mutation]:
        """Extract mutation objects from raw parsed data."""
        mutations = []
        
        for mut_data in raw_data.get('mutations', []):
            mutation = Mutation(
                gene=mut_data.get('gene', ''),
                variant=mut_data.get('variant', ''),
                hgvs_c=mut_data.get('hgvs_c'),
                hgvs_p=mut_data.get('hgvs_p'),
                chromosome=mut_data.get('chrom'),
                position=mut_data.get('pos'),
                ref=mut_data.get('ref'),
                alt=mut_data.get('alt'),
                vaf=mut_data.get('vaf'),
                coverage=mut_data.get('coverage'),
                zygosity=self._parse_zygosity(mut_data.get('zygosity')),
                source=self._parse_source(mut_data.get('source')),
                classification=mut_data.get('classification')
            )
            mutations.append(mutation)
        
        return mutations
    
    def _normalize_mutation(self, mutation: Mutation) -> Mutation:
        """Normalize gene names and HGVS notation."""
        mutation.gene = self.gene_normalizer.normalize(mutation.gene)
        
        if mutation.hgvs_c:
            mutation.hgvs_c = self.hgvs_normalizer.normalize(mutation.hgvs_c)
        if mutation.hgvs_p:
            mutation.hgvs_p = self.hgvs_normalizer.normalize(mutation.hgvs_p)
        
        return mutation
```

### PDF Parser (LLM-Based)

```python
# api/services/extraction/parsers/pdf_parser.py

from typing import BinaryIO, Union
import io
import logging

# PDF extraction
import fitz  # PyMuPDF
from google import genai  # Gemini for intelligent extraction

logger = logging.getLogger(__name__)

class PDFParser:
    """
    Extract mutation and clinical data from PDF reports using LLM.
    
    Supports:
    - Foundation Medicine reports
    - Tempus reports
    - Guardant Health reports
    - Generic lab reports
    """
    
    EXTRACTION_PROMPT = """
    You are a clinical genomics expert. Extract all mutations and clinical data from this report.
    
    Return JSON with this structure:
    {
        "patient_id": "string or null",
        "disease": "cancer type",
        "mutations": [
            {
                "gene": "BRAF",
                "variant": "V600E",
                "hgvs_p": "p.Val600Glu",
                "hgvs_c": "c.1799T>A",
                "vaf": 0.45,
                "classification": "Pathogenic"
            }
        ],
        "clinical_data": {
            "stage": "IVB",
            "histology": "adenocarcinoma",
            "prior_treatments": ["carboplatin", "paclitaxel"],
            "biomarkers": {
                "TMB": 10.2,
                "MSI": "Stable",
                "PD-L1": "50%"
            }
        },
        "germline_mutations": [],
        "lab_name": "Foundation Medicine",
        "report_date": "2025-01-15"
    }
    
    IMPORTANT:
    - Extract ALL mutations listed, including VUS
    - Use standard HGVS notation
    - Normalize gene symbols to HGNC
    - If data is unclear, mark as null
    
    Report text:
    {report_text}
    """
    
    def __init__(self, model_id: str = "gemini-2.0-flash"):
        self.client = genai.Client()
        self.model_id = model_id
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes],
        metadata: dict = None
    ) -> dict:
        """
        Parse PDF report and extract structured data.
        
        Args:
            file: PDF file content
            metadata: Optional metadata
        
        Returns:
            Dict with extracted data
        """
        # Step 1: Extract text from PDF
        text = self._extract_text(file)
        logger.info(f"Extracted {len(text)} characters from PDF")
        
        # Step 2: Use LLM to extract structured data
        prompt = self.EXTRACTION_PROMPT.format(report_text=text[:50000])  # Limit
        
        response = self.client.models.generate_content(
            model=self.model_id,
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.1  # Low temperature for accuracy
            }
        )
        
        # Step 3: Parse JSON response
        import json
        try:
            extracted = json.loads(response.text)
        except json.JSONDecodeError:
            logger.error("Failed to parse LLM response as JSON")
            extracted = {"mutations": [], "error": "parse_failed"}
        
        # Step 4: Add provenance
        extracted['extraction_method'] = 'llm_pdf_extraction'
        extracted['source_text_length'] = len(text)
        
        return extracted
    
    def _extract_text(self, file: Union[BinaryIO, bytes]) -> str:
        """Extract text content from PDF."""
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        
        return text
```

### VCF Parser

```python
# api/services/extraction/parsers/vcf_parser.py

from typing import BinaryIO, Union, List, Dict
import io

class VCFParser:
    """
    Parse VCF (Variant Call Format) files.
    
    Supports:
    - VCF 4.1, 4.2, 4.3
    - Multi-sample VCFs (uses first sample)
    - Gzipped VCF files
    """
    
    def __init__(self):
        self.required_fields = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes, str],
        metadata: dict = None
    ) -> dict:
        """Parse VCF file and extract mutations."""
        
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        mutations = []
        header_info = {}
        
        for line in file:
            if isinstance(line, bytes):
                line = line.decode('utf-8')
            line = line.strip()
            
            # Parse header
            if line.startswith('##'):
                self._parse_header_line(line, header_info)
                continue
            
            # Parse column header
            if line.startswith('#CHROM'):
                columns = line.split('\t')
                continue
            
            # Parse variant line
            if line and not line.startswith('#'):
                mutation = self._parse_variant_line(line, columns)
                if mutation:
                    mutations.append(mutation)
        
        return {
            'mutations': mutations,
            'vcf_header': header_info,
            'mutation_count': len(mutations)
        }
    
    def _parse_variant_line(self, line: str, columns: List[str]) -> Dict:
        """Parse a single variant line."""
        fields = line.split('\t')
        
        mutation = {
            'chrom': fields[0],
            'pos': int(fields[1]),
            'id': fields[2] if fields[2] != '.' else None,
            'ref': fields[3],
            'alt': fields[4],
            'qual': float(fields[5]) if fields[5] != '.' else None,
            'filter': fields[6],
            'info': self._parse_info(fields[7]) if len(fields) > 7 else {}
        }
        
        # Extract gene and variant from INFO field
        info = mutation['info']
        mutation['gene'] = info.get('GENE', info.get('Gene', ''))
        mutation['hgvs_c'] = info.get('HGVSc', info.get('HGVS_c', ''))
        mutation['hgvs_p'] = info.get('HGVSp', info.get('HGVS_p', ''))
        mutation['variant'] = mutation['hgvs_p'] or f"{mutation['ref']}>{mutation['alt']}"
        
        # Extract VAF if available
        if len(fields) > 9:  # Has sample data
            format_fields = fields[8].split(':')
            sample_data = fields[9].split(':')
            format_dict = dict(zip(format_fields, sample_data))
            
            if 'AF' in format_dict:
                mutation['vaf'] = float(format_dict['AF'])
            elif 'AD' in format_dict:
                # Calculate from allele depth
                ad = [int(x) for x in format_dict['AD'].split(',')]
                if sum(ad) > 0:
                    mutation['vaf'] = ad[1] / sum(ad)
        
        return mutation
    
    def _parse_info(self, info_str: str) -> Dict:
        """Parse INFO field into dictionary."""
        info = {}
        for item in info_str.split(';'):
            if '=' in item:
                key, value = item.split('=', 1)
                info[key] = value
            else:
                info[item] = True
        return info
```

---

## ðŸ§ª TESTING

### Unit Tests

```python
# api/services/extraction/tests/test_vcf_parser.py

import pytest
from ..parsers.vcf_parser import VCFParser

@pytest.fixture
def vcf_content():
    return b"""##fileformat=VCFv4.2
##INFO=<ID=GENE,Number=1,Type=String,Description="Gene name">
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
chr17\t7674872\t.\tG\tA\t.\tPASS\tGENE=TP53;HGVSp=p.Arg175His\tGT:AF\t0/1:0.62
"""

@pytest.mark.asyncio
async def test_vcf_parser_basic(vcf_content):
    parser = VCFParser()
    result = await parser.parse(vcf_content)
    
    assert result['mutation_count'] == 2
    assert result['mutations'][0]['gene'] == 'BRAF'
    assert result['mutations'][0]['hgvs_p'] == 'p.Val600Glu'
    assert result['mutations'][0]['vaf'] == 0.45

@pytest.mark.asyncio
async def test_vcf_parser_missing_vaf(vcf_content):
    # Test handling of missing VAF
    content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF
"""
    parser = VCFParser()
    result = await parser.parse(content)
    
    assert result['mutations'][0]['vaf'] is None
```

### Integration Test

```python
# api/services/extraction/tests/test_integration.py

import pytest
from ..extraction_agent import DataExtractionAgent

@pytest.fixture
def agent():
    return DataExtractionAgent()

@pytest.mark.asyncio
async def test_full_extraction_flow(agent):
    # Test with sample VCF
    vcf_content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
"""
    
    profile = await agent.extract(
        file=vcf_content,
        file_type='vcf',
        metadata={'patient_id': 'TEST-001'}
    )
    
    assert profile.patient_id == 'TEST-001'
    assert len(profile.mutations) == 1
    assert profile.mutations[0].gene == 'BRAF'
    assert profile.extraction_provenance['source'] == 'vcf'
```

---

## ðŸ“‹ IMPLEMENTATION CHECKLIST

### Phase 1: Core Parsers
- [ ] Implement VCF parser (standard format)
- [ ] Implement MAF parser (tab-delimited)
- [ ] Implement JSON parser (structured input)
- [ ] Unit tests for each parser

### Phase 2: PDF Extraction
- [ ] Set up PyMuPDF for text extraction
- [ ] Create LLM extraction prompt
- [ ] Handle Foundation Medicine reports
- [ ] Handle Tempus reports
- [ ] Handle generic reports
- [ ] Unit tests for PDF extraction

### Phase 3: Validation & Normalization
- [ ] Gene name validation (HGNC)
- [ ] HGVS notation validation
- [ ] Zygosity inference
- [ ] Data quality flagging
- [ ] Unit tests for validators

### Phase 4: Integration
- [ ] Create DataExtractionAgent class
- [ ] Wire up all parsers
- [ ] Add provenance tracking
- [ ] Integration tests
- [ ] Performance testing (100 files/minute target)

---

## ðŸ”— DEPENDENCIES

### Python Packages

```txt
# requirements_extraction.txt
PyMuPDF>=1.23.0          # PDF text extraction
google-genai>=0.3.0      # LLM for PDF extraction
pydantic>=2.0.0          # Data validation
hgvs>=1.5.4              # HGVS notation parsing
```

### External Services

| Service | Purpose | Required |
|---------|---------|----------|
| Gemini API | PDF extraction | Yes (for PDF) |
| HGNC API | Gene symbol validation | Optional |

---

## ðŸ“¡ API ENDPOINT

```yaml
POST /api/agents/extract
Content-Type: multipart/form-data

Request:
  file: binary
  file_type: string  # vcf, maf, pdf, json
  metadata: json     # optional

Response:
  patient_profile: PatientProfile
  extraction_time_ms: number
  warnings: string[]
```

---

## âœ… ACCEPTANCE CRITERIA

1. âœ… Can parse VCF files with >95% accuracy
2. âœ… Can parse MAF files with >95% accuracy
3. âœ… Can extract mutations from PDF reports with >85% accuracy
4. âœ… All gene names normalized to HGNC
5. âœ… All HGVS notation validated
6. âœ… Data quality flags generated for missing data
7. âœ… Provenance tracked for all extractions
8. âœ… Processing time <10 seconds for typical files
9. âœ… Unit test coverage >80%

---

---

## ðŸŽ¯ MISSION

Build an intelligent data extraction agent that can:
1. Accept any file format (PDF, VCF, MAF, JSON, TXT)
2. Extract mutations, clinical data, and demographics
3. Validate data quality and flag issues
4. Output a structured `PatientProfile` object

---

## ðŸ“¥ INPUTS

### Accepted File Types

| Format | Description | Parser Needed |
|--------|-------------|---------------|
| **VCF** | Variant Call Format | Standard VCF parser |
| **MAF** | Mutation Annotation Format | Tab-delimited parser |
| **PDF** | NGS reports from labs | LLM-based extraction |
| **JSON** | Structured mutation data | JSON parser |
| **TXT/CSV** | Clinical notes, lab results | Text extraction |

### Example Input

```json
{
  "file": "binary_file_content",
  "file_type": "pdf",
  "file_name": "Foundation_One_Report.pdf",
  "metadata": {
    "lab": "Foundation Medicine",
    "report_date": "2025-01-15"
  }
}
```

---

## ðŸ“¤ OUTPUTS

### PatientProfile Schema

```python
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
from enum import Enum

class Zygosity(Enum):
    HETEROZYGOUS = "heterozygous"
    HOMOZYGOUS = "homozygous"
    HEMIZYGOUS = "hemizygous"
    UNKNOWN = "unknown"

class MutationSource(Enum):
    NGS = "ngs"
    IHC = "ihc"
    FISH = "fish"
    PCR = "pcr"
    INFERRED = "inferred"

@dataclass
class Mutation:
    gene: str
    variant: str                    # e.g., "c.1239delA" or "p.V600E"
    hgvs_c: Optional[str] = None    # Coding change
    hgvs_p: Optional[str] = None    # Protein change
    chromosome: Optional[str] = None
    position: Optional[int] = None
    ref: Optional[str] = None
    alt: Optional[str] = None
    vaf: Optional[float] = None     # Variant allele frequency
    coverage: Optional[int] = None
    zygosity: Zygosity = Zygosity.UNKNOWN
    source: MutationSource = MutationSource.NGS
    classification: Optional[str] = None  # Pathogenic, VUS, Benign

@dataclass
class GermlinePanel:
    genes_tested: List[str]
    pathogenic: Dict[str, str]      # gene -> variant
    vus: Dict[str, str]
    negative: List[str]
    panel_name: Optional[str] = None
    test_date: Optional[datetime] = None

@dataclass
class ClinicalData:
    stage: Optional[str] = None         # e.g., "IVB"
    histology: Optional[str] = None     # e.g., "high_grade_serous"
    grade: Optional[str] = None
    ecog_ps: Optional[int] = None       # Performance status
    biomarkers: Dict[str, any] = None   # CA-125, HER2, etc.
    prior_treatments: List[str] = None
    current_treatment: Optional[str] = None

@dataclass
class Demographics:
    age: Optional[int] = None
    sex: Optional[str] = None
    ethnicity: Optional[str] = None

@dataclass
class PatientProfile:
    patient_id: str
    disease: str                        # e.g., "ovarian_cancer"
    mutations: List[Mutation]
    germline_panel: Optional[GermlinePanel] = None
    clinical_data: Optional[ClinicalData] = None
    demographics: Optional[Demographics] = None
    data_quality_flags: List[str] = None  # ["ca125_missing", "hrd_pending"]
    extraction_provenance: Dict[str, any] = None  # Source, confidence, method
    created_at: datetime = None
    updated_at: datetime = None
```

---

## ðŸ—ï¸ IMPLEMENTATION

### File Structure

```
api/services/extraction/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ extraction_agent.py          # Main agent logic
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vcf_parser.py            # VCF file parsing
â”‚   â”œâ”€â”€ maf_parser.py            # MAF file parsing
â”‚   â”œâ”€â”€ pdf_parser.py            # PDF extraction with LLM
â”‚   â”œâ”€â”€ json_parser.py           # JSON parsing
â”‚   â””â”€â”€ text_parser.py           # Clinical notes extraction
â”œâ”€â”€ validators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mutation_validator.py    # Validate mutation format
â”‚   â”œâ”€â”€ gene_validator.py        # Validate gene names
â”‚   â””â”€â”€ quality_checker.py       # Data quality assessment
â”œâ”€â”€ normalizers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hgvs_normalizer.py       # Normalize HGVS notation
â”‚   â”œâ”€â”€ gene_normalizer.py       # Normalize gene symbols
â”‚   â””â”€â”€ disease_normalizer.py    # Normalize disease terms
â””â”€â”€ tests/
    â”œâ”€â”€ test_vcf_parser.py
    â”œâ”€â”€ test_pdf_parser.py
    â””â”€â”€ test_integration.py
```

### Core Agent Implementation

```python
# api/services/extraction/extraction_agent.py

from typing import Union, BinaryIO
from pathlib import Path
import logging

from .parsers import VCFParser, MAFParser, PDFParser, JSONParser, TextParser
from .validators import MutationValidator, GeneValidator, QualityChecker
from .normalizers import HGVSNormalizer, GeneNormalizer, DiseaseNormalizer
from ..models import PatientProfile, Mutation, DataQualityFlag

logger = logging.getLogger(__name__)

class DataExtractionAgent:
    """
    Intelligent agent for extracting structured patient data from various file formats.
    
    Capabilities:
    - Multi-format parsing (VCF, MAF, PDF, JSON, TXT)
    - Mutation validation and normalization
    - Data quality assessment
    - Provenance tracking
    """
    
    def __init__(self):
        # Initialize parsers
        self.parsers = {
            'vcf': VCFParser(),
            'maf': MAFParser(),
            'pdf': PDFParser(),  # Uses LLM for extraction
            'json': JSONParser(),
            'txt': TextParser(),
            'csv': TextParser(),
        }
        
        # Initialize validators
        self.mutation_validator = MutationValidator()
        self.gene_validator = GeneValidator()
        self.quality_checker = QualityChecker()
        
        # Initialize normalizers
        self.hgvs_normalizer = HGVSNormalizer()
        self.gene_normalizer = GeneNormalizer()
        self.disease_normalizer = DiseaseNormalizer()
    
    async def extract(
        self,
        file: Union[BinaryIO, bytes, str],
        file_type: str,
        metadata: dict = None
    ) -> PatientProfile:
        """
        Main extraction entry point.
        
        Args:
            file: File content (binary, bytes, or path)
            file_type: One of 'vcf', 'maf', 'pdf', 'json', 'txt', 'csv'
            metadata: Optional metadata (lab, date, patient_id)
        
        Returns:
            PatientProfile with extracted data
        """
        logger.info(f"Starting extraction for file_type={file_type}")
        
        # Step 1: Parse file
        parser = self.parsers.get(file_type.lower())
        if not parser:
            raise ValueError(f"Unsupported file type: {file_type}")
        
        raw_data = await parser.parse(file, metadata)
        
        # Step 2: Extract mutations
        mutations = self._extract_mutations(raw_data)
        
        # Step 3: Validate mutations
        validated_mutations = []
        for mut in mutations:
            if self.mutation_validator.validate(mut):
                validated_mutations.append(mut)
            else:
                logger.warning(f"Invalid mutation skipped: {mut}")
        
        # Step 4: Normalize mutations
        normalized_mutations = [
            self._normalize_mutation(mut) for mut in validated_mutations
        ]
        
        # Step 5: Extract clinical data
        clinical_data = self._extract_clinical_data(raw_data)
        
        # Step 6: Extract demographics
        demographics = self._extract_demographics(raw_data)
        
        # Step 7: Check data quality
        quality_flags = self.quality_checker.check(
            mutations=normalized_mutations,
            clinical_data=clinical_data
        )
        
        # Step 8: Build PatientProfile
        profile = PatientProfile(
            patient_id=metadata.get('patient_id', self._generate_id()),
            disease=self.disease_normalizer.normalize(
                raw_data.get('disease', 'unknown')
            ),
            mutations=normalized_mutations,
            clinical_data=clinical_data,
            demographics=demographics,
            data_quality_flags=quality_flags,
            extraction_provenance={
                'source': file_type,
                'lab': metadata.get('lab'),
                'extraction_method': parser.__class__.__name__,
                'confidence': self._calculate_confidence(raw_data)
            }
        )
        
        logger.info(f"Extraction complete: {len(normalized_mutations)} mutations")
        return profile
    
    def _extract_mutations(self, raw_data: dict) -> List[Mutation]:
        """Extract mutation objects from raw parsed data."""
        mutations = []
        
        for mut_data in raw_data.get('mutations', []):
            mutation = Mutation(
                gene=mut_data.get('gene', ''),
                variant=mut_data.get('variant', ''),
                hgvs_c=mut_data.get('hgvs_c'),
                hgvs_p=mut_data.get('hgvs_p'),
                chromosome=mut_data.get('chrom'),
                position=mut_data.get('pos'),
                ref=mut_data.get('ref'),
                alt=mut_data.get('alt'),
                vaf=mut_data.get('vaf'),
                coverage=mut_data.get('coverage'),
                zygosity=self._parse_zygosity(mut_data.get('zygosity')),
                source=self._parse_source(mut_data.get('source')),
                classification=mut_data.get('classification')
            )
            mutations.append(mutation)
        
        return mutations
    
    def _normalize_mutation(self, mutation: Mutation) -> Mutation:
        """Normalize gene names and HGVS notation."""
        mutation.gene = self.gene_normalizer.normalize(mutation.gene)
        
        if mutation.hgvs_c:
            mutation.hgvs_c = self.hgvs_normalizer.normalize(mutation.hgvs_c)
        if mutation.hgvs_p:
            mutation.hgvs_p = self.hgvs_normalizer.normalize(mutation.hgvs_p)
        
        return mutation
```

### PDF Parser (LLM-Based)

```python
# api/services/extraction/parsers/pdf_parser.py

from typing import BinaryIO, Union
import io
import logging

# PDF extraction
import fitz  # PyMuPDF
from google import genai  # Gemini for intelligent extraction

logger = logging.getLogger(__name__)

class PDFParser:
    """
    Extract mutation and clinical data from PDF reports using LLM.
    
    Supports:
    - Foundation Medicine reports
    - Tempus reports
    - Guardant Health reports
    - Generic lab reports
    """
    
    EXTRACTION_PROMPT = """
    You are a clinical genomics expert. Extract all mutations and clinical data from this report.
    
    Return JSON with this structure:
    {
        "patient_id": "string or null",
        "disease": "cancer type",
        "mutations": [
            {
                "gene": "BRAF",
                "variant": "V600E",
                "hgvs_p": "p.Val600Glu",
                "hgvs_c": "c.1799T>A",
                "vaf": 0.45,
                "classification": "Pathogenic"
            }
        ],
        "clinical_data": {
            "stage": "IVB",
            "histology": "adenocarcinoma",
            "prior_treatments": ["carboplatin", "paclitaxel"],
            "biomarkers": {
                "TMB": 10.2,
                "MSI": "Stable",
                "PD-L1": "50%"
            }
        },
        "germline_mutations": [],
        "lab_name": "Foundation Medicine",
        "report_date": "2025-01-15"
    }
    
    IMPORTANT:
    - Extract ALL mutations listed, including VUS
    - Use standard HGVS notation
    - Normalize gene symbols to HGNC
    - If data is unclear, mark as null
    
    Report text:
    {report_text}
    """
    
    def __init__(self, model_id: str = "gemini-2.0-flash"):
        self.client = genai.Client()
        self.model_id = model_id
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes],
        metadata: dict = None
    ) -> dict:
        """
        Parse PDF report and extract structured data.
        
        Args:
            file: PDF file content
            metadata: Optional metadata
        
        Returns:
            Dict with extracted data
        """
        # Step 1: Extract text from PDF
        text = self._extract_text(file)
        logger.info(f"Extracted {len(text)} characters from PDF")
        
        # Step 2: Use LLM to extract structured data
        prompt = self.EXTRACTION_PROMPT.format(report_text=text[:50000])  # Limit
        
        response = self.client.models.generate_content(
            model=self.model_id,
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.1  # Low temperature for accuracy
            }
        )
        
        # Step 3: Parse JSON response
        import json
        try:
            extracted = json.loads(response.text)
        except json.JSONDecodeError:
            logger.error("Failed to parse LLM response as JSON")
            extracted = {"mutations": [], "error": "parse_failed"}
        
        # Step 4: Add provenance
        extracted['extraction_method'] = 'llm_pdf_extraction'
        extracted['source_text_length'] = len(text)
        
        return extracted
    
    def _extract_text(self, file: Union[BinaryIO, bytes]) -> str:
        """Extract text content from PDF."""
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        
        return text
```

### VCF Parser

```python
# api/services/extraction/parsers/vcf_parser.py

from typing import BinaryIO, Union, List, Dict
import io

class VCFParser:
    """
    Parse VCF (Variant Call Format) files.
    
    Supports:
    - VCF 4.1, 4.2, 4.3
    - Multi-sample VCFs (uses first sample)
    - Gzipped VCF files
    """
    
    def __init__(self):
        self.required_fields = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes, str],
        metadata: dict = None
    ) -> dict:
        """Parse VCF file and extract mutations."""
        
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        mutations = []
        header_info = {}
        
        for line in file:
            if isinstance(line, bytes):
                line = line.decode('utf-8')
            line = line.strip()
            
            # Parse header
            if line.startswith('##'):
                self._parse_header_line(line, header_info)
                continue
            
            # Parse column header
            if line.startswith('#CHROM'):
                columns = line.split('\t')
                continue
            
            # Parse variant line
            if line and not line.startswith('#'):
                mutation = self._parse_variant_line(line, columns)
                if mutation:
                    mutations.append(mutation)
        
        return {
            'mutations': mutations,
            'vcf_header': header_info,
            'mutation_count': len(mutations)
        }
    
    def _parse_variant_line(self, line: str, columns: List[str]) -> Dict:
        """Parse a single variant line."""
        fields = line.split('\t')
        
        mutation = {
            'chrom': fields[0],
            'pos': int(fields[1]),
            'id': fields[2] if fields[2] != '.' else None,
            'ref': fields[3],
            'alt': fields[4],
            'qual': float(fields[5]) if fields[5] != '.' else None,
            'filter': fields[6],
            'info': self._parse_info(fields[7]) if len(fields) > 7 else {}
        }
        
        # Extract gene and variant from INFO field
        info = mutation['info']
        mutation['gene'] = info.get('GENE', info.get('Gene', ''))
        mutation['hgvs_c'] = info.get('HGVSc', info.get('HGVS_c', ''))
        mutation['hgvs_p'] = info.get('HGVSp', info.get('HGVS_p', ''))
        mutation['variant'] = mutation['hgvs_p'] or f"{mutation['ref']}>{mutation['alt']}"
        
        # Extract VAF if available
        if len(fields) > 9:  # Has sample data
            format_fields = fields[8].split(':')
            sample_data = fields[9].split(':')
            format_dict = dict(zip(format_fields, sample_data))
            
            if 'AF' in format_dict:
                mutation['vaf'] = float(format_dict['AF'])
            elif 'AD' in format_dict:
                # Calculate from allele depth
                ad = [int(x) for x in format_dict['AD'].split(',')]
                if sum(ad) > 0:
                    mutation['vaf'] = ad[1] / sum(ad)
        
        return mutation
    
    def _parse_info(self, info_str: str) -> Dict:
        """Parse INFO field into dictionary."""
        info = {}
        for item in info_str.split(';'):
            if '=' in item:
                key, value = item.split('=', 1)
                info[key] = value
            else:
                info[item] = True
        return info
```

---

## ðŸ§ª TESTING

### Unit Tests

```python
# api/services/extraction/tests/test_vcf_parser.py

import pytest
from ..parsers.vcf_parser import VCFParser

@pytest.fixture
def vcf_content():
    return b"""##fileformat=VCFv4.2
##INFO=<ID=GENE,Number=1,Type=String,Description="Gene name">
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
chr17\t7674872\t.\tG\tA\t.\tPASS\tGENE=TP53;HGVSp=p.Arg175His\tGT:AF\t0/1:0.62
"""

@pytest.mark.asyncio
async def test_vcf_parser_basic(vcf_content):
    parser = VCFParser()
    result = await parser.parse(vcf_content)
    
    assert result['mutation_count'] == 2
    assert result['mutations'][0]['gene'] == 'BRAF'
    assert result['mutations'][0]['hgvs_p'] == 'p.Val600Glu'
    assert result['mutations'][0]['vaf'] == 0.45

@pytest.mark.asyncio
async def test_vcf_parser_missing_vaf(vcf_content):
    # Test handling of missing VAF
    content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF
"""
    parser = VCFParser()
    result = await parser.parse(content)
    
    assert result['mutations'][0]['vaf'] is None
```

### Integration Test

```python
# api/services/extraction/tests/test_integration.py

import pytest
from ..extraction_agent import DataExtractionAgent

@pytest.fixture
def agent():
    return DataExtractionAgent()

@pytest.mark.asyncio
async def test_full_extraction_flow(agent):
    # Test with sample VCF
    vcf_content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
"""
    
    profile = await agent.extract(
        file=vcf_content,
        file_type='vcf',
        metadata={'patient_id': 'TEST-001'}
    )
    
    assert profile.patient_id == 'TEST-001'
    assert len(profile.mutations) == 1
    assert profile.mutations[0].gene == 'BRAF'
    assert profile.extraction_provenance['source'] == 'vcf'
```

---

## ðŸ“‹ IMPLEMENTATION CHECKLIST

### Phase 1: Core Parsers
- [ ] Implement VCF parser (standard format)
- [ ] Implement MAF parser (tab-delimited)
- [ ] Implement JSON parser (structured input)
- [ ] Unit tests for each parser

### Phase 2: PDF Extraction
- [ ] Set up PyMuPDF for text extraction
- [ ] Create LLM extraction prompt
- [ ] Handle Foundation Medicine reports
- [ ] Handle Tempus reports
- [ ] Handle generic reports
- [ ] Unit tests for PDF extraction

### Phase 3: Validation & Normalization
- [ ] Gene name validation (HGNC)
- [ ] HGVS notation validation
- [ ] Zygosity inference
- [ ] Data quality flagging
- [ ] Unit tests for validators

### Phase 4: Integration
- [ ] Create DataExtractionAgent class
- [ ] Wire up all parsers
- [ ] Add provenance tracking
- [ ] Integration tests
- [ ] Performance testing (100 files/minute target)

---

## ðŸ”— DEPENDENCIES

### Python Packages

```txt
# requirements_extraction.txt
PyMuPDF>=1.23.0          # PDF text extraction
google-genai>=0.3.0      # LLM for PDF extraction
pydantic>=2.0.0          # Data validation
hgvs>=1.5.4              # HGVS notation parsing
```

### External Services

| Service | Purpose | Required |
|---------|---------|----------|
| Gemini API | PDF extraction | Yes (for PDF) |
| HGNC API | Gene symbol validation | Optional |

---

## ðŸ“¡ API ENDPOINT

```yaml
POST /api/agents/extract
Content-Type: multipart/form-data

Request:
  file: binary
  file_type: string  # vcf, maf, pdf, json
  metadata: json     # optional

Response:
  patient_profile: PatientProfile
  extraction_time_ms: number
  warnings: string[]
```

---

## âœ… ACCEPTANCE CRITERIA

1. âœ… Can parse VCF files with >95% accuracy
2. âœ… Can parse MAF files with >95% accuracy
3. âœ… Can extract mutations from PDF reports with >85% accuracy
4. âœ… All gene names normalized to HGNC
5. âœ… All HGVS notation validated
6. âœ… Data quality flags generated for missing data
7. âœ… Provenance tracked for all extractions
8. âœ… Processing time <10 seconds for typical files
9. âœ… Unit test coverage >80%

---

---

## ðŸŽ¯ MISSION

Build an intelligent data extraction agent that can:
1. Accept any file format (PDF, VCF, MAF, JSON, TXT)
2. Extract mutations, clinical data, and demographics
3. Validate data quality and flag issues
4. Output a structured `PatientProfile` object

---

## ðŸ“¥ INPUTS

### Accepted File Types

| Format | Description | Parser Needed |
|--------|-------------|---------------|
| **VCF** | Variant Call Format | Standard VCF parser |
| **MAF** | Mutation Annotation Format | Tab-delimited parser |
| **PDF** | NGS reports from labs | LLM-based extraction |
| **JSON** | Structured mutation data | JSON parser |
| **TXT/CSV** | Clinical notes, lab results | Text extraction |

### Example Input

```json
{
  "file": "binary_file_content",
  "file_type": "pdf",
  "file_name": "Foundation_One_Report.pdf",
  "metadata": {
    "lab": "Foundation Medicine",
    "report_date": "2025-01-15"
  }
}
```

---

## ðŸ“¤ OUTPUTS

### PatientProfile Schema

```python
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
from enum import Enum

class Zygosity(Enum):
    HETEROZYGOUS = "heterozygous"
    HOMOZYGOUS = "homozygous"
    HEMIZYGOUS = "hemizygous"
    UNKNOWN = "unknown"

class MutationSource(Enum):
    NGS = "ngs"
    IHC = "ihc"
    FISH = "fish"
    PCR = "pcr"
    INFERRED = "inferred"

@dataclass
class Mutation:
    gene: str
    variant: str                    # e.g., "c.1239delA" or "p.V600E"
    hgvs_c: Optional[str] = None    # Coding change
    hgvs_p: Optional[str] = None    # Protein change
    chromosome: Optional[str] = None
    position: Optional[int] = None
    ref: Optional[str] = None
    alt: Optional[str] = None
    vaf: Optional[float] = None     # Variant allele frequency
    coverage: Optional[int] = None
    zygosity: Zygosity = Zygosity.UNKNOWN
    source: MutationSource = MutationSource.NGS
    classification: Optional[str] = None  # Pathogenic, VUS, Benign

@dataclass
class GermlinePanel:
    genes_tested: List[str]
    pathogenic: Dict[str, str]      # gene -> variant
    vus: Dict[str, str]
    negative: List[str]
    panel_name: Optional[str] = None
    test_date: Optional[datetime] = None

@dataclass
class ClinicalData:
    stage: Optional[str] = None         # e.g., "IVB"
    histology: Optional[str] = None     # e.g., "high_grade_serous"
    grade: Optional[str] = None
    ecog_ps: Optional[int] = None       # Performance status
    biomarkers: Dict[str, any] = None   # CA-125, HER2, etc.
    prior_treatments: List[str] = None
    current_treatment: Optional[str] = None

@dataclass
class Demographics:
    age: Optional[int] = None
    sex: Optional[str] = None
    ethnicity: Optional[str] = None

@dataclass
class PatientProfile:
    patient_id: str
    disease: str                        # e.g., "ovarian_cancer"
    mutations: List[Mutation]
    germline_panel: Optional[GermlinePanel] = None
    clinical_data: Optional[ClinicalData] = None
    demographics: Optional[Demographics] = None
    data_quality_flags: List[str] = None  # ["ca125_missing", "hrd_pending"]
    extraction_provenance: Dict[str, any] = None  # Source, confidence, method
    created_at: datetime = None
    updated_at: datetime = None
```

---

## ðŸ—ï¸ IMPLEMENTATION

### File Structure

```
api/services/extraction/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ extraction_agent.py          # Main agent logic
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vcf_parser.py            # VCF file parsing
â”‚   â”œâ”€â”€ maf_parser.py            # MAF file parsing
â”‚   â”œâ”€â”€ pdf_parser.py            # PDF extraction with LLM
â”‚   â”œâ”€â”€ json_parser.py           # JSON parsing
â”‚   â””â”€â”€ text_parser.py           # Clinical notes extraction
â”œâ”€â”€ validators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mutation_validator.py    # Validate mutation format
â”‚   â”œâ”€â”€ gene_validator.py        # Validate gene names
â”‚   â””â”€â”€ quality_checker.py       # Data quality assessment
â”œâ”€â”€ normalizers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hgvs_normalizer.py       # Normalize HGVS notation
â”‚   â”œâ”€â”€ gene_normalizer.py       # Normalize gene symbols
â”‚   â””â”€â”€ disease_normalizer.py    # Normalize disease terms
â””â”€â”€ tests/
    â”œâ”€â”€ test_vcf_parser.py
    â”œâ”€â”€ test_pdf_parser.py
    â””â”€â”€ test_integration.py
```

### Core Agent Implementation

```python
# api/services/extraction/extraction_agent.py

from typing import Union, BinaryIO
from pathlib import Path
import logging

from .parsers import VCFParser, MAFParser, PDFParser, JSONParser, TextParser
from .validators import MutationValidator, GeneValidator, QualityChecker
from .normalizers import HGVSNormalizer, GeneNormalizer, DiseaseNormalizer
from ..models import PatientProfile, Mutation, DataQualityFlag

logger = logging.getLogger(__name__)

class DataExtractionAgent:
    """
    Intelligent agent for extracting structured patient data from various file formats.
    
    Capabilities:
    - Multi-format parsing (VCF, MAF, PDF, JSON, TXT)
    - Mutation validation and normalization
    - Data quality assessment
    - Provenance tracking
    """
    
    def __init__(self):
        # Initialize parsers
        self.parsers = {
            'vcf': VCFParser(),
            'maf': MAFParser(),
            'pdf': PDFParser(),  # Uses LLM for extraction
            'json': JSONParser(),
            'txt': TextParser(),
            'csv': TextParser(),
        }
        
        # Initialize validators
        self.mutation_validator = MutationValidator()
        self.gene_validator = GeneValidator()
        self.quality_checker = QualityChecker()
        
        # Initialize normalizers
        self.hgvs_normalizer = HGVSNormalizer()
        self.gene_normalizer = GeneNormalizer()
        self.disease_normalizer = DiseaseNormalizer()
    
    async def extract(
        self,
        file: Union[BinaryIO, bytes, str],
        file_type: str,
        metadata: dict = None
    ) -> PatientProfile:
        """
        Main extraction entry point.
        
        Args:
            file: File content (binary, bytes, or path)
            file_type: One of 'vcf', 'maf', 'pdf', 'json', 'txt', 'csv'
            metadata: Optional metadata (lab, date, patient_id)
        
        Returns:
            PatientProfile with extracted data
        """
        logger.info(f"Starting extraction for file_type={file_type}")
        
        # Step 1: Parse file
        parser = self.parsers.get(file_type.lower())
        if not parser:
            raise ValueError(f"Unsupported file type: {file_type}")
        
        raw_data = await parser.parse(file, metadata)
        
        # Step 2: Extract mutations
        mutations = self._extract_mutations(raw_data)
        
        # Step 3: Validate mutations
        validated_mutations = []
        for mut in mutations:
            if self.mutation_validator.validate(mut):
                validated_mutations.append(mut)
            else:
                logger.warning(f"Invalid mutation skipped: {mut}")
        
        # Step 4: Normalize mutations
        normalized_mutations = [
            self._normalize_mutation(mut) for mut in validated_mutations
        ]
        
        # Step 5: Extract clinical data
        clinical_data = self._extract_clinical_data(raw_data)
        
        # Step 6: Extract demographics
        demographics = self._extract_demographics(raw_data)
        
        # Step 7: Check data quality
        quality_flags = self.quality_checker.check(
            mutations=normalized_mutations,
            clinical_data=clinical_data
        )
        
        # Step 8: Build PatientProfile
        profile = PatientProfile(
            patient_id=metadata.get('patient_id', self._generate_id()),
            disease=self.disease_normalizer.normalize(
                raw_data.get('disease', 'unknown')
            ),
            mutations=normalized_mutations,
            clinical_data=clinical_data,
            demographics=demographics,
            data_quality_flags=quality_flags,
            extraction_provenance={
                'source': file_type,
                'lab': metadata.get('lab'),
                'extraction_method': parser.__class__.__name__,
                'confidence': self._calculate_confidence(raw_data)
            }
        )
        
        logger.info(f"Extraction complete: {len(normalized_mutations)} mutations")
        return profile
    
    def _extract_mutations(self, raw_data: dict) -> List[Mutation]:
        """Extract mutation objects from raw parsed data."""
        mutations = []
        
        for mut_data in raw_data.get('mutations', []):
            mutation = Mutation(
                gene=mut_data.get('gene', ''),
                variant=mut_data.get('variant', ''),
                hgvs_c=mut_data.get('hgvs_c'),
                hgvs_p=mut_data.get('hgvs_p'),
                chromosome=mut_data.get('chrom'),
                position=mut_data.get('pos'),
                ref=mut_data.get('ref'),
                alt=mut_data.get('alt'),
                vaf=mut_data.get('vaf'),
                coverage=mut_data.get('coverage'),
                zygosity=self._parse_zygosity(mut_data.get('zygosity')),
                source=self._parse_source(mut_data.get('source')),
                classification=mut_data.get('classification')
            )
            mutations.append(mutation)
        
        return mutations
    
    def _normalize_mutation(self, mutation: Mutation) -> Mutation:
        """Normalize gene names and HGVS notation."""
        mutation.gene = self.gene_normalizer.normalize(mutation.gene)
        
        if mutation.hgvs_c:
            mutation.hgvs_c = self.hgvs_normalizer.normalize(mutation.hgvs_c)
        if mutation.hgvs_p:
            mutation.hgvs_p = self.hgvs_normalizer.normalize(mutation.hgvs_p)
        
        return mutation
```

### PDF Parser (LLM-Based)

```python
# api/services/extraction/parsers/pdf_parser.py

from typing import BinaryIO, Union
import io
import logging

# PDF extraction
import fitz  # PyMuPDF
from google import genai  # Gemini for intelligent extraction

logger = logging.getLogger(__name__)

class PDFParser:
    """
    Extract mutation and clinical data from PDF reports using LLM.
    
    Supports:
    - Foundation Medicine reports
    - Tempus reports
    - Guardant Health reports
    - Generic lab reports
    """
    
    EXTRACTION_PROMPT = """
    You are a clinical genomics expert. Extract all mutations and clinical data from this report.
    
    Return JSON with this structure:
    {
        "patient_id": "string or null",
        "disease": "cancer type",
        "mutations": [
            {
                "gene": "BRAF",
                "variant": "V600E",
                "hgvs_p": "p.Val600Glu",
                "hgvs_c": "c.1799T>A",
                "vaf": 0.45,
                "classification": "Pathogenic"
            }
        ],
        "clinical_data": {
            "stage": "IVB",
            "histology": "adenocarcinoma",
            "prior_treatments": ["carboplatin", "paclitaxel"],
            "biomarkers": {
                "TMB": 10.2,
                "MSI": "Stable",
                "PD-L1": "50%"
            }
        },
        "germline_mutations": [],
        "lab_name": "Foundation Medicine",
        "report_date": "2025-01-15"
    }
    
    IMPORTANT:
    - Extract ALL mutations listed, including VUS
    - Use standard HGVS notation
    - Normalize gene symbols to HGNC
    - If data is unclear, mark as null
    
    Report text:
    {report_text}
    """
    
    def __init__(self, model_id: str = "gemini-2.0-flash"):
        self.client = genai.Client()
        self.model_id = model_id
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes],
        metadata: dict = None
    ) -> dict:
        """
        Parse PDF report and extract structured data.
        
        Args:
            file: PDF file content
            metadata: Optional metadata
        
        Returns:
            Dict with extracted data
        """
        # Step 1: Extract text from PDF
        text = self._extract_text(file)
        logger.info(f"Extracted {len(text)} characters from PDF")
        
        # Step 2: Use LLM to extract structured data
        prompt = self.EXTRACTION_PROMPT.format(report_text=text[:50000])  # Limit
        
        response = self.client.models.generate_content(
            model=self.model_id,
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.1  # Low temperature for accuracy
            }
        )
        
        # Step 3: Parse JSON response
        import json
        try:
            extracted = json.loads(response.text)
        except json.JSONDecodeError:
            logger.error("Failed to parse LLM response as JSON")
            extracted = {"mutations": [], "error": "parse_failed"}
        
        # Step 4: Add provenance
        extracted['extraction_method'] = 'llm_pdf_extraction'
        extracted['source_text_length'] = len(text)
        
        return extracted
    
    def _extract_text(self, file: Union[BinaryIO, bytes]) -> str:
        """Extract text content from PDF."""
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        
        return text
```

### VCF Parser

```python
# api/services/extraction/parsers/vcf_parser.py

from typing import BinaryIO, Union, List, Dict
import io

class VCFParser:
    """
    Parse VCF (Variant Call Format) files.
    
    Supports:
    - VCF 4.1, 4.2, 4.3
    - Multi-sample VCFs (uses first sample)
    - Gzipped VCF files
    """
    
    def __init__(self):
        self.required_fields = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes, str],
        metadata: dict = None
    ) -> dict:
        """Parse VCF file and extract mutations."""
        
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        mutations = []
        header_info = {}
        
        for line in file:
            if isinstance(line, bytes):
                line = line.decode('utf-8')
            line = line.strip()
            
            # Parse header
            if line.startswith('##'):
                self._parse_header_line(line, header_info)
                continue
            
            # Parse column header
            if line.startswith('#CHROM'):
                columns = line.split('\t')
                continue
            
            # Parse variant line
            if line and not line.startswith('#'):
                mutation = self._parse_variant_line(line, columns)
                if mutation:
                    mutations.append(mutation)
        
        return {
            'mutations': mutations,
            'vcf_header': header_info,
            'mutation_count': len(mutations)
        }
    
    def _parse_variant_line(self, line: str, columns: List[str]) -> Dict:
        """Parse a single variant line."""
        fields = line.split('\t')
        
        mutation = {
            'chrom': fields[0],
            'pos': int(fields[1]),
            'id': fields[2] if fields[2] != '.' else None,
            'ref': fields[3],
            'alt': fields[4],
            'qual': float(fields[5]) if fields[5] != '.' else None,
            'filter': fields[6],
            'info': self._parse_info(fields[7]) if len(fields) > 7 else {}
        }
        
        # Extract gene and variant from INFO field
        info = mutation['info']
        mutation['gene'] = info.get('GENE', info.get('Gene', ''))
        mutation['hgvs_c'] = info.get('HGVSc', info.get('HGVS_c', ''))
        mutation['hgvs_p'] = info.get('HGVSp', info.get('HGVS_p', ''))
        mutation['variant'] = mutation['hgvs_p'] or f"{mutation['ref']}>{mutation['alt']}"
        
        # Extract VAF if available
        if len(fields) > 9:  # Has sample data
            format_fields = fields[8].split(':')
            sample_data = fields[9].split(':')
            format_dict = dict(zip(format_fields, sample_data))
            
            if 'AF' in format_dict:
                mutation['vaf'] = float(format_dict['AF'])
            elif 'AD' in format_dict:
                # Calculate from allele depth
                ad = [int(x) for x in format_dict['AD'].split(',')]
                if sum(ad) > 0:
                    mutation['vaf'] = ad[1] / sum(ad)
        
        return mutation
    
    def _parse_info(self, info_str: str) -> Dict:
        """Parse INFO field into dictionary."""
        info = {}
        for item in info_str.split(';'):
            if '=' in item:
                key, value = item.split('=', 1)
                info[key] = value
            else:
                info[item] = True
        return info
```

---

## ðŸ§ª TESTING

### Unit Tests

```python
# api/services/extraction/tests/test_vcf_parser.py

import pytest
from ..parsers.vcf_parser import VCFParser

@pytest.fixture
def vcf_content():
    return b"""##fileformat=VCFv4.2
##INFO=<ID=GENE,Number=1,Type=String,Description="Gene name">
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
chr17\t7674872\t.\tG\tA\t.\tPASS\tGENE=TP53;HGVSp=p.Arg175His\tGT:AF\t0/1:0.62
"""

@pytest.mark.asyncio
async def test_vcf_parser_basic(vcf_content):
    parser = VCFParser()
    result = await parser.parse(vcf_content)
    
    assert result['mutation_count'] == 2
    assert result['mutations'][0]['gene'] == 'BRAF'
    assert result['mutations'][0]['hgvs_p'] == 'p.Val600Glu'
    assert result['mutations'][0]['vaf'] == 0.45

@pytest.mark.asyncio
async def test_vcf_parser_missing_vaf(vcf_content):
    # Test handling of missing VAF
    content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF
"""
    parser = VCFParser()
    result = await parser.parse(content)
    
    assert result['mutations'][0]['vaf'] is None
```

### Integration Test

```python
# api/services/extraction/tests/test_integration.py

import pytest
from ..extraction_agent import DataExtractionAgent

@pytest.fixture
def agent():
    return DataExtractionAgent()

@pytest.mark.asyncio
async def test_full_extraction_flow(agent):
    # Test with sample VCF
    vcf_content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
"""
    
    profile = await agent.extract(
        file=vcf_content,
        file_type='vcf',
        metadata={'patient_id': 'TEST-001'}
    )
    
    assert profile.patient_id == 'TEST-001'
    assert len(profile.mutations) == 1
    assert profile.mutations[0].gene == 'BRAF'
    assert profile.extraction_provenance['source'] == 'vcf'
```

---

## ðŸ“‹ IMPLEMENTATION CHECKLIST

### Phase 1: Core Parsers
- [ ] Implement VCF parser (standard format)
- [ ] Implement MAF parser (tab-delimited)
- [ ] Implement JSON parser (structured input)
- [ ] Unit tests for each parser

### Phase 2: PDF Extraction
- [ ] Set up PyMuPDF for text extraction
- [ ] Create LLM extraction prompt
- [ ] Handle Foundation Medicine reports
- [ ] Handle Tempus reports
- [ ] Handle generic reports
- [ ] Unit tests for PDF extraction

### Phase 3: Validation & Normalization
- [ ] Gene name validation (HGNC)
- [ ] HGVS notation validation
- [ ] Zygosity inference
- [ ] Data quality flagging
- [ ] Unit tests for validators

### Phase 4: Integration
- [ ] Create DataExtractionAgent class
- [ ] Wire up all parsers
- [ ] Add provenance tracking
- [ ] Integration tests
- [ ] Performance testing (100 files/minute target)

---

## ðŸ”— DEPENDENCIES

### Python Packages

```txt
# requirements_extraction.txt
PyMuPDF>=1.23.0          # PDF text extraction
google-genai>=0.3.0      # LLM for PDF extraction
pydantic>=2.0.0          # Data validation
hgvs>=1.5.4              # HGVS notation parsing
```

### External Services

| Service | Purpose | Required |
|---------|---------|----------|
| Gemini API | PDF extraction | Yes (for PDF) |
| HGNC API | Gene symbol validation | Optional |

---

## ðŸ“¡ API ENDPOINT

```yaml
POST /api/agents/extract
Content-Type: multipart/form-data

Request:
  file: binary
  file_type: string  # vcf, maf, pdf, json
  metadata: json     # optional

Response:
  patient_profile: PatientProfile
  extraction_time_ms: number
  warnings: string[]
```

---

## âœ… ACCEPTANCE CRITERIA

1. âœ… Can parse VCF files with >95% accuracy
2. âœ… Can parse MAF files with >95% accuracy
3. âœ… Can extract mutations from PDF reports with >85% accuracy
4. âœ… All gene names normalized to HGNC
5. âœ… All HGVS notation validated
6. âœ… Data quality flags generated for missing data
7. âœ… Provenance tracked for all extractions
8. âœ… Processing time <10 seconds for typical files
9. âœ… Unit test coverage >80%

---

---

## ðŸŽ¯ MISSION

Build an intelligent data extraction agent that can:
1. Accept any file format (PDF, VCF, MAF, JSON, TXT)
2. Extract mutations, clinical data, and demographics
3. Validate data quality and flag issues
4. Output a structured `PatientProfile` object

---

## ðŸ“¥ INPUTS

### Accepted File Types

| Format | Description | Parser Needed |
|--------|-------------|---------------|
| **VCF** | Variant Call Format | Standard VCF parser |
| **MAF** | Mutation Annotation Format | Tab-delimited parser |
| **PDF** | NGS reports from labs | LLM-based extraction |
| **JSON** | Structured mutation data | JSON parser |
| **TXT/CSV** | Clinical notes, lab results | Text extraction |

### Example Input

```json
{
  "file": "binary_file_content",
  "file_type": "pdf",
  "file_name": "Foundation_One_Report.pdf",
  "metadata": {
    "lab": "Foundation Medicine",
    "report_date": "2025-01-15"
  }
}
```

---

## ðŸ“¤ OUTPUTS

### PatientProfile Schema

```python
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
from enum import Enum

class Zygosity(Enum):
    HETEROZYGOUS = "heterozygous"
    HOMOZYGOUS = "homozygous"
    HEMIZYGOUS = "hemizygous"
    UNKNOWN = "unknown"

class MutationSource(Enum):
    NGS = "ngs"
    IHC = "ihc"
    FISH = "fish"
    PCR = "pcr"
    INFERRED = "inferred"

@dataclass
class Mutation:
    gene: str
    variant: str                    # e.g., "c.1239delA" or "p.V600E"
    hgvs_c: Optional[str] = None    # Coding change
    hgvs_p: Optional[str] = None    # Protein change
    chromosome: Optional[str] = None
    position: Optional[int] = None
    ref: Optional[str] = None
    alt: Optional[str] = None
    vaf: Optional[float] = None     # Variant allele frequency
    coverage: Optional[int] = None
    zygosity: Zygosity = Zygosity.UNKNOWN
    source: MutationSource = MutationSource.NGS
    classification: Optional[str] = None  # Pathogenic, VUS, Benign

@dataclass
class GermlinePanel:
    genes_tested: List[str]
    pathogenic: Dict[str, str]      # gene -> variant
    vus: Dict[str, str]
    negative: List[str]
    panel_name: Optional[str] = None
    test_date: Optional[datetime] = None

@dataclass
class ClinicalData:
    stage: Optional[str] = None         # e.g., "IVB"
    histology: Optional[str] = None     # e.g., "high_grade_serous"
    grade: Optional[str] = None
    ecog_ps: Optional[int] = None       # Performance status
    biomarkers: Dict[str, any] = None   # CA-125, HER2, etc.
    prior_treatments: List[str] = None
    current_treatment: Optional[str] = None

@dataclass
class Demographics:
    age: Optional[int] = None
    sex: Optional[str] = None
    ethnicity: Optional[str] = None

@dataclass
class PatientProfile:
    patient_id: str
    disease: str                        # e.g., "ovarian_cancer"
    mutations: List[Mutation]
    germline_panel: Optional[GermlinePanel] = None
    clinical_data: Optional[ClinicalData] = None
    demographics: Optional[Demographics] = None
    data_quality_flags: List[str] = None  # ["ca125_missing", "hrd_pending"]
    extraction_provenance: Dict[str, any] = None  # Source, confidence, method
    created_at: datetime = None
    updated_at: datetime = None
```

---

## ðŸ—ï¸ IMPLEMENTATION

### File Structure

```
api/services/extraction/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ extraction_agent.py          # Main agent logic
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vcf_parser.py            # VCF file parsing
â”‚   â”œâ”€â”€ maf_parser.py            # MAF file parsing
â”‚   â”œâ”€â”€ pdf_parser.py            # PDF extraction with LLM
â”‚   â”œâ”€â”€ json_parser.py           # JSON parsing
â”‚   â””â”€â”€ text_parser.py           # Clinical notes extraction
â”œâ”€â”€ validators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mutation_validator.py    # Validate mutation format
â”‚   â”œâ”€â”€ gene_validator.py        # Validate gene names
â”‚   â””â”€â”€ quality_checker.py       # Data quality assessment
â”œâ”€â”€ normalizers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hgvs_normalizer.py       # Normalize HGVS notation
â”‚   â”œâ”€â”€ gene_normalizer.py       # Normalize gene symbols
â”‚   â””â”€â”€ disease_normalizer.py    # Normalize disease terms
â””â”€â”€ tests/
    â”œâ”€â”€ test_vcf_parser.py
    â”œâ”€â”€ test_pdf_parser.py
    â””â”€â”€ test_integration.py
```

### Core Agent Implementation

```python
# api/services/extraction/extraction_agent.py

from typing import Union, BinaryIO
from pathlib import Path
import logging

from .parsers import VCFParser, MAFParser, PDFParser, JSONParser, TextParser
from .validators import MutationValidator, GeneValidator, QualityChecker
from .normalizers import HGVSNormalizer, GeneNormalizer, DiseaseNormalizer
from ..models import PatientProfile, Mutation, DataQualityFlag

logger = logging.getLogger(__name__)

class DataExtractionAgent:
    """
    Intelligent agent for extracting structured patient data from various file formats.
    
    Capabilities:
    - Multi-format parsing (VCF, MAF, PDF, JSON, TXT)
    - Mutation validation and normalization
    - Data quality assessment
    - Provenance tracking
    """
    
    def __init__(self):
        # Initialize parsers
        self.parsers = {
            'vcf': VCFParser(),
            'maf': MAFParser(),
            'pdf': PDFParser(),  # Uses LLM for extraction
            'json': JSONParser(),
            'txt': TextParser(),
            'csv': TextParser(),
        }
        
        # Initialize validators
        self.mutation_validator = MutationValidator()
        self.gene_validator = GeneValidator()
        self.quality_checker = QualityChecker()
        
        # Initialize normalizers
        self.hgvs_normalizer = HGVSNormalizer()
        self.gene_normalizer = GeneNormalizer()
        self.disease_normalizer = DiseaseNormalizer()
    
    async def extract(
        self,
        file: Union[BinaryIO, bytes, str],
        file_type: str,
        metadata: dict = None
    ) -> PatientProfile:
        """
        Main extraction entry point.
        
        Args:
            file: File content (binary, bytes, or path)
            file_type: One of 'vcf', 'maf', 'pdf', 'json', 'txt', 'csv'
            metadata: Optional metadata (lab, date, patient_id)
        
        Returns:
            PatientProfile with extracted data
        """
        logger.info(f"Starting extraction for file_type={file_type}")
        
        # Step 1: Parse file
        parser = self.parsers.get(file_type.lower())
        if not parser:
            raise ValueError(f"Unsupported file type: {file_type}")
        
        raw_data = await parser.parse(file, metadata)
        
        # Step 2: Extract mutations
        mutations = self._extract_mutations(raw_data)
        
        # Step 3: Validate mutations
        validated_mutations = []
        for mut in mutations:
            if self.mutation_validator.validate(mut):
                validated_mutations.append(mut)
            else:
                logger.warning(f"Invalid mutation skipped: {mut}")
        
        # Step 4: Normalize mutations
        normalized_mutations = [
            self._normalize_mutation(mut) for mut in validated_mutations
        ]
        
        # Step 5: Extract clinical data
        clinical_data = self._extract_clinical_data(raw_data)
        
        # Step 6: Extract demographics
        demographics = self._extract_demographics(raw_data)
        
        # Step 7: Check data quality
        quality_flags = self.quality_checker.check(
            mutations=normalized_mutations,
            clinical_data=clinical_data
        )
        
        # Step 8: Build PatientProfile
        profile = PatientProfile(
            patient_id=metadata.get('patient_id', self._generate_id()),
            disease=self.disease_normalizer.normalize(
                raw_data.get('disease', 'unknown')
            ),
            mutations=normalized_mutations,
            clinical_data=clinical_data,
            demographics=demographics,
            data_quality_flags=quality_flags,
            extraction_provenance={
                'source': file_type,
                'lab': metadata.get('lab'),
                'extraction_method': parser.__class__.__name__,
                'confidence': self._calculate_confidence(raw_data)
            }
        )
        
        logger.info(f"Extraction complete: {len(normalized_mutations)} mutations")
        return profile
    
    def _extract_mutations(self, raw_data: dict) -> List[Mutation]:
        """Extract mutation objects from raw parsed data."""
        mutations = []
        
        for mut_data in raw_data.get('mutations', []):
            mutation = Mutation(
                gene=mut_data.get('gene', ''),
                variant=mut_data.get('variant', ''),
                hgvs_c=mut_data.get('hgvs_c'),
                hgvs_p=mut_data.get('hgvs_p'),
                chromosome=mut_data.get('chrom'),
                position=mut_data.get('pos'),
                ref=mut_data.get('ref'),
                alt=mut_data.get('alt'),
                vaf=mut_data.get('vaf'),
                coverage=mut_data.get('coverage'),
                zygosity=self._parse_zygosity(mut_data.get('zygosity')),
                source=self._parse_source(mut_data.get('source')),
                classification=mut_data.get('classification')
            )
            mutations.append(mutation)
        
        return mutations
    
    def _normalize_mutation(self, mutation: Mutation) -> Mutation:
        """Normalize gene names and HGVS notation."""
        mutation.gene = self.gene_normalizer.normalize(mutation.gene)
        
        if mutation.hgvs_c:
            mutation.hgvs_c = self.hgvs_normalizer.normalize(mutation.hgvs_c)
        if mutation.hgvs_p:
            mutation.hgvs_p = self.hgvs_normalizer.normalize(mutation.hgvs_p)
        
        return mutation
```

### PDF Parser (LLM-Based)

```python
# api/services/extraction/parsers/pdf_parser.py

from typing import BinaryIO, Union
import io
import logging

# PDF extraction
import fitz  # PyMuPDF
from google import genai  # Gemini for intelligent extraction

logger = logging.getLogger(__name__)

class PDFParser:
    """
    Extract mutation and clinical data from PDF reports using LLM.
    
    Supports:
    - Foundation Medicine reports
    - Tempus reports
    - Guardant Health reports
    - Generic lab reports
    """
    
    EXTRACTION_PROMPT = """
    You are a clinical genomics expert. Extract all mutations and clinical data from this report.
    
    Return JSON with this structure:
    {
        "patient_id": "string or null",
        "disease": "cancer type",
        "mutations": [
            {
                "gene": "BRAF",
                "variant": "V600E",
                "hgvs_p": "p.Val600Glu",
                "hgvs_c": "c.1799T>A",
                "vaf": 0.45,
                "classification": "Pathogenic"
            }
        ],
        "clinical_data": {
            "stage": "IVB",
            "histology": "adenocarcinoma",
            "prior_treatments": ["carboplatin", "paclitaxel"],
            "biomarkers": {
                "TMB": 10.2,
                "MSI": "Stable",
                "PD-L1": "50%"
            }
        },
        "germline_mutations": [],
        "lab_name": "Foundation Medicine",
        "report_date": "2025-01-15"
    }
    
    IMPORTANT:
    - Extract ALL mutations listed, including VUS
    - Use standard HGVS notation
    - Normalize gene symbols to HGNC
    - If data is unclear, mark as null
    
    Report text:
    {report_text}
    """
    
    def __init__(self, model_id: str = "gemini-2.0-flash"):
        self.client = genai.Client()
        self.model_id = model_id
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes],
        metadata: dict = None
    ) -> dict:
        """
        Parse PDF report and extract structured data.
        
        Args:
            file: PDF file content
            metadata: Optional metadata
        
        Returns:
            Dict with extracted data
        """
        # Step 1: Extract text from PDF
        text = self._extract_text(file)
        logger.info(f"Extracted {len(text)} characters from PDF")
        
        # Step 2: Use LLM to extract structured data
        prompt = self.EXTRACTION_PROMPT.format(report_text=text[:50000])  # Limit
        
        response = self.client.models.generate_content(
            model=self.model_id,
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.1  # Low temperature for accuracy
            }
        )
        
        # Step 3: Parse JSON response
        import json
        try:
            extracted = json.loads(response.text)
        except json.JSONDecodeError:
            logger.error("Failed to parse LLM response as JSON")
            extracted = {"mutations": [], "error": "parse_failed"}
        
        # Step 4: Add provenance
        extracted['extraction_method'] = 'llm_pdf_extraction'
        extracted['source_text_length'] = len(text)
        
        return extracted
    
    def _extract_text(self, file: Union[BinaryIO, bytes]) -> str:
        """Extract text content from PDF."""
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        
        return text
```

### VCF Parser

```python
# api/services/extraction/parsers/vcf_parser.py

from typing import BinaryIO, Union, List, Dict
import io

class VCFParser:
    """
    Parse VCF (Variant Call Format) files.
    
    Supports:
    - VCF 4.1, 4.2, 4.3
    - Multi-sample VCFs (uses first sample)
    - Gzipped VCF files
    """
    
    def __init__(self):
        self.required_fields = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes, str],
        metadata: dict = None
    ) -> dict:
        """Parse VCF file and extract mutations."""
        
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        mutations = []
        header_info = {}
        
        for line in file:
            if isinstance(line, bytes):
                line = line.decode('utf-8')
            line = line.strip()
            
            # Parse header
            if line.startswith('##'):
                self._parse_header_line(line, header_info)
                continue
            
            # Parse column header
            if line.startswith('#CHROM'):
                columns = line.split('\t')
                continue
            
            # Parse variant line
            if line and not line.startswith('#'):
                mutation = self._parse_variant_line(line, columns)
                if mutation:
                    mutations.append(mutation)
        
        return {
            'mutations': mutations,
            'vcf_header': header_info,
            'mutation_count': len(mutations)
        }
    
    def _parse_variant_line(self, line: str, columns: List[str]) -> Dict:
        """Parse a single variant line."""
        fields = line.split('\t')
        
        mutation = {
            'chrom': fields[0],
            'pos': int(fields[1]),
            'id': fields[2] if fields[2] != '.' else None,
            'ref': fields[3],
            'alt': fields[4],
            'qual': float(fields[5]) if fields[5] != '.' else None,
            'filter': fields[6],
            'info': self._parse_info(fields[7]) if len(fields) > 7 else {}
        }
        
        # Extract gene and variant from INFO field
        info = mutation['info']
        mutation['gene'] = info.get('GENE', info.get('Gene', ''))
        mutation['hgvs_c'] = info.get('HGVSc', info.get('HGVS_c', ''))
        mutation['hgvs_p'] = info.get('HGVSp', info.get('HGVS_p', ''))
        mutation['variant'] = mutation['hgvs_p'] or f"{mutation['ref']}>{mutation['alt']}"
        
        # Extract VAF if available
        if len(fields) > 9:  # Has sample data
            format_fields = fields[8].split(':')
            sample_data = fields[9].split(':')
            format_dict = dict(zip(format_fields, sample_data))
            
            if 'AF' in format_dict:
                mutation['vaf'] = float(format_dict['AF'])
            elif 'AD' in format_dict:
                # Calculate from allele depth
                ad = [int(x) for x in format_dict['AD'].split(',')]
                if sum(ad) > 0:
                    mutation['vaf'] = ad[1] / sum(ad)
        
        return mutation
    
    def _parse_info(self, info_str: str) -> Dict:
        """Parse INFO field into dictionary."""
        info = {}
        for item in info_str.split(';'):
            if '=' in item:
                key, value = item.split('=', 1)
                info[key] = value
            else:
                info[item] = True
        return info
```

---

## ðŸ§ª TESTING

### Unit Tests

```python
# api/services/extraction/tests/test_vcf_parser.py

import pytest
from ..parsers.vcf_parser import VCFParser

@pytest.fixture
def vcf_content():
    return b"""##fileformat=VCFv4.2
##INFO=<ID=GENE,Number=1,Type=String,Description="Gene name">
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
chr17\t7674872\t.\tG\tA\t.\tPASS\tGENE=TP53;HGVSp=p.Arg175His\tGT:AF\t0/1:0.62
"""

@pytest.mark.asyncio
async def test_vcf_parser_basic(vcf_content):
    parser = VCFParser()
    result = await parser.parse(vcf_content)
    
    assert result['mutation_count'] == 2
    assert result['mutations'][0]['gene'] == 'BRAF'
    assert result['mutations'][0]['hgvs_p'] == 'p.Val600Glu'
    assert result['mutations'][0]['vaf'] == 0.45

@pytest.mark.asyncio
async def test_vcf_parser_missing_vaf(vcf_content):
    # Test handling of missing VAF
    content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF
"""
    parser = VCFParser()
    result = await parser.parse(content)
    
    assert result['mutations'][0]['vaf'] is None
```

### Integration Test

```python
# api/services/extraction/tests/test_integration.py

import pytest
from ..extraction_agent import DataExtractionAgent

@pytest.fixture
def agent():
    return DataExtractionAgent()

@pytest.mark.asyncio
async def test_full_extraction_flow(agent):
    # Test with sample VCF
    vcf_content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
"""
    
    profile = await agent.extract(
        file=vcf_content,
        file_type='vcf',
        metadata={'patient_id': 'TEST-001'}
    )
    
    assert profile.patient_id == 'TEST-001'
    assert len(profile.mutations) == 1
    assert profile.mutations[0].gene == 'BRAF'
    assert profile.extraction_provenance['source'] == 'vcf'
```

---

## ðŸ“‹ IMPLEMENTATION CHECKLIST

### Phase 1: Core Parsers
- [ ] Implement VCF parser (standard format)
- [ ] Implement MAF parser (tab-delimited)
- [ ] Implement JSON parser (structured input)
- [ ] Unit tests for each parser

### Phase 2: PDF Extraction
- [ ] Set up PyMuPDF for text extraction
- [ ] Create LLM extraction prompt
- [ ] Handle Foundation Medicine reports
- [ ] Handle Tempus reports
- [ ] Handle generic reports
- [ ] Unit tests for PDF extraction

### Phase 3: Validation & Normalization
- [ ] Gene name validation (HGNC)
- [ ] HGVS notation validation
- [ ] Zygosity inference
- [ ] Data quality flagging
- [ ] Unit tests for validators

### Phase 4: Integration
- [ ] Create DataExtractionAgent class
- [ ] Wire up all parsers
- [ ] Add provenance tracking
- [ ] Integration tests
- [ ] Performance testing (100 files/minute target)

---

## ðŸ”— DEPENDENCIES

### Python Packages

```txt
# requirements_extraction.txt
PyMuPDF>=1.23.0          # PDF text extraction
google-genai>=0.3.0      # LLM for PDF extraction
pydantic>=2.0.0          # Data validation
hgvs>=1.5.4              # HGVS notation parsing
```

### External Services

| Service | Purpose | Required |
|---------|---------|----------|
| Gemini API | PDF extraction | Yes (for PDF) |
| HGNC API | Gene symbol validation | Optional |

---

## ðŸ“¡ API ENDPOINT

```yaml
POST /api/agents/extract
Content-Type: multipart/form-data

Request:
  file: binary
  file_type: string  # vcf, maf, pdf, json
  metadata: json     # optional

Response:
  patient_profile: PatientProfile
  extraction_time_ms: number
  warnings: string[]
```

---

## âœ… ACCEPTANCE CRITERIA

1. âœ… Can parse VCF files with >95% accuracy
2. âœ… Can parse MAF files with >95% accuracy
3. âœ… Can extract mutations from PDF reports with >85% accuracy
4. âœ… All gene names normalized to HGNC
5. âœ… All HGVS notation validated
6. âœ… Data quality flags generated for missing data
7. âœ… Provenance tracked for all extractions
8. âœ… Processing time <10 seconds for typical files
9. âœ… Unit test coverage >80%

---

---

## ðŸŽ¯ MISSION

Build an intelligent data extraction agent that can:
1. Accept any file format (PDF, VCF, MAF, JSON, TXT)
2. Extract mutations, clinical data, and demographics
3. Validate data quality and flag issues
4. Output a structured `PatientProfile` object

---

## ðŸ“¥ INPUTS

### Accepted File Types

| Format | Description | Parser Needed |
|--------|-------------|---------------|
| **VCF** | Variant Call Format | Standard VCF parser |
| **MAF** | Mutation Annotation Format | Tab-delimited parser |
| **PDF** | NGS reports from labs | LLM-based extraction |
| **JSON** | Structured mutation data | JSON parser |
| **TXT/CSV** | Clinical notes, lab results | Text extraction |

### Example Input

```json
{
  "file": "binary_file_content",
  "file_type": "pdf",
  "file_name": "Foundation_One_Report.pdf",
  "metadata": {
    "lab": "Foundation Medicine",
    "report_date": "2025-01-15"
  }
}
```

---

## ðŸ“¤ OUTPUTS

### PatientProfile Schema

```python
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
from enum import Enum

class Zygosity(Enum):
    HETEROZYGOUS = "heterozygous"
    HOMOZYGOUS = "homozygous"
    HEMIZYGOUS = "hemizygous"
    UNKNOWN = "unknown"

class MutationSource(Enum):
    NGS = "ngs"
    IHC = "ihc"
    FISH = "fish"
    PCR = "pcr"
    INFERRED = "inferred"

@dataclass
class Mutation:
    gene: str
    variant: str                    # e.g., "c.1239delA" or "p.V600E"
    hgvs_c: Optional[str] = None    # Coding change
    hgvs_p: Optional[str] = None    # Protein change
    chromosome: Optional[str] = None
    position: Optional[int] = None
    ref: Optional[str] = None
    alt: Optional[str] = None
    vaf: Optional[float] = None     # Variant allele frequency
    coverage: Optional[int] = None
    zygosity: Zygosity = Zygosity.UNKNOWN
    source: MutationSource = MutationSource.NGS
    classification: Optional[str] = None  # Pathogenic, VUS, Benign

@dataclass
class GermlinePanel:
    genes_tested: List[str]
    pathogenic: Dict[str, str]      # gene -> variant
    vus: Dict[str, str]
    negative: List[str]
    panel_name: Optional[str] = None
    test_date: Optional[datetime] = None

@dataclass
class ClinicalData:
    stage: Optional[str] = None         # e.g., "IVB"
    histology: Optional[str] = None     # e.g., "high_grade_serous"
    grade: Optional[str] = None
    ecog_ps: Optional[int] = None       # Performance status
    biomarkers: Dict[str, any] = None   # CA-125, HER2, etc.
    prior_treatments: List[str] = None
    current_treatment: Optional[str] = None

@dataclass
class Demographics:
    age: Optional[int] = None
    sex: Optional[str] = None
    ethnicity: Optional[str] = None

@dataclass
class PatientProfile:
    patient_id: str
    disease: str                        # e.g., "ovarian_cancer"
    mutations: List[Mutation]
    germline_panel: Optional[GermlinePanel] = None
    clinical_data: Optional[ClinicalData] = None
    demographics: Optional[Demographics] = None
    data_quality_flags: List[str] = None  # ["ca125_missing", "hrd_pending"]
    extraction_provenance: Dict[str, any] = None  # Source, confidence, method
    created_at: datetime = None
    updated_at: datetime = None
```

---

## ðŸ—ï¸ IMPLEMENTATION

### File Structure

```
api/services/extraction/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ extraction_agent.py          # Main agent logic
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vcf_parser.py            # VCF file parsing
â”‚   â”œâ”€â”€ maf_parser.py            # MAF file parsing
â”‚   â”œâ”€â”€ pdf_parser.py            # PDF extraction with LLM
â”‚   â”œâ”€â”€ json_parser.py           # JSON parsing
â”‚   â””â”€â”€ text_parser.py           # Clinical notes extraction
â”œâ”€â”€ validators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mutation_validator.py    # Validate mutation format
â”‚   â”œâ”€â”€ gene_validator.py        # Validate gene names
â”‚   â””â”€â”€ quality_checker.py       # Data quality assessment
â”œâ”€â”€ normalizers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hgvs_normalizer.py       # Normalize HGVS notation
â”‚   â”œâ”€â”€ gene_normalizer.py       # Normalize gene symbols
â”‚   â””â”€â”€ disease_normalizer.py    # Normalize disease terms
â””â”€â”€ tests/
    â”œâ”€â”€ test_vcf_parser.py
    â”œâ”€â”€ test_pdf_parser.py
    â””â”€â”€ test_integration.py
```

### Core Agent Implementation

```python
# api/services/extraction/extraction_agent.py

from typing import Union, BinaryIO
from pathlib import Path
import logging

from .parsers import VCFParser, MAFParser, PDFParser, JSONParser, TextParser
from .validators import MutationValidator, GeneValidator, QualityChecker
from .normalizers import HGVSNormalizer, GeneNormalizer, DiseaseNormalizer
from ..models import PatientProfile, Mutation, DataQualityFlag

logger = logging.getLogger(__name__)

class DataExtractionAgent:
    """
    Intelligent agent for extracting structured patient data from various file formats.
    
    Capabilities:
    - Multi-format parsing (VCF, MAF, PDF, JSON, TXT)
    - Mutation validation and normalization
    - Data quality assessment
    - Provenance tracking
    """
    
    def __init__(self):
        # Initialize parsers
        self.parsers = {
            'vcf': VCFParser(),
            'maf': MAFParser(),
            'pdf': PDFParser(),  # Uses LLM for extraction
            'json': JSONParser(),
            'txt': TextParser(),
            'csv': TextParser(),
        }
        
        # Initialize validators
        self.mutation_validator = MutationValidator()
        self.gene_validator = GeneValidator()
        self.quality_checker = QualityChecker()
        
        # Initialize normalizers
        self.hgvs_normalizer = HGVSNormalizer()
        self.gene_normalizer = GeneNormalizer()
        self.disease_normalizer = DiseaseNormalizer()
    
    async def extract(
        self,
        file: Union[BinaryIO, bytes, str],
        file_type: str,
        metadata: dict = None
    ) -> PatientProfile:
        """
        Main extraction entry point.
        
        Args:
            file: File content (binary, bytes, or path)
            file_type: One of 'vcf', 'maf', 'pdf', 'json', 'txt', 'csv'
            metadata: Optional metadata (lab, date, patient_id)
        
        Returns:
            PatientProfile with extracted data
        """
        logger.info(f"Starting extraction for file_type={file_type}")
        
        # Step 1: Parse file
        parser = self.parsers.get(file_type.lower())
        if not parser:
            raise ValueError(f"Unsupported file type: {file_type}")
        
        raw_data = await parser.parse(file, metadata)
        
        # Step 2: Extract mutations
        mutations = self._extract_mutations(raw_data)
        
        # Step 3: Validate mutations
        validated_mutations = []
        for mut in mutations:
            if self.mutation_validator.validate(mut):
                validated_mutations.append(mut)
            else:
                logger.warning(f"Invalid mutation skipped: {mut}")
        
        # Step 4: Normalize mutations
        normalized_mutations = [
            self._normalize_mutation(mut) for mut in validated_mutations
        ]
        
        # Step 5: Extract clinical data
        clinical_data = self._extract_clinical_data(raw_data)
        
        # Step 6: Extract demographics
        demographics = self._extract_demographics(raw_data)
        
        # Step 7: Check data quality
        quality_flags = self.quality_checker.check(
            mutations=normalized_mutations,
            clinical_data=clinical_data
        )
        
        # Step 8: Build PatientProfile
        profile = PatientProfile(
            patient_id=metadata.get('patient_id', self._generate_id()),
            disease=self.disease_normalizer.normalize(
                raw_data.get('disease', 'unknown')
            ),
            mutations=normalized_mutations,
            clinical_data=clinical_data,
            demographics=demographics,
            data_quality_flags=quality_flags,
            extraction_provenance={
                'source': file_type,
                'lab': metadata.get('lab'),
                'extraction_method': parser.__class__.__name__,
                'confidence': self._calculate_confidence(raw_data)
            }
        )
        
        logger.info(f"Extraction complete: {len(normalized_mutations)} mutations")
        return profile
    
    def _extract_mutations(self, raw_data: dict) -> List[Mutation]:
        """Extract mutation objects from raw parsed data."""
        mutations = []
        
        for mut_data in raw_data.get('mutations', []):
            mutation = Mutation(
                gene=mut_data.get('gene', ''),
                variant=mut_data.get('variant', ''),
                hgvs_c=mut_data.get('hgvs_c'),
                hgvs_p=mut_data.get('hgvs_p'),
                chromosome=mut_data.get('chrom'),
                position=mut_data.get('pos'),
                ref=mut_data.get('ref'),
                alt=mut_data.get('alt'),
                vaf=mut_data.get('vaf'),
                coverage=mut_data.get('coverage'),
                zygosity=self._parse_zygosity(mut_data.get('zygosity')),
                source=self._parse_source(mut_data.get('source')),
                classification=mut_data.get('classification')
            )
            mutations.append(mutation)
        
        return mutations
    
    def _normalize_mutation(self, mutation: Mutation) -> Mutation:
        """Normalize gene names and HGVS notation."""
        mutation.gene = self.gene_normalizer.normalize(mutation.gene)
        
        if mutation.hgvs_c:
            mutation.hgvs_c = self.hgvs_normalizer.normalize(mutation.hgvs_c)
        if mutation.hgvs_p:
            mutation.hgvs_p = self.hgvs_normalizer.normalize(mutation.hgvs_p)
        
        return mutation
```

### PDF Parser (LLM-Based)

```python
# api/services/extraction/parsers/pdf_parser.py

from typing import BinaryIO, Union
import io
import logging

# PDF extraction
import fitz  # PyMuPDF
from google import genai  # Gemini for intelligent extraction

logger = logging.getLogger(__name__)

class PDFParser:
    """
    Extract mutation and clinical data from PDF reports using LLM.
    
    Supports:
    - Foundation Medicine reports
    - Tempus reports
    - Guardant Health reports
    - Generic lab reports
    """
    
    EXTRACTION_PROMPT = """
    You are a clinical genomics expert. Extract all mutations and clinical data from this report.
    
    Return JSON with this structure:
    {
        "patient_id": "string or null",
        "disease": "cancer type",
        "mutations": [
            {
                "gene": "BRAF",
                "variant": "V600E",
                "hgvs_p": "p.Val600Glu",
                "hgvs_c": "c.1799T>A",
                "vaf": 0.45,
                "classification": "Pathogenic"
            }
        ],
        "clinical_data": {
            "stage": "IVB",
            "histology": "adenocarcinoma",
            "prior_treatments": ["carboplatin", "paclitaxel"],
            "biomarkers": {
                "TMB": 10.2,
                "MSI": "Stable",
                "PD-L1": "50%"
            }
        },
        "germline_mutations": [],
        "lab_name": "Foundation Medicine",
        "report_date": "2025-01-15"
    }
    
    IMPORTANT:
    - Extract ALL mutations listed, including VUS
    - Use standard HGVS notation
    - Normalize gene symbols to HGNC
    - If data is unclear, mark as null
    
    Report text:
    {report_text}
    """
    
    def __init__(self, model_id: str = "gemini-2.0-flash"):
        self.client = genai.Client()
        self.model_id = model_id
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes],
        metadata: dict = None
    ) -> dict:
        """
        Parse PDF report and extract structured data.
        
        Args:
            file: PDF file content
            metadata: Optional metadata
        
        Returns:
            Dict with extracted data
        """
        # Step 1: Extract text from PDF
        text = self._extract_text(file)
        logger.info(f"Extracted {len(text)} characters from PDF")
        
        # Step 2: Use LLM to extract structured data
        prompt = self.EXTRACTION_PROMPT.format(report_text=text[:50000])  # Limit
        
        response = self.client.models.generate_content(
            model=self.model_id,
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.1  # Low temperature for accuracy
            }
        )
        
        # Step 3: Parse JSON response
        import json
        try:
            extracted = json.loads(response.text)
        except json.JSONDecodeError:
            logger.error("Failed to parse LLM response as JSON")
            extracted = {"mutations": [], "error": "parse_failed"}
        
        # Step 4: Add provenance
        extracted['extraction_method'] = 'llm_pdf_extraction'
        extracted['source_text_length'] = len(text)
        
        return extracted
    
    def _extract_text(self, file: Union[BinaryIO, bytes]) -> str:
        """Extract text content from PDF."""
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        
        return text
```

### VCF Parser

```python
# api/services/extraction/parsers/vcf_parser.py

from typing import BinaryIO, Union, List, Dict
import io

class VCFParser:
    """
    Parse VCF (Variant Call Format) files.
    
    Supports:
    - VCF 4.1, 4.2, 4.3
    - Multi-sample VCFs (uses first sample)
    - Gzipped VCF files
    """
    
    def __init__(self):
        self.required_fields = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes, str],
        metadata: dict = None
    ) -> dict:
        """Parse VCF file and extract mutations."""
        
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        mutations = []
        header_info = {}
        
        for line in file:
            if isinstance(line, bytes):
                line = line.decode('utf-8')
            line = line.strip()
            
            # Parse header
            if line.startswith('##'):
                self._parse_header_line(line, header_info)
                continue
            
            # Parse column header
            if line.startswith('#CHROM'):
                columns = line.split('\t')
                continue
            
            # Parse variant line
            if line and not line.startswith('#'):
                mutation = self._parse_variant_line(line, columns)
                if mutation:
                    mutations.append(mutation)
        
        return {
            'mutations': mutations,
            'vcf_header': header_info,
            'mutation_count': len(mutations)
        }
    
    def _parse_variant_line(self, line: str, columns: List[str]) -> Dict:
        """Parse a single variant line."""
        fields = line.split('\t')
        
        mutation = {
            'chrom': fields[0],
            'pos': int(fields[1]),
            'id': fields[2] if fields[2] != '.' else None,
            'ref': fields[3],
            'alt': fields[4],
            'qual': float(fields[5]) if fields[5] != '.' else None,
            'filter': fields[6],
            'info': self._parse_info(fields[7]) if len(fields) > 7 else {}
        }
        
        # Extract gene and variant from INFO field
        info = mutation['info']
        mutation['gene'] = info.get('GENE', info.get('Gene', ''))
        mutation['hgvs_c'] = info.get('HGVSc', info.get('HGVS_c', ''))
        mutation['hgvs_p'] = info.get('HGVSp', info.get('HGVS_p', ''))
        mutation['variant'] = mutation['hgvs_p'] or f"{mutation['ref']}>{mutation['alt']}"
        
        # Extract VAF if available
        if len(fields) > 9:  # Has sample data
            format_fields = fields[8].split(':')
            sample_data = fields[9].split(':')
            format_dict = dict(zip(format_fields, sample_data))
            
            if 'AF' in format_dict:
                mutation['vaf'] = float(format_dict['AF'])
            elif 'AD' in format_dict:
                # Calculate from allele depth
                ad = [int(x) for x in format_dict['AD'].split(',')]
                if sum(ad) > 0:
                    mutation['vaf'] = ad[1] / sum(ad)
        
        return mutation
    
    def _parse_info(self, info_str: str) -> Dict:
        """Parse INFO field into dictionary."""
        info = {}
        for item in info_str.split(';'):
            if '=' in item:
                key, value = item.split('=', 1)
                info[key] = value
            else:
                info[item] = True
        return info
```

---

## ðŸ§ª TESTING

### Unit Tests

```python
# api/services/extraction/tests/test_vcf_parser.py

import pytest
from ..parsers.vcf_parser import VCFParser

@pytest.fixture
def vcf_content():
    return b"""##fileformat=VCFv4.2
##INFO=<ID=GENE,Number=1,Type=String,Description="Gene name">
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
chr17\t7674872\t.\tG\tA\t.\tPASS\tGENE=TP53;HGVSp=p.Arg175His\tGT:AF\t0/1:0.62
"""

@pytest.mark.asyncio
async def test_vcf_parser_basic(vcf_content):
    parser = VCFParser()
    result = await parser.parse(vcf_content)
    
    assert result['mutation_count'] == 2
    assert result['mutations'][0]['gene'] == 'BRAF'
    assert result['mutations'][0]['hgvs_p'] == 'p.Val600Glu'
    assert result['mutations'][0]['vaf'] == 0.45

@pytest.mark.asyncio
async def test_vcf_parser_missing_vaf(vcf_content):
    # Test handling of missing VAF
    content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF
"""
    parser = VCFParser()
    result = await parser.parse(content)
    
    assert result['mutations'][0]['vaf'] is None
```

### Integration Test

```python
# api/services/extraction/tests/test_integration.py

import pytest
from ..extraction_agent import DataExtractionAgent

@pytest.fixture
def agent():
    return DataExtractionAgent()

@pytest.mark.asyncio
async def test_full_extraction_flow(agent):
    # Test with sample VCF
    vcf_content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
"""
    
    profile = await agent.extract(
        file=vcf_content,
        file_type='vcf',
        metadata={'patient_id': 'TEST-001'}
    )
    
    assert profile.patient_id == 'TEST-001'
    assert len(profile.mutations) == 1
    assert profile.mutations[0].gene == 'BRAF'
    assert profile.extraction_provenance['source'] == 'vcf'
```

---

## ðŸ“‹ IMPLEMENTATION CHECKLIST

### Phase 1: Core Parsers
- [ ] Implement VCF parser (standard format)
- [ ] Implement MAF parser (tab-delimited)
- [ ] Implement JSON parser (structured input)
- [ ] Unit tests for each parser

### Phase 2: PDF Extraction
- [ ] Set up PyMuPDF for text extraction
- [ ] Create LLM extraction prompt
- [ ] Handle Foundation Medicine reports
- [ ] Handle Tempus reports
- [ ] Handle generic reports
- [ ] Unit tests for PDF extraction

### Phase 3: Validation & Normalization
- [ ] Gene name validation (HGNC)
- [ ] HGVS notation validation
- [ ] Zygosity inference
- [ ] Data quality flagging
- [ ] Unit tests for validators

### Phase 4: Integration
- [ ] Create DataExtractionAgent class
- [ ] Wire up all parsers
- [ ] Add provenance tracking
- [ ] Integration tests
- [ ] Performance testing (100 files/minute target)

---

## ðŸ”— DEPENDENCIES

### Python Packages

```txt
# requirements_extraction.txt
PyMuPDF>=1.23.0          # PDF text extraction
google-genai>=0.3.0      # LLM for PDF extraction
pydantic>=2.0.0          # Data validation
hgvs>=1.5.4              # HGVS notation parsing
```

### External Services

| Service | Purpose | Required |
|---------|---------|----------|
| Gemini API | PDF extraction | Yes (for PDF) |
| HGNC API | Gene symbol validation | Optional |

---

## ðŸ“¡ API ENDPOINT

```yaml
POST /api/agents/extract
Content-Type: multipart/form-data

Request:
  file: binary
  file_type: string  # vcf, maf, pdf, json
  metadata: json     # optional

Response:
  patient_profile: PatientProfile
  extraction_time_ms: number
  warnings: string[]
```

---

## âœ… ACCEPTANCE CRITERIA

1. âœ… Can parse VCF files with >95% accuracy
2. âœ… Can parse MAF files with >95% accuracy
3. âœ… Can extract mutations from PDF reports with >85% accuracy
4. âœ… All gene names normalized to HGNC
5. âœ… All HGVS notation validated
6. âœ… Data quality flags generated for missing data
7. âœ… Provenance tracked for all extractions
8. âœ… Processing time <10 seconds for typical files
9. âœ… Unit test coverage >80%

---

---

## ðŸŽ¯ MISSION

Build an intelligent data extraction agent that can:
1. Accept any file format (PDF, VCF, MAF, JSON, TXT)
2. Extract mutations, clinical data, and demographics
3. Validate data quality and flag issues
4. Output a structured `PatientProfile` object

---

## ðŸ“¥ INPUTS

### Accepted File Types

| Format | Description | Parser Needed |
|--------|-------------|---------------|
| **VCF** | Variant Call Format | Standard VCF parser |
| **MAF** | Mutation Annotation Format | Tab-delimited parser |
| **PDF** | NGS reports from labs | LLM-based extraction |
| **JSON** | Structured mutation data | JSON parser |
| **TXT/CSV** | Clinical notes, lab results | Text extraction |

### Example Input

```json
{
  "file": "binary_file_content",
  "file_type": "pdf",
  "file_name": "Foundation_One_Report.pdf",
  "metadata": {
    "lab": "Foundation Medicine",
    "report_date": "2025-01-15"
  }
}
```

---

## ðŸ“¤ OUTPUTS

### PatientProfile Schema

```python
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
from enum import Enum

class Zygosity(Enum):
    HETEROZYGOUS = "heterozygous"
    HOMOZYGOUS = "homozygous"
    HEMIZYGOUS = "hemizygous"
    UNKNOWN = "unknown"

class MutationSource(Enum):
    NGS = "ngs"
    IHC = "ihc"
    FISH = "fish"
    PCR = "pcr"
    INFERRED = "inferred"

@dataclass
class Mutation:
    gene: str
    variant: str                    # e.g., "c.1239delA" or "p.V600E"
    hgvs_c: Optional[str] = None    # Coding change
    hgvs_p: Optional[str] = None    # Protein change
    chromosome: Optional[str] = None
    position: Optional[int] = None
    ref: Optional[str] = None
    alt: Optional[str] = None
    vaf: Optional[float] = None     # Variant allele frequency
    coverage: Optional[int] = None
    zygosity: Zygosity = Zygosity.UNKNOWN
    source: MutationSource = MutationSource.NGS
    classification: Optional[str] = None  # Pathogenic, VUS, Benign

@dataclass
class GermlinePanel:
    genes_tested: List[str]
    pathogenic: Dict[str, str]      # gene -> variant
    vus: Dict[str, str]
    negative: List[str]
    panel_name: Optional[str] = None
    test_date: Optional[datetime] = None

@dataclass
class ClinicalData:
    stage: Optional[str] = None         # e.g., "IVB"
    histology: Optional[str] = None     # e.g., "high_grade_serous"
    grade: Optional[str] = None
    ecog_ps: Optional[int] = None       # Performance status
    biomarkers: Dict[str, any] = None   # CA-125, HER2, etc.
    prior_treatments: List[str] = None
    current_treatment: Optional[str] = None

@dataclass
class Demographics:
    age: Optional[int] = None
    sex: Optional[str] = None
    ethnicity: Optional[str] = None

@dataclass
class PatientProfile:
    patient_id: str
    disease: str                        # e.g., "ovarian_cancer"
    mutations: List[Mutation]
    germline_panel: Optional[GermlinePanel] = None
    clinical_data: Optional[ClinicalData] = None
    demographics: Optional[Demographics] = None
    data_quality_flags: List[str] = None  # ["ca125_missing", "hrd_pending"]
    extraction_provenance: Dict[str, any] = None  # Source, confidence, method
    created_at: datetime = None
    updated_at: datetime = None
```

---

## ðŸ—ï¸ IMPLEMENTATION

### File Structure

```
api/services/extraction/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ extraction_agent.py          # Main agent logic
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vcf_parser.py            # VCF file parsing
â”‚   â”œâ”€â”€ maf_parser.py            # MAF file parsing
â”‚   â”œâ”€â”€ pdf_parser.py            # PDF extraction with LLM
â”‚   â”œâ”€â”€ json_parser.py           # JSON parsing
â”‚   â””â”€â”€ text_parser.py           # Clinical notes extraction
â”œâ”€â”€ validators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mutation_validator.py    # Validate mutation format
â”‚   â”œâ”€â”€ gene_validator.py        # Validate gene names
â”‚   â””â”€â”€ quality_checker.py       # Data quality assessment
â”œâ”€â”€ normalizers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hgvs_normalizer.py       # Normalize HGVS notation
â”‚   â”œâ”€â”€ gene_normalizer.py       # Normalize gene symbols
â”‚   â””â”€â”€ disease_normalizer.py    # Normalize disease terms
â””â”€â”€ tests/
    â”œâ”€â”€ test_vcf_parser.py
    â”œâ”€â”€ test_pdf_parser.py
    â””â”€â”€ test_integration.py
```

### Core Agent Implementation

```python
# api/services/extraction/extraction_agent.py

from typing import Union, BinaryIO
from pathlib import Path
import logging

from .parsers import VCFParser, MAFParser, PDFParser, JSONParser, TextParser
from .validators import MutationValidator, GeneValidator, QualityChecker
from .normalizers import HGVSNormalizer, GeneNormalizer, DiseaseNormalizer
from ..models import PatientProfile, Mutation, DataQualityFlag

logger = logging.getLogger(__name__)

class DataExtractionAgent:
    """
    Intelligent agent for extracting structured patient data from various file formats.
    
    Capabilities:
    - Multi-format parsing (VCF, MAF, PDF, JSON, TXT)
    - Mutation validation and normalization
    - Data quality assessment
    - Provenance tracking
    """
    
    def __init__(self):
        # Initialize parsers
        self.parsers = {
            'vcf': VCFParser(),
            'maf': MAFParser(),
            'pdf': PDFParser(),  # Uses LLM for extraction
            'json': JSONParser(),
            'txt': TextParser(),
            'csv': TextParser(),
        }
        
        # Initialize validators
        self.mutation_validator = MutationValidator()
        self.gene_validator = GeneValidator()
        self.quality_checker = QualityChecker()
        
        # Initialize normalizers
        self.hgvs_normalizer = HGVSNormalizer()
        self.gene_normalizer = GeneNormalizer()
        self.disease_normalizer = DiseaseNormalizer()
    
    async def extract(
        self,
        file: Union[BinaryIO, bytes, str],
        file_type: str,
        metadata: dict = None
    ) -> PatientProfile:
        """
        Main extraction entry point.
        
        Args:
            file: File content (binary, bytes, or path)
            file_type: One of 'vcf', 'maf', 'pdf', 'json', 'txt', 'csv'
            metadata: Optional metadata (lab, date, patient_id)
        
        Returns:
            PatientProfile with extracted data
        """
        logger.info(f"Starting extraction for file_type={file_type}")
        
        # Step 1: Parse file
        parser = self.parsers.get(file_type.lower())
        if not parser:
            raise ValueError(f"Unsupported file type: {file_type}")
        
        raw_data = await parser.parse(file, metadata)
        
        # Step 2: Extract mutations
        mutations = self._extract_mutations(raw_data)
        
        # Step 3: Validate mutations
        validated_mutations = []
        for mut in mutations:
            if self.mutation_validator.validate(mut):
                validated_mutations.append(mut)
            else:
                logger.warning(f"Invalid mutation skipped: {mut}")
        
        # Step 4: Normalize mutations
        normalized_mutations = [
            self._normalize_mutation(mut) for mut in validated_mutations
        ]
        
        # Step 5: Extract clinical data
        clinical_data = self._extract_clinical_data(raw_data)
        
        # Step 6: Extract demographics
        demographics = self._extract_demographics(raw_data)
        
        # Step 7: Check data quality
        quality_flags = self.quality_checker.check(
            mutations=normalized_mutations,
            clinical_data=clinical_data
        )
        
        # Step 8: Build PatientProfile
        profile = PatientProfile(
            patient_id=metadata.get('patient_id', self._generate_id()),
            disease=self.disease_normalizer.normalize(
                raw_data.get('disease', 'unknown')
            ),
            mutations=normalized_mutations,
            clinical_data=clinical_data,
            demographics=demographics,
            data_quality_flags=quality_flags,
            extraction_provenance={
                'source': file_type,
                'lab': metadata.get('lab'),
                'extraction_method': parser.__class__.__name__,
                'confidence': self._calculate_confidence(raw_data)
            }
        )
        
        logger.info(f"Extraction complete: {len(normalized_mutations)} mutations")
        return profile
    
    def _extract_mutations(self, raw_data: dict) -> List[Mutation]:
        """Extract mutation objects from raw parsed data."""
        mutations = []
        
        for mut_data in raw_data.get('mutations', []):
            mutation = Mutation(
                gene=mut_data.get('gene', ''),
                variant=mut_data.get('variant', ''),
                hgvs_c=mut_data.get('hgvs_c'),
                hgvs_p=mut_data.get('hgvs_p'),
                chromosome=mut_data.get('chrom'),
                position=mut_data.get('pos'),
                ref=mut_data.get('ref'),
                alt=mut_data.get('alt'),
                vaf=mut_data.get('vaf'),
                coverage=mut_data.get('coverage'),
                zygosity=self._parse_zygosity(mut_data.get('zygosity')),
                source=self._parse_source(mut_data.get('source')),
                classification=mut_data.get('classification')
            )
            mutations.append(mutation)
        
        return mutations
    
    def _normalize_mutation(self, mutation: Mutation) -> Mutation:
        """Normalize gene names and HGVS notation."""
        mutation.gene = self.gene_normalizer.normalize(mutation.gene)
        
        if mutation.hgvs_c:
            mutation.hgvs_c = self.hgvs_normalizer.normalize(mutation.hgvs_c)
        if mutation.hgvs_p:
            mutation.hgvs_p = self.hgvs_normalizer.normalize(mutation.hgvs_p)
        
        return mutation
```

### PDF Parser (LLM-Based)

```python
# api/services/extraction/parsers/pdf_parser.py

from typing import BinaryIO, Union
import io
import logging

# PDF extraction
import fitz  # PyMuPDF
from google import genai  # Gemini for intelligent extraction

logger = logging.getLogger(__name__)

class PDFParser:
    """
    Extract mutation and clinical data from PDF reports using LLM.
    
    Supports:
    - Foundation Medicine reports
    - Tempus reports
    - Guardant Health reports
    - Generic lab reports
    """
    
    EXTRACTION_PROMPT = """
    You are a clinical genomics expert. Extract all mutations and clinical data from this report.
    
    Return JSON with this structure:
    {
        "patient_id": "string or null",
        "disease": "cancer type",
        "mutations": [
            {
                "gene": "BRAF",
                "variant": "V600E",
                "hgvs_p": "p.Val600Glu",
                "hgvs_c": "c.1799T>A",
                "vaf": 0.45,
                "classification": "Pathogenic"
            }
        ],
        "clinical_data": {
            "stage": "IVB",
            "histology": "adenocarcinoma",
            "prior_treatments": ["carboplatin", "paclitaxel"],
            "biomarkers": {
                "TMB": 10.2,
                "MSI": "Stable",
                "PD-L1": "50%"
            }
        },
        "germline_mutations": [],
        "lab_name": "Foundation Medicine",
        "report_date": "2025-01-15"
    }
    
    IMPORTANT:
    - Extract ALL mutations listed, including VUS
    - Use standard HGVS notation
    - Normalize gene symbols to HGNC
    - If data is unclear, mark as null
    
    Report text:
    {report_text}
    """
    
    def __init__(self, model_id: str = "gemini-2.0-flash"):
        self.client = genai.Client()
        self.model_id = model_id
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes],
        metadata: dict = None
    ) -> dict:
        """
        Parse PDF report and extract structured data.
        
        Args:
            file: PDF file content
            metadata: Optional metadata
        
        Returns:
            Dict with extracted data
        """
        # Step 1: Extract text from PDF
        text = self._extract_text(file)
        logger.info(f"Extracted {len(text)} characters from PDF")
        
        # Step 2: Use LLM to extract structured data
        prompt = self.EXTRACTION_PROMPT.format(report_text=text[:50000])  # Limit
        
        response = self.client.models.generate_content(
            model=self.model_id,
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.1  # Low temperature for accuracy
            }
        )
        
        # Step 3: Parse JSON response
        import json
        try:
            extracted = json.loads(response.text)
        except json.JSONDecodeError:
            logger.error("Failed to parse LLM response as JSON")
            extracted = {"mutations": [], "error": "parse_failed"}
        
        # Step 4: Add provenance
        extracted['extraction_method'] = 'llm_pdf_extraction'
        extracted['source_text_length'] = len(text)
        
        return extracted
    
    def _extract_text(self, file: Union[BinaryIO, bytes]) -> str:
        """Extract text content from PDF."""
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        
        return text
```

### VCF Parser

```python
# api/services/extraction/parsers/vcf_parser.py

from typing import BinaryIO, Union, List, Dict
import io

class VCFParser:
    """
    Parse VCF (Variant Call Format) files.
    
    Supports:
    - VCF 4.1, 4.2, 4.3
    - Multi-sample VCFs (uses first sample)
    - Gzipped VCF files
    """
    
    def __init__(self):
        self.required_fields = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']
    
    async def parse(
        self,
        file: Union[BinaryIO, bytes, str],
        metadata: dict = None
    ) -> dict:
        """Parse VCF file and extract mutations."""
        
        if isinstance(file, bytes):
            file = io.BytesIO(file)
        
        mutations = []
        header_info = {}
        
        for line in file:
            if isinstance(line, bytes):
                line = line.decode('utf-8')
            line = line.strip()
            
            # Parse header
            if line.startswith('##'):
                self._parse_header_line(line, header_info)
                continue
            
            # Parse column header
            if line.startswith('#CHROM'):
                columns = line.split('\t')
                continue
            
            # Parse variant line
            if line and not line.startswith('#'):
                mutation = self._parse_variant_line(line, columns)
                if mutation:
                    mutations.append(mutation)
        
        return {
            'mutations': mutations,
            'vcf_header': header_info,
            'mutation_count': len(mutations)
        }
    
    def _parse_variant_line(self, line: str, columns: List[str]) -> Dict:
        """Parse a single variant line."""
        fields = line.split('\t')
        
        mutation = {
            'chrom': fields[0],
            'pos': int(fields[1]),
            'id': fields[2] if fields[2] != '.' else None,
            'ref': fields[3],
            'alt': fields[4],
            'qual': float(fields[5]) if fields[5] != '.' else None,
            'filter': fields[6],
            'info': self._parse_info(fields[7]) if len(fields) > 7 else {}
        }
        
        # Extract gene and variant from INFO field
        info = mutation['info']
        mutation['gene'] = info.get('GENE', info.get('Gene', ''))
        mutation['hgvs_c'] = info.get('HGVSc', info.get('HGVS_c', ''))
        mutation['hgvs_p'] = info.get('HGVSp', info.get('HGVS_p', ''))
        mutation['variant'] = mutation['hgvs_p'] or f"{mutation['ref']}>{mutation['alt']}"
        
        # Extract VAF if available
        if len(fields) > 9:  # Has sample data
            format_fields = fields[8].split(':')
            sample_data = fields[9].split(':')
            format_dict = dict(zip(format_fields, sample_data))
            
            if 'AF' in format_dict:
                mutation['vaf'] = float(format_dict['AF'])
            elif 'AD' in format_dict:
                # Calculate from allele depth
                ad = [int(x) for x in format_dict['AD'].split(',')]
                if sum(ad) > 0:
                    mutation['vaf'] = ad[1] / sum(ad)
        
        return mutation
    
    def _parse_info(self, info_str: str) -> Dict:
        """Parse INFO field into dictionary."""
        info = {}
        for item in info_str.split(';'):
            if '=' in item:
                key, value = item.split('=', 1)
                info[key] = value
            else:
                info[item] = True
        return info
```

---

## ðŸ§ª TESTING

### Unit Tests

```python
# api/services/extraction/tests/test_vcf_parser.py

import pytest
from ..parsers.vcf_parser import VCFParser

@pytest.fixture
def vcf_content():
    return b"""##fileformat=VCFv4.2
##INFO=<ID=GENE,Number=1,Type=String,Description="Gene name">
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
chr17\t7674872\t.\tG\tA\t.\tPASS\tGENE=TP53;HGVSp=p.Arg175His\tGT:AF\t0/1:0.62
"""

@pytest.mark.asyncio
async def test_vcf_parser_basic(vcf_content):
    parser = VCFParser()
    result = await parser.parse(vcf_content)
    
    assert result['mutation_count'] == 2
    assert result['mutations'][0]['gene'] == 'BRAF'
    assert result['mutations'][0]['hgvs_p'] == 'p.Val600Glu'
    assert result['mutations'][0]['vaf'] == 0.45

@pytest.mark.asyncio
async def test_vcf_parser_missing_vaf(vcf_content):
    # Test handling of missing VAF
    content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF
"""
    parser = VCFParser()
    result = await parser.parse(content)
    
    assert result['mutations'][0]['vaf'] is None
```

### Integration Test

```python
# api/services/extraction/tests/test_integration.py

import pytest
from ..extraction_agent import DataExtractionAgent

@pytest.fixture
def agent():
    return DataExtractionAgent()

@pytest.mark.asyncio
async def test_full_extraction_flow(agent):
    # Test with sample VCF
    vcf_content = b"""##fileformat=VCFv4.2
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE
chr7\t140453136\t.\tT\tA\t.\tPASS\tGENE=BRAF;HGVSp=p.Val600Glu\tGT:AF\t0/1:0.45
"""
    
    profile = await agent.extract(
        file=vcf_content,
        file_type='vcf',
        metadata={'patient_id': 'TEST-001'}
    )
    
    assert profile.patient_id == 'TEST-001'
    assert len(profile.mutations) == 1
    assert profile.mutations[0].gene == 'BRAF'
    assert profile.extraction_provenance['source'] == 'vcf'
```

---

## ðŸ“‹ IMPLEMENTATION CHECKLIST

### Phase 1: Core Parsers
- [ ] Implement VCF parser (standard format)
- [ ] Implement MAF parser (tab-delimited)
- [ ] Implement JSON parser (structured input)
- [ ] Unit tests for each parser

### Phase 2: PDF Extraction
- [ ] Set up PyMuPDF for text extraction
- [ ] Create LLM extraction prompt
- [ ] Handle Foundation Medicine reports
- [ ] Handle Tempus reports
- [ ] Handle generic reports
- [ ] Unit tests for PDF extraction

### Phase 3: Validation & Normalization
- [ ] Gene name validation (HGNC)
- [ ] HGVS notation validation
- [ ] Zygosity inference
- [ ] Data quality flagging
- [ ] Unit tests for validators

### Phase 4: Integration
- [ ] Create DataExtractionAgent class
- [ ] Wire up all parsers
- [ ] Add provenance tracking
- [ ] Integration tests
- [ ] Performance testing (100 files/minute target)

---

## ðŸ”— DEPENDENCIES

### Python Packages

```txt
# requirements_extraction.txt
PyMuPDF>=1.23.0          # PDF text extraction
google-genai>=0.3.0      # LLM for PDF extraction
pydantic>=2.0.0          # Data validation
hgvs>=1.5.4              # HGVS notation parsing
```

### External Services

| Service | Purpose | Required |
|---------|---------|----------|
| Gemini API | PDF extraction | Yes (for PDF) |
| HGNC API | Gene symbol validation | Optional |

---

## ðŸ“¡ API ENDPOINT

```yaml
POST /api/agents/extract
Content-Type: multipart/form-data

Request:
  file: binary
  file_type: string  # vcf, maf, pdf, json
  metadata: json     # optional

Response:
  patient_profile: PatientProfile
  extraction_time_ms: number
  warnings: string[]
```

---

## âœ… ACCEPTANCE CRITERIA

1. âœ… Can parse VCF files with >95% accuracy
2. âœ… Can parse MAF files with >95% accuracy
3. âœ… Can extract mutations from PDF reports with >85% accuracy
4. âœ… All gene names normalized to HGNC
5. âœ… All HGVS notation validated
6. âœ… Data quality flags generated for missing data
7. âœ… Provenance tracked for all extractions
8. âœ… Processing time <10 seconds for typical files
9. âœ… Unit test coverage >80%

---