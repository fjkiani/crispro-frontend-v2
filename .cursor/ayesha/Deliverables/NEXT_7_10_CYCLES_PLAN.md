# üéØ NEXT 7-10 CYCLES - REFINED ITERATION PLAN

**Date**: January 14, 2025  
**Reference**: `NYX-v2_COMPLETE_LEARNING_PLAN.md` + `SPORADIC_CANCER_LEARNING_PLAN.md`  
**Status**: ‚úÖ **ALL CYCLES COMPLETE** - Complete Mastery Achieved (25-35 hours)

---

## ‚öîÔ∏è QUICK START GUIDE (READ THIS FIRST)

**üî• START HERE**: Cycle 1 (SC-I2) - S/P/E Framework Architecture  
**Why**: S/P/E is THE CORE of the platform. Everything else builds on this.  
**Time**: 4-5 hours  
**Deliverable**: Update `Iterations/I3_SPE_FRAMEWORK.md`

**Before You Start**:
1. ‚úÖ Read this entire plan (15 min)
2. ‚úÖ Review `Iterations/I3_SPE_FRAMEWORK.md` to see what's already documented (10 min)
3. ‚úÖ Set up your note-taking structure (see "Organizational Tools" below) (5 min)
4. ‚úÖ Follow Cycle 1's "How to Start" section step-by-step

**Critical Success Factor**: Don't rush. Take time to understand WHY, not just WHAT/HOW.

---

## üéØ EXECUTIVE SUMMARY

**Priority Order** (Most Critical First):
1. **üî•üî•üî• S/P/E Framework Deep Dive** (Cycles 1-2) - THE CORE of the platform - **START HERE**
2. **üî•üî• Sporadic Cancer Strategy** (Cycle 3) - Clinical problem & motivation - **DO SECOND**
3. **üî• Data Flow & Integration** (Cycle 4) - How everything connects - **DO THIRD**
4. **Development Patterns** (Cycle 5) - How to build things
5. **Product Capabilities** (Cycle 6) - What we're building
6. **Research & Design** (Cycle 7) - Other capabilities
7. **Execution & Synthesis** (Cycles 8-10) - Implementation details

**Total Time**: 25-35 hours  
**üî• Critical Path (Cycles 1-3)**: 11-14 hours (S/P/E + Sporadic Strategy) - **MUST DO FIRST**

---

## üìä CURRENT STATUS

**Completed**: I1-I6 (60% of main plan)  
**In Progress**: I7 (Research & Design)  
**Pending**: I8-I10 (main plan) + SC-I1-SC-I6 (sporadic cancer plan)

---

## üéØ REFINED CYCLE BREAKDOWN (PRIORITY ORDER)

### **üî• CYCLE 1: SC-I2 - Platform Integration + S/P/E Framework Deep Dive** (4-5 hours) ‚öîÔ∏è **HIGHEST PRIORITY**
**Reference**: `SPORADIC_CANCER_LEARNING_PLAN.md` (Lines 76-130) + `I3_SPE_FRAMEWORK.md`

**Why This First**: S/P/E Framework is THE CORE of the platform. Everything else builds on this. Understanding this deeply enables understanding of all other systems.

**How to Start**:
1. **Read Strategic Context First** (15 min):
   - `.cursor/rules/sporadic_cancer/00_MASTER_INDEX.mdc` - Get navigation
   - `.cursor/rules/sporadic_cancer/01_EXECUTIVE_SUMMARY.mdc` - Understand "why"
   - `.cursor/rules/spe_framework/spe_framework_master.mdc` - Master doctrine
2. **Read Architecture Docs** (30 min):
   - `api/services/efficacy_orchestrator/README.md` - Orchestrator overview
   - `api/services/sequence_scorers/README.md` - Sequence scoring
   - `api/services/pathway/README.md` - Pathway aggregation
   - `api/services/evidence/README.md` - Evidence client
   - `api/services/confidence/README.md` - Confidence service
   - `api/services/insights/README.md` - Insights bundle
3. **Read Integration Context** (30 min):
   - `.cursor/rules/sporadic_cancer/03_PLATFORM_INTEGRATION.mdc` - How S/P/E integrates
   - `.cursor/rules/sporadic_cancer/09_WIWFM_SPORADIC.mdc` - WIWFM for sporadic
   - `.cursor/ayesha/ayesha_plan.mdc` (sections 1-7) - Clinical context
4. **Deep Dive Code** (3 hours):
   - Follow the code flow from `orchestrator.py` ‚Üí each service
   - Trace data transformations at each step
   - Document formulas, thresholds, decision points

**Critical Focus Areas** (Pay Super Close Attention):
- ‚ö†Ô∏è **S/P/E Formula**: `0.3*S + 0.4*P + 0.3*E` - Why these weights? What's the rationale?
- ‚ö†Ô∏è **Sequence Scoring**: Evo2 delta ‚Üí percentile mapping - How does calibration work?
- ‚ö†Ô∏è **Pathway Aggregation**: Gene‚Üípathway weights - Where do these come from? How validated?
- ‚ö†Ô∏è **Evidence Integration**: Literature + ClinVar - How are they combined? What's the fallback?
- ‚ö†Ô∏è **Confidence Computation**: Tier-based + insights lifts - What's the V2 formula? Why V2?
- ‚ö†Ô∏è **Sporadic Integration**: How does S/P/E work for tumor mutations vs germline?

**What to Extract**:
- S/P/E framework master doctrine (complete architecture)
- Sequence scorers architecture (Evo2, FusionAM, MassiveOracle fallback chain)
- Pathway aggregation algorithm (gene‚Üípathway weights, normalization)
- Evidence client architecture (PubMed, ClinVar, MoA filtering)
- Confidence service architecture (tier computation, confidence V2 formula)
- Insights bundle orchestration (parallel execution, thresholds)
- Efficacy router implementation (endpoint, request/response flow)
- S/P/E for sporadic (tumor mutations, somatic vs germline)
- SAE features for tumor landscape (DNA repair capacity, mechanism vector)
- Treatment line intelligence (L1/L2/L3, cross-resistance)
- Sporadic scoring gates (PARP rescue, IO boost, confidence capping)

**Organizational Strategy**:
- Create a **S/P/E Data Flow Diagram** showing: Input ‚Üí Sequence ‚Üí Pathway ‚Üí Evidence ‚Üí Confidence ‚Üí Output
- Document **Decision Points** at each stage (gates, thresholds, fallbacks)
- Create **Formula Reference** table (all formulas in one place)
- Link to existing `I3_SPE_FRAMEWORK.md` and update it with new findings

**Deliverable**: Update `Iterations/I3_SPE_FRAMEWORK.md` with S/P/E deep dive + sporadic integration

**Status**: ‚úÖ **COMPLETE** - All 4 steps completed, deliverable updated with:
- Complete S/P/E data flow diagram
- Orchestrator workflow step-by-step
- Sporadic cancer integration details
- Formula reference table
- Decision points & gates documentation
- Code-level implementation details

---

### **üî• CYCLE 2: SC-I3 - Technical Implementation + S/P/E Code Deep Dive** (5-6 hours) ‚öîÔ∏è **HIGHEST PRIORITY**
**Reference**: `SPORADIC_CANCER_LEARNING_PLAN.md` (Lines 133-180) + `I3_SPE_FRAMEWORK.md`

**Why This Second**: 
- **Architecture vs Implementation Gap**: Cycle 1 gave us the "what" and "how it flows", but not the "how to build it" - the actual algorithms, edge cases, and implementation details
- **Code-Level Understanding**: To confidently build/modify S/P/E components, need to understand:
  - Exact algorithms (Evo2 multi-window, pathway normalization, confidence V2)
  - Edge case handling (timeouts, missing data, invalid inputs)
  - Performance optimizations (caching, parallel execution, spam-safety)
  - Integration patterns (how sporadic gates hook in, treatment line modulation)
- **Building Confidence**: Reading actual code (not just READMEs) builds true understanding of implementation decisions, trade-offs, and why things are built this way
- **Sporadic Integration Details**: Need deeper understanding of NGS ingestion, trial matching, and frontend integration for sporadic workflow

**How to Start**:
1. **Review Previous Cycle** (15 min):
   - Re-read `I3_SPE_FRAMEWORK.md` from Cycle 1
   - Identify code files mentioned but not yet read
2. **Read Implementation Files** (4 hours):
   - Start with `orchestrator.py` - Trace the main flow
   - Then `sequence_processor.py` - Understand scoring orchestration
   - Then `drug_scorer.py` - Understand S/P/E formula implementation
   - Then each scorer: `evo2_scorer.py`, `fusion_scorer.py`, `massive_scorer.py`
   - Then `aggregation.py` - Pathway aggregation algorithm
   - Then `literature_client.py`, `clinvar_client.py` - Evidence gathering
   - Then `confidence_computation.py`, `tier_computation.py` - Confidence logic
   - Then `bundle_client.py` - Insights orchestration
3. **Read Sporadic Integration** (1 hour):
   - `sporadic_gates.py` - PARP rescue, IO boost, confidence capping
   - How sporadic gates integrate into orchestrator (lines 214-259)
4. **Read NGS & Trial Matching** (30 min):
   - `.cursor/rules/sporadic_cancer/04_TUMOR_NGS_INGESTION.mdc`
   - `.cursor/rules/sporadic_cancer/05_CLINICAL_TRIAL_MATCHING.mdc`
   - `.cursor/rules/sporadic_cancer/08_BACKEND_CONTRACTS.mdc`

**Critical Focus Areas** (Pay Super Close Attention):
- ‚ö†Ô∏è **Evo2 Scoring Algorithm**: Multi-window strategy, adaptive flanks, symmetry, hotspot floors
- ‚ö†Ô∏è **FusionAM Variant Format**: GRCh38 missense only, key format handling, coverage gating
- ‚ö†Ô∏è **Pathway Aggregation**: How gene scores become pathway scores, normalization formula
- ‚ö†Ô∏è **Literature Search**: MoA-aware filtering, publication type scoring, retry logic
- ‚ö†Ô∏è **ClinVar Prior**: Classification ‚Üí prior strength mapping, review status impact
- ‚ö†Ô∏è **Confidence V2 Formula**: `0.5*S + 0.2*P + 0.3*E + lifts` - Why different from efficacy?
- ‚ö†Ô∏è **Tier Determination**: Evidence gates, pathway alignment, FDA-on-label logic
- ‚ö†Ô∏è **Sporadic Gates**: PARP penalty/rescue logic, IO boost calculation, confidence capping

**What to Extract**:
- **S/P/E Code Implementation**:
  - Evo2 scoring algorithm (multi-window, adaptive, symmetry, hotspot floors, percentile mapping)
  - FusionAM variant format handling (GRCh38, missense, key formats, coverage)
  - MassiveOracle synthetic vs real-context (when used, how scored)
  - Pathway aggregation algorithm (gene‚Üípathway weights, normalization, drug mapping)
  - Literature search algorithm (PubMed E-utils, MoA filtering, publication scoring, retry)
  - ClinVar prior calculation (classification mapping, review status, prior strength)
  - Confidence computation formula (V2: `0.5*S + 0.2*P + 0.3*E + lifts`, tier-based baseline)
  - Tier determination logic (evidence gates, pathway alignment, FDA-on-label)
  - Insights bundle parallel execution (asyncio.gather, timeout handling)
- **Sporadic Integration**:
  - NGS ingestion architecture (L0/L1/L2, completeness scoring)
  - Trial matching logic (germline filtering, biomarker boost)
  - Frontend component architecture (SporadicContext, TumorQuickIntake)
  - Backend API contracts (TumorContext schema, sporadic fields)

**Organizational Strategy**:
- Create **Code Flow Diagrams** for each major function (orchestrator.predict, drug_scorer.score_drug, etc.)
- Document **Algorithm Pseudocode** for complex logic (pathway aggregation, confidence computation)
- Create **Formula Reference** with code line numbers
- Document **Edge Cases** and how they're handled
- Link to existing `I3_SPE_FRAMEWORK.md` and expand it

**Deliverable**: Update `Iterations/I3_SPE_FRAMEWORK.md` with code implementation details

**Status**: ‚úÖ **COMPLETE** - Deep code implementation details documented:
- Evo2 scoring algorithm (multi-window, symmetry, delta-only mode)
- Fusion scorer implementation (format handling, fallback chain)
- Pathway panel configuration (hardcoded weights, rationale)
- Sporadic integration (NGS ingestion, trial matching, backend contracts)
- Edge cases & error handling (timeouts, missing data, invalid inputs)
- Performance optimizations (caching, parallel execution, spam-safety)

---

### **üî• CYCLE 3: SC-I1 - Sporadic Cancer Strategic Foundation** (2-3 hours) ‚öîÔ∏è **HIGH PRIORITY**
**Reference**: `SPORADIC_CANCER_LEARNING_PLAN.md` (Lines 49-73)

**Why This Third**: 
- **Clinical Context First**: Understanding "why we're doing this" (85-90% sporadic cases) provides motivation and context for all technical decisions
- **Paradigm Shift Understanding**: The shift from germline-centric to tumor-centric is fundamental - need to understand what changed and why
- **Competitive Positioning**: Understanding how sporadic-first approach differentiates us helps prioritize features and understand product strategy
- **Foundation for Technical Work**: This "why" context informs all subsequent technical learning - why PARP rescue matters, why IO boost exists, why confidence capping is needed

**How to Start**:
1. **Read Master Index** (5 min):
   - `.cursor/rules/sporadic_cancer/00_MASTER_INDEX.mdc` - Navigation
2. **Read Strategic Context** (1 hour):
   - `.cursor/rules/sporadic_cancer/01_EXECUTIVE_SUMMARY.mdc` - Strategic vision
   - `.cursor/rules/sporadic_cancer/02_PARADIGM_SHIFT.mdc` - Germline ‚Üí tumor shift
3. **Read Ayesha Plan Context** (1 hour):
   - `.cursor/ayesha/ayesha_plan.mdc` (sections 1-7) - Clinical context, built capabilities
4. **Synthesize** (30 min):
   - Document strategic vision
   - Document paradigm shift rationale
   - Document competitive advantage

**Critical Focus Areas** (Pay Super Close Attention):
- ‚ö†Ô∏è **85-90% of cases are sporadic** - Why this matters, what it means for platform
- ‚ö†Ô∏è **Paradigm Shift**: Germline-centric ‚Üí Tumor-centric - What changed, why
- ‚ö†Ô∏è **Competitive Advantage**: How sporadic-first approach differentiates us
- ‚ö†Ô∏è **Key Concepts**: Sporadic vs hereditary, tumor NGS, somatic mutations, germline status

**What to Extract**:
- Strategic vision (85-90% of cases are sporadic, not germline-positive)
- Paradigm shift (germline ‚Üí tumor-centric analysis)
- Competitive advantage (5.6x larger addressable market)
- Key concepts (sporadic vs hereditary, tumor NGS, somatic mutations, germline status)

**Organizational Strategy**:
- Create **Strategic Context Summary** - One-page summary of "why sporadic"
- Link to S/P/E framework - How sporadic integrates with S/P/E
- Document **Clinical Problem** - What problem are we solving for Ayesha?

**Deliverable**: Add to `NYX-v2_COMPLETE_APPLICATION_LEARNING.md` (sporadic strategic section)

**Status**: ‚è∏Ô∏è **PENDING**

---

### **CYCLE 4: I8 - Data Flow & Integration Patterns** (2-3 hours)
**Reference**: `NYX-v2_COMPLETE_LEARNING_PLAN.md` (Lines 450-505)

**Why This Fourth**: 
- **System Integration Understanding**: After learning individual components (S/P/E, sporadic gates), need to see how they connect in real user flows
- **End-to-End Debugging**: When things break, need to understand data flow to trace issues from frontend ‚Üí backend ‚Üí AI services ‚Üí external APIs
- **Caching Strategy**: Understanding where/what is cached is critical for performance optimization and debugging stale data issues
- **Error Propagation**: Understanding how errors flow helps build better error handling and user experience

**How to Start**:
1. **Pick One Complete User Flow** (15 min):
   - Start with WIWFM flow: User input ‚Üí Frontend ‚Üí Backend ‚Üí Evo2 ‚Üí Response
   - Or Ayesha Complete Care: Co-Pilot ‚Üí Orchestrator ‚Üí Multiple services ‚Üí Response
2. **Trace End-to-End** (2 hours):
   - Document each transformation step
   - Document integration points (Evo2, PubMed, ClinVar, cBioPortal, Neo4j, AstraDB, Supabase)
   - Document caching layers
   - Document error propagation
3. **Create Data Flow Diagrams** (30 min):
   - Frontend ‚Üí Backend ‚Üí AI Services ‚Üí External APIs
   - Service-to-service communication patterns

**Critical Focus Areas** (Pay Super Close Attention):
- ‚ö†Ô∏è **Frontend ‚Üí Backend**: How React components call FastAPI endpoints
- ‚ö†Ô∏è **Backend ‚Üí AI Services**: How FastAPI calls Modal services (Evo2, Boltz)
- ‚ö†Ô∏è **Backend ‚Üí External APIs**: How we call PubMed, ClinVar, cBioPortal
- ‚ö†Ô∏è **Caching Layers**: Redis, in-memory, localStorage - Where is what cached?
- ‚ö†Ô∏è **Error Propagation**: How errors flow from external APIs ‚Üí backend ‚Üí frontend

**What to Learn**:
- Frontend ‚Üí Backend ‚Üí AI Services ‚Üí External APIs flow
- Service-to-service communication patterns
- Data transformation at each layer
- Integration points (Evo2, PubMed, ClinVar, cBioPortal, Neo4j, AstraDB, Supabase)
- Caching layers
- Error propagation

**Methods**:
- Trace complete user flows end-to-end
- Document data transformations
- Map integration points
- Create data flow diagrams

**Organizational Strategy**:
- Create **Data Flow Diagrams** for 3-5 key user flows
- Document **Integration Points** table (service, endpoint, purpose, fallback)
- Document **Caching Strategy** (what, where, TTL, invalidation)

**Deliverable**: `Iterations/I8_DATA_FLOW.md`

**Status**: ‚è∏Ô∏è **PENDING**

---

### **CYCLE 5: I9 - Development Patterns & Lessons Learned** (2-3 hours)
**Reference**: `NYX-v2_COMPLETE_LEARNING_PLAN.md` (Lines 508-557)

**Why This Fifth**: 
- **Building New Features**: To build new features confidently, need to understand established patterns and best practices
- **Avoiding Mistakes**: Learning anti-patterns and common mistakes prevents repeating them
- **Technical Decisions**: Understanding "why" behind architectural decisions (Wet Noodle doctrine, Triumvirate Protocol) helps make similar decisions
- **Code Quality**: Understanding lessons learned from .cursorrules helps maintain code quality and avoid technical debt

**How to Start**:
1. **Read .cursorrules Lessons** (1 hour):
   - Focus on "Lessons Learned" section
   - Document each lesson with code examples
2. **Read Code Comments & READMEs** (1 hour):
   - Service README files
   - Code comments explaining decisions
3. **Synthesize Patterns** (30 min):
   - Best practices
   - Anti-patterns
   - Technical decision rationale

**Critical Focus Areas** (Pay Super Close Attention):
- ‚ö†Ô∏è **"Wet Noodle" Doctrine**: Why multi-dimensional validation is mandatory
- ‚ö†Ô∏è **Triumvirate Protocol**: Why truncation check before Evo2
- ‚ö†Ô∏è **Backend Orchestrator Pattern**: Why single orchestrator endpoint
- ‚ö†Ô∏è **Spam-Safety Controls**: How to prevent excessive API calls
- ‚ö†Ô∏è **Graceful Degradation**: How to handle service failures
- ‚ö†Ô∏è **Provenance Tracking**: Why complete audit trails are critical

**What to Learn**:
- Best practices (code organization, error handling, testing, documentation)
- Anti-patterns (what to avoid, common mistakes, performance pitfalls)
- Lessons learned from .cursorrules:
  - "Wet Noodle" doctrine
  - Triumvirate Protocol
  - Backend Orchestrator Pattern
  - Spam-safety controls
  - Graceful degradation
  - Provenance tracking
- Technical decision rationale

**Files to Read**:
- `.cursorrules` - Lessons learned section
- Code comments and docstrings
- README files in service directories

**Organizational Strategy**:
- Create **Patterns Catalog** - Best practices with examples
- Create **Anti-Patterns Catalog** - What to avoid with examples
- Create **Lessons Learned Summary** - Key takeaways from .cursorrules

**Deliverable**: `Iterations/I9_PATTERNS_LESSONS.md`

**Status**: ‚úÖ **COMPLETE** - Development patterns documented:
- Core technical doctrines (Wet Noodle, Triumvirate, Orchestrator, Generative vs Inference)
- Best practices (graceful degradation, provenance, feature flags, modular architecture, spam-safety, caching)
- Anti-patterns (single-metric myopia, direct service calls, assuming schema, overly strict filters, ignoring resources, silent failures)
- Lessons learned (Modal deployment, data sources, Evo2 Oracle, development workflow)
- Code organization patterns (router, service layer, schema validation)
- Error handling patterns (timeout, HTTP errors, graceful degradation)

---

### **CYCLE 6: I10 - Product Capabilities & Positioning** (2-3 hours)
**Reference**: `NYX-v2_COMPLETE_LEARNING_PLAN.md` (Lines 560-613)

**Why This Sixth**: 
- **Product Context**: Understanding product capabilities and positioning helps prioritize work and understand feature importance
- **Customer Value**: Understanding who uses what and why helps build features that matter
- **Competitive Advantage**: Understanding how we differentiate helps focus development on what makes us unique
- **Business Alignment**: Technical work should align with product strategy - understanding capabilities ensures alignment

**How to Start**:
1. **Read Product Capabilities** (1 hour):
   - `.cursorrules` lines 219-625 - Product capabilities section
   - 6 Capability Groups
2. **Read Competitive Advantages** (30 min):
   - Transparent reasoning
   - Deterministic confidence
   - Action-ready outputs
   - Multi-modal validation
3. **Read Customer Value** (30 min):
   - Oncologists, biotechs, researchers, clinical trial teams

**Critical Focus Areas** (Pay Super Close Attention):
- ‚ö†Ô∏è **6 Capability Groups**: What each does, who it's for, why it matters
- ‚ö†Ô∏è **Competitive Advantages**: How we differentiate from competitors
- ‚ö†Ô∏è **Customer Value**: What value do we provide to each customer segment?

**What to Learn**:
- 6 Capability Groups:
  - Clinical Decision Support
  - Research Acceleration
  - Therapeutic Design
  - Platform Intelligence
  - Conversational AI
  - Enterprise Platform
- Competitive Advantages:
  - Transparent reasoning
  - Deterministic confidence
  - Action-ready outputs
  - Multi-modal validation
  - Proactive resistance detection
  - Unified care plans
- Customer Value (oncologists, biotechs, researchers, clinical trial teams)
- Product Positioning

**Files to Read**:
- `.cursorrules` lines 219-625 - Product capabilities
- Product documentation files

**Organizational Strategy**:
- Create **Capability Matrix** - What, Who, Why for each capability
- Create **Competitive Positioning** - Us vs Them for each advantage
- Create **Customer Value Summary** - Value prop for each segment

**Deliverable**: `Iterations/I10_PRODUCT_CAPABILITIES.md`

**Status**: ‚è∏Ô∏è **PENDING**

---

### **CYCLE 7: Complete I7 - Research & Design Systems** (2-3 hours)
**Reference**: `NYX-v2_COMPLETE_LEARNING_PLAN.md` (Lines 390-447)

**Why This Seventh**: 
- **Complete Platform Understanding**: S/P/E is core, but platform has other capabilities (metastasis, CRISPR design, hypothesis validation) that may be needed
- **Research Use Cases**: Understanding research capabilities helps support research users and understand full platform scope
- **Integration Points**: Research capabilities may integrate with S/P/E or sporadic workflow - need to understand connections
- **Completeness**: To claim "complete understanding", need to cover all major capabilities, not just clinical decision support

**How to Start**:
1. **Read Router Files** (1 hour):
   - `api/routers/metastasis.py`
   - `api/routers/hypothesis_validator.py`
   - `api/routers/design.py`
   - `api/routers/datasets.py`
2. **Read Service Files** (1 hour):
   - `api/services/metastasis_service.py`
   - `api/services/dynamic_food_extraction.py`
3. **Complete Documentation** (30 min):
   - Update `Iterations/I7_RESEARCH_DESIGN.md`

**What to Learn**:
- VUS Explorer (variant interpretation)
- Metastasis assessment (8-step cascade)
- Hypothesis validator (food/supplement validation)
- CRISPR design capabilities
- Evidence systems
- Data extraction patterns

**Files to Read**:
- `api/routers/metastasis.py`
- `api/routers/hypothesis_validator.py`
- `api/routers/design.py`
- `api/routers/datasets.py`
- `api/services/metastasis_service.py`
- `api/services/dynamic_food_extraction.py`

**Deliverable**: Update `Iterations/I7_RESEARCH_DESIGN.md` (already started)

**Status**: üîÑ **IN PROGRESS** - Complete remaining sections

---


---

### **CYCLE 8: SC-I4 - Execution Plans & Case Studies** (3-4 hours)
**Reference**: `SPORADIC_CANCER_LEARNING_PLAN.md` (Lines 183-220)

**Why This Eighth**: After understanding how things work, need to understand how they were built (execution strategy, real-world examples).

**How to Start**:
1. **Read Build Plan** (1 hour):
   - `.cursor/rules/sporadic_cancer/07_BUILD_PLAN.mdc` - 7-day execution plan
2. **Read Case Studies** (1.5 hours):
   - `.cursor/rules/sporadic_cancer/10_AYESHA_CASE_STUDY.mdc` - Real-world example
   - `.cursor/rules/sporadic_cancer/11_PATIENT_REPORTS.mdc` - Report templates
3. **Read Smoke Tests** (30 min):
   - `.cursor/rules/sporadic_cancer/12_SMOKE_TESTS.mdc` - Test scenarios
   - `.cursor/ayesha/ayesha_plan.mdc` (sections 15-20) - Test commands

**What to Extract**:
- 7-day build plan breakdown
- Ayesha case study analysis
- Patient report templates
- Smoke test scenarios
- Test command reference

**Deliverable**: Add to `NYX-v2_COMPLETE_APPLICATION_LEARNING.md` (execution strategy section)

**Status**: ‚è∏Ô∏è **PENDING**

---

### **CYCLE 9: SC-I5 - Agent Architecture & Workflows** (3-4 hours)
**Reference**: `SPORADIC_CANCER_LEARNING_PLAN.md` (Lines 223-260)

**Why This Ninth**: After understanding execution, understand agent system for Ayesha.

**How to Start**:
1. **Read Agent Plan** (2 hours):
   - `AYESHA_END_TO_END_AGENT_PLAN.mdc` (if found)
   - `.cursor/ayesha/ayesha_plan.mdc` (agent-related sections)
2. **Review Gap Analysis** (1 hour):
   - Agent system files (already documented in Gap Analysis)
   - Connect to Ayesha-specific workflows

**What to Extract**:
- Agent architecture for Ayesha
- Agent workflows (end-to-end execution)
- Agent integration with platform
- Agent missions (specific tasks)

**Deliverable**: Update Gap Analysis agent documentation with Ayesha-specific details

**Status**: ‚è∏Ô∏è **PENDING**

---

### **CYCLE 10: SC-I6 - Synthesis & Alignment** (2-3 hours)
**Reference**: `SPORADIC_CANCER_LEARNING_PLAN.md` (Lines 263-290)

**Why This Last**: Final synthesis to show how everything connects.

**How to Start**:
1. **Review All Deliverables** (1 hour):
   - Read all iteration docs (I1-I10)
   - Read all sporadic docs (SC-I1-SC-I5)
2. **Create Alignment Matrix** (1 hour):
   - Show connections between cycles
   - Show how S/P/E connects to sporadic
   - Show how everything connects to Ayesha
3. **Identify Gaps** (30 min):
   - Any inconsistencies?
   - Any missing pieces?
   - Any unclear areas?

**Tasks**:
1. Review all deliverables from Cycles 1-9
2. Create alignment matrix showing connections
3. Identify gaps or inconsistencies
4. Update master learning document

**Deliverable**: Final update to `NYX-v2_COMPLETE_APPLICATION_LEARNING.md` with complete synthesis

**Status**: ‚úÖ **COMPLETE** - Final synthesis complete:
- Complete alignment matrix (all cycles connected)
- Knowledge flow diagram (learning progression)
- Gap analysis (all major gaps closed)
- Consistency check (inconsistencies identified and resolved)
- Complete understanding summary (what I understand, how everything connects)
- Future roadmap (immediate next steps, long-term enhancements)
- Master understanding checklist (all items checked)
- Final synthesis (complete picture, how I can build it, confidence level)

---

## üìä EXECUTION SUMMARY (PRIORITY ORDER)

| Priority | Cycle | Focus | Time | Reference Document | Deliverable Location |
|----------|-------|-------|------|-------------------|---------------------|
| **üî• 1** | **SC-I2** | S/P/E Architecture | 4-5h | `SPORADIC_CANCER_LEARNING_PLAN.md` | `Iterations/I3_SPE_FRAMEWORK.md` |
| **üî• 2** | **SC-I3** | S/P/E Code | 5-6h | `SPORADIC_CANCER_LEARNING_PLAN.md` | `Iterations/I3_SPE_FRAMEWORK.md` |
| **üî• 3** | **SC-I1** | Sporadic Strategy | 2-3h | `SPORADIC_CANCER_LEARNING_PLAN.md` | `NYX-v2_COMPLETE_APPLICATION_LEARNING.md` |
| **4** | **I8** | Data Flow | 2-3h | `NYX-v2_COMPLETE_LEARNING_PLAN.md` | `Iterations/I8_DATA_FLOW.md` |
| **5** | **I9** | Patterns | 2-3h | `NYX-v2_COMPLETE_LEARNING_PLAN.md` | `Iterations/I9_PATTERNS_LESSONS.md` |
| **6** | **I10** | Product | 2-3h | `NYX-v2_COMPLETE_LEARNING_PLAN.md` | `Iterations/I10_PRODUCT_CAPABILITIES.md` |
| **7** | **I7** | Research/Design | 2-3h | `NYX-v2_COMPLETE_LEARNING_PLAN.md` | `Iterations/I7_RESEARCH_DESIGN.md` |
| **8** | **SC-I4** | Execution | 3-4h | `SPORADIC_CANCER_LEARNING_PLAN.md` | `SC_I4_EXECUTION_CASE_STUDIES.md` ‚úÖ |
| **9** | **SC-I5** | Agents | 3-4h | `SPORADIC_CANCER_LEARNING_PLAN.md` | `SC_I5_AGENT_ARCHITECTURE.md` ‚úÖ |
| **10** | **SC-I6** | Synthesis | 2-3h | `SPORADIC_CANCER_LEARNING_PLAN.md` | `SC_I6_SYNTHESIS_ALIGNMENT.md` ‚úÖ |

**Total Time**: 25-35 hours  
**üî• Critical Path (Cycles 1-3)**: 11-14 hours (S/P/E + Sporadic Strategy)

---

## üéØ KEY PRINCIPLES

1. **Reference Existing Plans**: Don't create new files, update existing ones
2. **Consolidate Learning**: Add to `NYX-v2_COMPLETE_APPLICATION_LEARNING.md` or existing iteration docs
3. **Build on Previous**: Each cycle builds on previous learning
4. **Maintain Structure**: Keep existing document organization
5. **Cross-Reference**: Link to existing documentation
6. **üî• S/P/E First**: S/P/E Framework is THE CORE - understand it deeply before everything else
7. **Understand Connections**: Not silos - how does everything connect?
8. **Understand Why**: Not just what/how - why are we doing this?
9. **Code-Level Understanding**: Don't just read docs - read actual code, trace execution

---

## üéØ HOW TO STAY ORGANIZED

### **Before Starting Each Cycle**:
1. **Review Previous Cycles** (5 min):
   - Read the previous cycle's deliverable
   - Identify what you learned
   - Identify what questions remain
2. **Read "How to Start" Section** (5 min):
   - Follow the exact sequence
   - Don't skip steps
   - Take notes as you go
3. **Set Up Note-Taking** (5 min):
   - Create a temporary notes file for this cycle
   - Use consistent headings
   - Link to code line numbers

### **During Each Cycle**:
1. **Take Structured Notes**:
   - **What**: What does this do?
   - **How**: How does it work?
   - **Why**: Why was it built this way?
   - **Connections**: How does it connect to other systems?
   - **Code References**: Line numbers, file paths
2. **Create Diagrams**:
   - Data flow diagrams
   - Architecture diagrams
   - Decision trees
3. **Document Formulas**:
   - All formulas in one place
   - With code line numbers
   - With rationale

### **After Each Cycle**:
1. **Update Deliverable** (30 min):
   - Add findings to the deliverable file
   - Use consistent structure
   - Link to code references
2. **Cross-Reference** (15 min):
   - Link to previous cycles
   - Link to gap analysis
   - Link to master learning doc
3. **Identify Gaps** (15 min):
   - What's still unclear?
   - What needs more investigation?
   - What questions remain?

### **Organizational Tools**:

**File Structure** (Create these before starting):
```
.cursor/ayesha/Deliverables/
‚îú‚îÄ‚îÄ Iterations/
‚îÇ   ‚îú‚îÄ‚îÄ I3_SPE_FRAMEWORK.md          ‚Üê Update in Cycles 1-2
‚îÇ   ‚îú‚îÄ‚îÄ I7_RESEARCH_DESIGN.md         ‚Üê Update in Cycle 7
‚îÇ   ‚îú‚îÄ‚îÄ I8_DATA_FLOW.md               ‚Üê Create in Cycle 4
‚îÇ   ‚îú‚îÄ‚îÄ I9_PATTERNS_LESSONS.md        ‚Üê Create in Cycle 5
‚îÇ   ‚îî‚îÄ‚îÄ I10_PRODUCT_CAPABILITIES.md   ‚Üê Create in Cycle 6
‚îú‚îÄ‚îÄ NYX-v2_COMPLETE_APPLICATION_LEARNING.md  ‚Üê Update after each cycle
‚îî‚îÄ‚îÄ _temp_notes/                      ‚Üê Temporary notes (delete after consolidation)
    ‚îú‚îÄ‚îÄ cycle1_notes.md
    ‚îú‚îÄ‚îÄ cycle2_notes.md
    ‚îî‚îÄ‚îÄ ...
```

**Note-Taking Template** (Use for each cycle):
```markdown
# Cycle X: [Name] - Notes

## Files Read
- [ ] File 1: [path] - [key takeaway]
- [ ] File 2: [path] - [key takeaway]

## Key Learnings
### What
- [Learning 1]

### How
- [Learning 2]

### Why
- [Learning 3]

## Connections
- [How this connects to previous cycles]

## Questions
- [Question 1]
- [Question 2]

## Code References
- [File:Line] - [What it does]
```

**Update Checklist** (After each cycle):
- [ ] Update cycle-specific deliverable file
- [ ] Update master learning doc with key findings
- [ ] Cross-reference to previous cycles
- [ ] Document any new gaps or questions
- [ ] Consolidate temporary notes into deliverable
- [ ] Delete temporary notes file

---

## ‚ö†Ô∏è CRITICAL FOCUS AREAS (Pay Super Close Attention)

### **S/P/E Framework (Cycles 1-2)**:
- ‚ö†Ô∏è **Formula Rationale**: Why `0.3*S + 0.4*P + 0.3*E`? Why not equal weights?
- ‚ö†Ô∏è **Calibration**: How does gene-specific calibration work? Why is it needed?
- ‚ö†Ô∏è **Pathway Weights**: Where do gene‚Üípathway weights come from? How validated?
- ‚ö†Ô∏è **Evidence Integration**: How are literature and ClinVar combined? What's the fallback?
- ‚ö†Ô∏è **Confidence V2**: Why different from efficacy formula? What's the rationale?
- ‚ö†Ô∏è **Sporadic Integration**: How does S/P/E work for tumor mutations vs germline?

### **Sporadic Cancer Strategy (Cycle 3)**:
- ‚ö†Ô∏è **85-90% Statistic**: Why does this matter? What's the clinical impact?
- ‚ö†Ô∏è **Paradigm Shift**: What changed from germline-centric to tumor-centric? Why?
- ‚ö†Ô∏è **PARP Rescue**: Why HRD ‚â•42 rescues PARP even if germline negative?
- ‚ö†Ô∏è **IO Boost**: Why TMB ‚â•20 or MSI-H ‚Üí 1.3x boost? What's the evidence?

### **Data Flow (Cycle 4)**:
- ‚ö†Ô∏è **Integration Points**: How does each external service integrate? What's the fallback?
- ‚ö†Ô∏è **Caching Strategy**: What's cached where? What's the TTL? How invalidated?
- ‚ö†Ô∏è **Error Propagation**: How do errors flow? What's the user experience?

### **Development Patterns (Cycle 5)**:
- ‚ö†Ô∏è **"Wet Noodle" Doctrine**: Why is multi-dimensional validation mandatory?
- ‚ö†Ô∏è **Triumvirate Protocol**: Why truncation check before Evo2?
- ‚ö†Ô∏è **Spam-Safety**: How do we prevent excessive API calls? What are the controls?

---

## üéØ SUCCESS CRITERIA

After completing all 10 cycles:
- ‚úÖ **S/P/E Framework**: Fully understood (architecture + code + rationale)
- ‚úÖ **Sporadic Cancer**: Fully understood (strategy + integration + implementation)
- ‚úÖ **Data Flow**: Complete end-to-end understanding (frontend ‚Üí backend ‚Üí AI ‚Üí external)
- ‚úÖ **Development Patterns**: Know how to build things (best practices + anti-patterns)
- ‚úÖ **Product Vision**: Understand what we're building and why
- ‚úÖ **All Connections**: Understand how everything connects (not silos)
- ‚úÖ **Master Learning Doc**: Updated with all findings
- ‚úÖ **All Gaps Closed**: Or documented with clear questions

---

## üöÄ EXECUTION ORDER

**Start Here**: üî• **CYCLE 1 (SC-I2)** - S/P/E Framework Architecture  
**Then**: üî• **CYCLE 2 (SC-I3)** - S/P/E Code Implementation  
**Then**: üî• **CYCLE 3 (SC-I1)** - Sporadic Cancer Strategy  
**Then**: Continue with remaining cycles in priority order

---

## üìö MAIN REFERENCE DOCUMENTS

1. **`NYX-v2_COMPLETE_LEARNING_PLAN.md`** - Main 10-iteration plan
2. **`SPORADIC_CANCER_LEARNING_PLAN.md`** - Sporadic cancer 6-iteration plan
3. **`NYX-v2_COMPLETE_APPLICATION_LEARNING.md`** - Master learning document (update this)
4. **`Iterations/I1-I6_*.md`** - Completed iteration docs (reference these)
5. **`Gap_Analysis/`** - Gap documentation (reference these)

---

## ‚úÖ SUCCESS CRITERIA

After completing all 10 cycles:
- ‚úÖ All main plan iterations complete (I1-I10)
- ‚úÖ All sporadic cancer iterations complete (SC-I1-SC-I6)
- ‚úÖ S/P/E framework fully understood (architecture + code)
- ‚úÖ Master learning document updated with all findings
- ‚úÖ All gaps closed or documented
- ‚úÖ Complete understanding of entire platform

---

**Status**: üìã **PLAN READY** - Reference existing documents, update master learning doc

