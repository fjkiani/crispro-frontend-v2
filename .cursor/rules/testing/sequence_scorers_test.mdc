Modal

crispro
Starter
/

main

Credits Remaining: $2,219.48
Limit hit
Slack Community
Docs
User avatar
Apps
Logs
Secrets
Storage
Notebooks
New

Overview


Deployment History


App Logs

Search functions

EvoService.*
Containers: 3 live
Calls: 0 running

EvoService1B.*
Containers: 2 live
Calls: 0 running

EvoService7B.*
Containers: 2 live
Calls: 0 running
evo-service / App Logs

Shift ‚Üê (A)
Toggle Pause/Play (T)
Shift ‚Üí (D)

1d
Oct 26, 10:15 PM ‚Äì now

Zoom out (Z)
Add filter
Expand logs
Search logs (‚åòK)
Timestamp
Content
Settings
Oct 27  16:03:56.425

==========
== CUDA ==
==========
Oct 27  16:03:56.447

CUDA Version 12.4.0
Oct 27  16:03:56.454

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  16:03:56.461

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  16:03:56.518

Oct 27  16:04:07.454
2025-10-27 20:04:07.447 | INFO     | main:load_model_and_api:707 - üöÄ Loading Evo2 model: evo2_1b_base ...
Oct 27  16:04:18.701
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:11<00:00,  2.80s/it]
Oct 27  16:04:18.704
Found complete file in repo: evo2_1b_base.pt
Oct 27  16:04:19.146
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 110.27it/s]
Oct 27  16:04:20.561
Extra keys in state_dict: {'blocks.17.mixer.dense._extra_state', 'unembed.weight', 'blocks.3.mixer.dense._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.24.mixer.dense._extra_state'}
Oct 27  16:04:20.566
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  16:04:20.847
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  16:04:21.000
2025-10-27 20:04:20.994 | INFO     | main:load_model_and_api:709 - üéâ Evo2 1B model loaded successfully!
Oct 27  16:04:25.138
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  2.00s/it]
Oct 27  16:04:25.189
   POST /score_delta -> 200 OK  (duration: 30.9 s, execution: 4.03 s)
Oct 27  16:07:53.297
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.16it/s]
Oct 27  16:07:53.348
   POST /score_delta -> 200 OK  (duration: 439.2 ms, execution: 373.9 ms)
Oct 27  16:07:55.147
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.16it/s]
Oct 27  16:07:55.199
   POST /score_delta -> 200 OK  (duration: 406.7 ms, execution: 357.3 ms)
Oct 27  16:07:58.262

==========
== CUDA ==
==========
Oct 27  16:07:58.282

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  16:07:58.293

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  16:07:58.341

Oct 27  16:08:06.726
2025-10-27 20:08:06.720 | INFO     | main:load_model_and_api:453 - üöÄ Loading Evo2 model: evo2_7b ...
Oct 27  16:08:58.252
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:51<00:00, 12.87s/it]
Oct 27  16:08:58.253
Found complete file in repo: evo2_7b.pt
Oct 27  16:08:58.772
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 101.82it/s]
Oct 27  16:09:06.585
Extra keys in state_dict: {'blocks.24.mixer.dense._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.27.mixer.mixer.filter.t', 'blocks.17.mixer.attn._extra_state', 'blocks.23.mixer.mixer.filter.t', 'blocks.10.mixer.attn._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.2.mixer.mixer.filter.t', 'blocks.3.mixer.dense._extra_state', 'unembed.weight', 'blocks.9.mixer.mixer.filter.t', 'blocks.6.mixer.mixer.filter.t', 'blocks.3.mixer.attn._extra_state', 'blocks.13.mixer.mixer.filter.t', 'blocks.16.mixer.mixer.filter.t', 'blocks.20.mixer.mixer.filter.t', 'blocks.31.mixer.attn._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.30.mixer.mixer.filter.t'}
Oct 27  16:09:06.603
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  16:09:08.377
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  16:09:11.330
2025-10-27 20:09:11.324 | INFO     | main:load_model_and_api:455 - üéâ Evo2 7B model loaded successfully!
Oct 27  16:09:14.817
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.65s/it]
Oct 27  16:09:14.914
   POST /score_delta -> 200 OK  (duration: 79.2 s, execution: 3.39 s)
Oct 27  16:09:18.705

==========
== CUDA ==
==========
Oct 27  16:09:18.727

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  16:09:18.740

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  16:09:18.791

Oct 27  16:09:33.164
2025-10-27 20:09:33.157 | INFO     | main:load_model_and_api:67 - üöÄ Loading Evo2 model: evo2_40b ...
Oct 27  16:09:33.164
Found existing merged file: /root/.cache/huggingface/evo2_40b.pt
Oct 27  16:09:35.532
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 27.32it/s]
Oct 27  16:10:32.558
Extra keys in state_dict: {'blocks.36.out_filter_dense._extra_state', 'blocks.5.mlp.l1._extra_state', 'blocks.36.mlp.l3._extra_state', 'blocks.46.out_filter_dense._extra_state', 'blocks.27.mlp.l3._extra_state', 'blocks.42.mlp.l2._extra_state', 'blocks.20.mlp.l3._extra_state', 'blocks.38.mlp.l3._extra_state', 'blocks.35.mlp.l1._extra_state', 'blocks.41.mlp.l3._extra_state', 'blocks.39.mlp.l3._extra_state', 'blocks.38.mlp.l2._extra_state', 'blocks.21.out_filter_dense._extra_state', 'blocks.7.mlp.l3._extra_state', 'blocks.44.out_filter_dense._extra_state', 'blocks.31.mlp.l1._extra_state', 'blocks.27.out_filter_dense._extra_state', 'blocks.15.out_filter_dense._extra_state', 'blocks.9.mlp.l1._extra_state', 'blocks.37.mlp.l1._extra_state', 'blocks.46.mlp.l1._extra_state', 'blocks.16.out_filter_dense._extra_state', 'blocks.34.mlp.l1._extra_state', 'blocks.14.mlp.l2._extra_state', 'blocks.8.out_filter_dense._extra_state', 'blocks.47.mlp.l3._extra_state', 'blocks.44.mlp.l3._extra_state', 'blocks.29.mlp.l3._extra_state', 'blocks.16.mlp.l2._extra_state', 'blocks.33.mlp.l2._extra_state', 'blocks.2.mlp.l3._extra_state', 'blocks.3.inner_mha_cls.Wqkv._extra_state', 'blocks.34.out_filter_dense._extra_state', 'blocks.10.mlp.l2._extra_state', 'blocks.6.mlp.l2._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.24.inner_mha_cls.Wqkv._extra_state', 'blocks.19.mlp.l3._extra_state', 'blocks.9.mlp.l3._extra_state', 'blocks.23.mlp.l2._extra_state', 'blocks.4.mlp.l2._extra_state', 'blocks.28.mlp.l1._extra_state', 'blocks.1.mlp.l2._extra_state', 'blocks.17.mlp.l2._extra_state', 'blocks.43.out_filter_dense._extra_state', 'blocks.14.out_filter_dense._extra_state', 'blocks.44.mlp.l1._extra_state', 'blocks.3.mlp.l1._extra_state', 'blocks.25.mlp.l1._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.5.mlp.l2._extra_state', 'blocks.5.mlp.l3._extra_state', 'blocks.8.mlp.l1._extra_state', 'blocks.27.mlp.l2._extra_state', 'blocks.32.mlp.l1._extra_state', 'blocks.38.mlp.l1._extra_state', 'blocks.46.mlp.l2._extra_state', 'blocks.31.mlp.l3._extra_state', 'blocks.40.mlp.l1._extra_state', 'blocks.32.mlp.l3._extra_state', 'blocks.14.mlp.l1._extra_state', 'blocks.35.mlp.l2._extra_state', 'blocks.45.mlp.l3._extra_state', 'blocks.30.mlp.l1._extra_state', 'blocks.17.mlp.l3._extra_state', 'blocks.49.mixer.attn._extra_state', 'blocks.6.mlp.l3._extra_state', 'blocks.33.out_filter_dense._extra_state', 'blocks.33.mlp.l3._extra_state', 'blocks.20.mlp.l1._extra_state', 'blocks.3.mixer.dense._extra_state', 'blocks.47.mlp.l2._extra_state', 'blocks.10.inner_mha_cls.Wqkv._extra_state', 'blocks.1.out_filter_dense._extra_state', 'blocks.14.mlp.l3._extra_state', 'blocks.33.mlp.l1._extra_state', 'blocks.31.mixer.attn._extra_state', 'blocks.22.mlp.l2._extra_state', 'blocks.23.mlp.l1._extra_state', 'blocks.29.mlp.l2._extra_state', 'blocks.3.mlp.l2._extra_state', 'blocks.43.mlp.l3._extra_state', 'blocks.10.mlp.l3._extra_state', 'blocks.20.out_filter_dense._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.47.mlp.l1._extra_state', 'blocks.19.mlp.l1._extra_state', 'blocks.7.mlp.l1._extra_state', 'blocks.17.mlp.l1._extra_state', 'blocks.26.out_filter_dense._extra_state', 'blocks.42.mlp.l1._extra_state', 'blocks.15.mlp.l1._extra_state', 'blocks.31.inner_mha_cls.Wqkv._extra_state', 'blocks.6.out_filter_dense._extra_state', 'unembed.weight', 'blocks.49.mlp.l1._extra_state', 'blocks.2.out_filter_dense._extra_state', 'blocks.10.mlp.l1._extra_state', 'blocks.9.out_filter_dense._extra_state', 'blocks.24.mlp.l1._extra_state', 'blocks.34.mlp.l2._extra_state', 'blocks.28.mlp.l2._extra_state', 'blocks.21.mlp.l1._extra_state', 'blocks.37.mlp.l3._extra_state', 'blocks.40.mlp.l3._extra_state', 'blocks.32.mlp.l2._extra_state', 'blocks.15.mlp.l2._extra_state', 'blocks.12.mlp.l1._extra_state', 'blocks.0.mlp.l1._extra_state', 'blocks.17.mixer.attn._extra_state', 'blocks.29.mlp.l1._extra_state', 'blocks.2.mlp.l1._extra_state', 'blocks.38.out_filter_dense._extra_state', 'blocks.16.mlp.l1._extra_state', 'blocks.18.mlp.l1._extra_state', 'blocks.39.out_filter_dense._extra_state', 'blocks.11.mlp.l1._extra_state', 'blocks.36.mlp.l2._extra_state', 'blocks.39.mlp.l1._extra_state', 'blocks.1.mlp.l3._extra_state', 'blocks.18.mlp.l3._extra_state', 'blocks.11.mlp.l3._extra_state', 'blocks.0.mlp.l2._extra_state', 'blocks.45.out_filter_dense._extra_state', 'blocks.4.mlp.l3._extra_state', 'blocks.7.mlp.l2._extra_state', 'blocks.40.mlp.l2._extra_state', 'blocks.47.out_filter_dense._extra_state', 'blocks.44.mlp.l2._extra_state', 'blocks.35.mixer.attn._extra_state', 'blocks.45.mlp.l1._extra_state', 'blocks.42.inner_mha_cls.Wqkv._extra_state', 'blocks.11.mlp.l2._extra_state', 'blocks.35.mixer.dense._extra_state', 'blocks.43.mlp.l1._extra_state', 'blocks.25.out_filter_dense._extra_state', 'blocks.30.mlp.l2._extra_state', 'blocks.19.mlp.l2._extra_state', 'blocks.12.mlp.l2._extra_state', 'blocks.10.mixer.attn._extra_state', 'blocks.25.mlp.l2._extra_state', 'blocks.3.mlp.l3._extra_state', 'blocks.37.mlp.l2._extra_state', 'blocks.49.mlp.l3._extra_state', 'blocks.22.mlp.l1._extra_state', 'blocks.13.out_filter_dense._extra_state', 'blocks.41.mlp.l1._extra_state', 'blocks.9.mlp.l2._extra_state', 'blocks.49.inner_mha_cls.Wqkv._extra_state', 'blocks.17.inner_mha_cls.Wqkv._extra_state', 'blocks.42.mlp.l3._extra_state', 'blocks.0.out_filter_dense._extra_state', 'blocks.22.out_filter_dense._extra_state', 'blocks.26.mlp.l1._extra_state', 'blocks.28.mlp.l3._extra_state', 'blocks.36.mlp.l1._extra_state', 'blocks.2.mlp.l2._extra_state', 'blocks.4.mlp.l1._extra_state', 'blocks.43.mlp.l2._extra_state', 'blocks.40.out_filter_dense._extra_state', 'blocks.26.mlp.l2._extra_state', 'blocks.32.out_filter_dense._extra_state', 'blocks.16.mlp.l3._extra_state', 'blocks.42.mixer.dense._extra_state', 'blocks.49.mlp.l2._extra_state', 'blocks.49.mixer.dense._extra_state', 'blocks.31.mlp.l2._extra_state', 'blocks.29.out_filter_dense._extra_state', 'blocks.24.mlp.l2._extra_state', 'blocks.8.mlp.l2._extra_state', 'blocks.1.mlp.l1._extra_state', 'blocks.18.out_filter_dense._extra_state', 'blocks.42.mixer.attn._extra_state', 'blocks.41.mlp.l2._extra_state', 'blocks.46.mlp.l3._extra_state', 'blocks.21.mlp.l2._extra_state', 'blocks.23.mlp.l3._extra_state', 'blocks.20.mlp.l2._extra_state', 'blocks.12.mlp.l3._extra_state', 'blocks.25.mlp.l3._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.26.mlp.l3._extra_state', 'blocks.13.mlp.l1._extra_state', 'blocks.30.mlp.l3._extra_state', 'blocks.3.mixer.attn._extra_state', 'blocks.24.mlp.l3._extra_state', 'blocks.34.mlp.l3._extra_state', 'blocks.7.out_filter_dense._extra_state', 'blocks.41.out_filter_dense._extra_state', 'blocks.6.mlp.l1._extra_state', 'blocks.4.out_filter_dense._extra_state', 'blocks.0.mlp.l3._extra_state', 'blocks.30.out_filter_dense._extra_state', 'blocks.28.out_filter_dense._extra_state', 'blocks.13.mlp.l2._extra_state', 'blocks.48.out_filter_dense._extra_state', 'blocks.48.mlp.l2._extra_state', 'blocks.15.mlp.l3._extra_state', 'blocks.45.mlp.l2._extra_state', 'blocks.48.mlp.l1._extra_state', 'blocks.22.mlp.l3._extra_state', 'blocks.8.mlp.l3._extra_state', 'blocks.12.out_filter_dense._extra_state', 'blocks.18.mlp.l2._extra_state', 'blocks.39.mlp.l2._extra_state', 'blocks.35.mlp.l3._extra_state', 'blocks.48.mlp.l3._extra_state', 'blocks.5.out_filter_dense._extra_state', 'blocks.23.out_filter_dense._extra_state', 'blocks.37.out_filter_dense._extra_state', 'blocks.35.inner_mha_cls.Wqkv._extra_state', 'blocks.21.mlp.l3._extra_state', 'blocks.19.out_filter_dense._extra_state', 'blocks.11.out_filter_dense._extra_state', 'blocks.27.mlp.l1._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.13.mlp.l3._extra_state'}
Oct 27  16:10:32.607
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  16:10:43.518
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  16:10:55.108
2025-10-27 20:10:55.102 | INFO     | main:load_model_and_api:69 - üéâ Evo2 model loaded successfully!
Oct 27  16:11:03.898
2025-10-27 20:10:55.264 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08<00:00,  4.31s/it]
2025-10-27 20:11:03.893 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  16:11:03.928
   POST /score_delta -> 200 OK  (duration: 108.6 s, execution: 8.68 s)
Oct 27  16:11:35.214
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.17it/s]
Oct 27  16:11:35.254
   POST /score_delta -> 200 OK  (duration: 428.6 ms, execution: 370.8 ms)
Oct 27  16:11:36.924
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]
Oct 27  16:11:36.991
   POST /score_delta -> 200 OK  (duration: 1.28 s, execution: 1.17 s)
Oct 27  16:11:41.855
2025-10-27 20:11:37.506 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.17s/it]
2025-10-27 20:11:41.849 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  16:11:41.887
   POST /score_delta -> 200 OK  (duration: 4.43 s, execution: 4.37 s)
Oct 27  16:11:46.298
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]
Oct 27  16:11:46.366
   POST /score_delta -> 200 OK  (duration: 1.17 s, execution: 1.11 s)
Oct 27  16:11:47.927
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]
Oct 27  16:11:47.990
   POST /score_delta -> 200 OK  (duration: 1.23 s, execution: 1.12 s)
Oct 27  16:11:49.693
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]
Oct 27  16:11:49.762
   POST /score_delta -> 200 OK  (duration: 1.25 s, execution: 1.15 s)
Oct 27  16:21:22.965

==========
== CUDA ==
==========
Oct 27  16:21:22.986

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  16:21:22.997

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  16:21:23.048

Oct 27  16:21:33.634
2025-10-27 20:21:33.628 | INFO     | main:load_model_and_api:707 - üöÄ Loading Evo2 model: evo2_1b_base ...
Oct 27  16:21:46.619
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:12<00:00,  3.21s/it]
Oct 27  16:21:46.621
Found complete file in repo: evo2_1b_base.pt
Oct 27  16:21:47.093
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 119.74it/s]
Oct 27  16:21:48.572
Extra keys in state_dict: {'blocks.3.mixer.dense._extra_state', 'blocks.17.mixer.dense._extra_state', 'unembed.weight', 'blocks.10.mixer.dense._extra_state', 'blocks.24.mixer.dense._extra_state'}
Oct 27  16:21:48.577
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  16:21:48.863
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  16:21:49.026
2025-10-27 20:21:49.020 | INFO     | main:load_model_and_api:709 - üéâ Evo2 1B model loaded successfully!
Oct 27  16:21:52.988
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.88s/it]
Oct 27  16:21:53.113
   POST /score_delta -> 200 OK  (duration: 32.9 s, execution: 3.87 s)
Oct 27  22:11:20.805

==========
== CUDA ==
==========
Oct 27  22:11:20.913

CUDA Version 12.4.0
Oct 27  22:11:20.955

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:21.001

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:21.182

Oct 27  22:11:21.791

==========
== CUDA ==
==========
Oct 27  22:11:21.804

==========
== CUDA ==
==========
Oct 27  22:11:21.826

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:21.838

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:21.842

CUDA Version 12.4.0
Oct 27  22:11:21.855

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:21.863

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:21.894

Oct 27  22:11:21.956

Oct 27  22:11:22.052

==========
== CUDA ==
==========
Oct 27  22:11:22.073

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:22.085

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:22.135

Oct 27  22:11:22.292

==========
== CUDA ==
==========
Oct 27  22:11:22.325

CUDA Version 12.4.0
Oct 27  22:11:22.333

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:22.339

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:22.453

Oct 27  22:11:22.738

==========
== CUDA ==
==========
Oct 27  22:11:22.762

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:22.773

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:22.829

Oct 27  22:11:22.918

==========
== CUDA ==
==========
Oct 27  22:11:22.939

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:22.952

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:23.015

Oct 27  22:11:31.358
2025-10-28 02:11:31.352 | INFO     | main:load_model_and_api:453 - üöÄ Loading Evo2 model: evo2_7b ...
Oct 27  22:11:33.071
2025-10-28 02:11:33.065 | INFO     | main:load_model_and_api:707 - üöÄ Loading Evo2 model: evo2_1b_base ...
Oct 27  22:11:34.053
Found existing merged file: /root/.cache/huggingface/evo2_40b.pt
Oct 27  22:11:34.053
2025-10-28 02:11:34.045 | INFO     | main:load_model_and_api:67 - üöÄ Loading Evo2 model: evo2_40b ...
Oct 27  22:11:34.425
2025-10-28 02:11:34.419 | INFO     | main:load_model_and_api:67 - üöÄ Loading Evo2 model: evo2_40b ...
Oct 27  22:11:34.426
Found existing merged file: /root/.cache/huggingface/evo2_40b.pt
Oct 27  22:11:34.463
2025-10-28 02:11:34.457 | INFO     | main:load_model_and_api:453 - üöÄ Loading Evo2 model: evo2_7b ...
Oct 27  22:11:35.252
2025-10-28 02:11:35.246 | INFO     | main:load_model_and_api:707 - üöÄ Loading Evo2 model: evo2_1b_base ...
Oct 27  22:11:35.590
Found existing merged file: /root/.cache/huggingface/evo2_40b.pt
Oct 27  22:11:35.591
2025-10-28 02:11:35.584 | INFO     | main:load_model_and_api:67 - üöÄ Loading Evo2 model: evo2_40b ...
Oct 27  22:11:36.013
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 39.07it/s]
Oct 27  22:11:36.518
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:02<00:00, 24.47it/s]
Oct 27  22:11:37.613
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 29.80it/s]
Oct 27  22:11:45.514
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:12<00:00,  3.07s/it]
Oct 27  22:11:45.514
Found complete file in repo: evo2_1b_base.pt
Oct 27  22:11:46.188
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 68.79it/s]
Oct 27  22:11:46.583
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:11<00:00,  2.80s/it]
Oct 27  22:11:46.584
Found complete file in repo: evo2_1b_base.pt
Oct 27  22:11:47.115
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 125.61it/s]
Oct 27  22:11:47.646
Extra keys in state_dict: {'blocks.24.mixer.dense._extra_state', 'unembed.weight', 'blocks.10.mixer.dense._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.3.mixer.dense._extra_state'}
Oct 27  22:11:47.651
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:11:47.943
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:11:48.128
2025-10-28 02:11:48.122 | INFO     | main:load_model_and_api:709 - üéâ Evo2 1B model loaded successfully!
Oct 27  22:11:48.541
Extra keys in state_dict: {'unembed.weight', 'blocks.10.mixer.dense._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.3.mixer.dense._extra_state', 'blocks.17.mixer.dense._extra_state'}
Oct 27  22:11:48.547
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:11:48.834
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:11:48.990
2025-10-28 02:11:48.984 | INFO     | main:load_model_and_api:709 - üéâ Evo2 1B model loaded successfully!
Oct 27  22:11:52.368
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.02s/it]
Oct 27  22:11:52.466
   POST /score_delta -> 200 OK  (duration: 33.6 s, execution: 4.15 s)
Oct 27  22:11:52.844
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.81s/it]
Oct 27  22:11:52.929
   POST /score_delta -> 200 OK  (duration: 34.1 s, execution: 3.77 s)
Oct 27  22:11:54.065
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.31it/s]
Oct 27  22:11:54.152
   POST /score_delta -> 200 OK  (duration: 35.2 s, execution: 1.64 s)
Oct 27  22:11:54.537
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.15it/s]
Oct 27  22:11:54.604
   POST /score_delta -> 200 OK  (duration: 34.9 s, execution: 407.8 ms)
Oct 27  22:11:55.395
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.19s/it]
Oct 27  22:11:55.472
   POST /score_delta -> 200 OK  (duration: 36.4 s, execution: 2.50 s)
Oct 27  22:11:55.648
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.15it/s]
Oct 27  22:11:55.722
   POST /score_delta -> 200 OK  (duration: 485.3 ms, execution: 412.7 ms)
Oct 27  22:11:58.175
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.55it/s]
Oct 27  22:11:58.253
   POST /score_delta -> 200 OK  (duration: 1.11 s, execution: 1.03 s)
Oct 27  22:12:00.008
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.40it/s]
Oct 27  22:12:00.723
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.40it/s]
Oct 27  22:12:00.815
   POST /score_delta -> 200 OK  (duration: 1.79 s, execution: 1.71 s)
Oct 27  22:12:04.299
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.13s/it]
Oct 27  22:12:04.375
   POST /score_delta -> 200 OK  (duration: 2.67 s, execution: 2.58 s)
Oct 27  22:12:22.998
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:51<00:00, 12.87s/it]
Oct 27  22:12:22.999
Found complete file in repo: evo2_7b.pt
Oct 27  22:12:23.283
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:48<00:00, 12.17s/it]
Oct 27  22:12:23.284
Found complete file in repo: evo2_7b.pt
Oct 27  22:12:23.895
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 55.97it/s]
Oct 27  22:12:23.896
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 93.91it/s]
Oct 27  22:12:25.645
Extra keys in state_dict: {'blocks.16.mlp.l1._extra_state', 'blocks.21.mlp.l2._extra_state', 'blocks.49.mixer.dense._extra_state', 'blocks.35.mlp.l1._extra_state', 'blocks.16.out_filter_dense._extra_state', 'blocks.12.out_filter_dense._extra_state', 'blocks.15.out_filter_dense._extra_state', 'blocks.17.inner_mha_cls.Wqkv._extra_state', 'blocks.29.mlp.l3._extra_state', 'blocks.33.mlp.l2._extra_state', 'blocks.3.mlp.l1._extra_state', 'blocks.19.mlp.l1._extra_state', 'blocks.31.mlp.l3._extra_state', 'blocks.21.mlp.l3._extra_state', 'blocks.27.mlp.l3._extra_state', 'blocks.16.mlp.l3._extra_state', 'blocks.49.mlp.l3._extra_state', 'blocks.0.mlp.l2._extra_state', 'blocks.22.out_filter_dense._extra_state', 'blocks.46.out_filter_dense._extra_state', 'blocks.22.mlp.l2._extra_state', 'blocks.34.out_filter_dense._extra_state', 'blocks.38.mlp.l3._extra_state', 'blocks.17.mlp.l2._extra_state', 'blocks.28.mlp.l3._extra_state', 'blocks.15.mlp.l1._extra_state', 'blocks.38.out_filter_dense._extra_state', 'blocks.40.mlp.l3._extra_state', 'blocks.32.mlp.l3._extra_state', 'blocks.9.mlp.l3._extra_state', 'blocks.35.mlp.l2._extra_state', 'blocks.0.mlp.l3._extra_state', 'blocks.20.mlp.l2._extra_state', 'blocks.2.mlp.l2._extra_state', 'blocks.3.mlp.l2._extra_state', 'blocks.31.mlp.l1._extra_state', 'blocks.6.mlp.l1._extra_state', 'blocks.10.mlp.l2._extra_state', 'blocks.39.mlp.l2._extra_state', 'blocks.36.mlp.l1._extra_state', 'blocks.30.mlp.l3._extra_state', 'blocks.6.mlp.l2._extra_state', 'blocks.35.mixer.dense._extra_state', 'blocks.35.inner_mha_cls.Wqkv._extra_state', 'blocks.44.mlp.l3._extra_state', 'blocks.8.out_filter_dense._extra_state', 'blocks.48.mlp.l1._extra_state', 'blocks.4.mlp.l1._extra_state', 'blocks.25.out_filter_dense._extra_state', 'blocks.46.mlp.l1._extra_state', 'blocks.23.mlp.l1._extra_state', 'blocks.9.mlp.l2._extra_state', 'blocks.17.mlp.l3._extra_state', 'blocks.26.mlp.l2._extra_state', 'blocks.42.mlp.l1._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.49.mlp.l2._extra_state', 'blocks.39.mlp.l3._extra_state', 'blocks.33.out_filter_dense._extra_state', 'blocks.14.mlp.l1._extra_state', 'blocks.26.mlp.l3._extra_state', 'blocks.31.mlp.l2._extra_state', 'blocks.48.out_filter_dense._extra_state', 'blocks.30.out_filter_dense._extra_state', 'blocks.28.mlp.l2._extra_state', 'blocks.37.mlp.l1._extra_state', 'blocks.43.mlp.l1._extra_state', 'blocks.29.mlp.l2._extra_state', 'blocks.14.mlp.l2._extra_state', 'blocks.6.out_filter_dense._extra_state', 'blocks.32.mlp.l2._extra_state', 'blocks.47.mlp.l2._extra_state', 'blocks.35.mlp.l3._extra_state', 'blocks.32.out_filter_dense._extra_state', 'blocks.11.mlp.l1._extra_state', 'blocks.8.mlp.l1._extra_state', 'blocks.29.mlp.l1._extra_state', 'blocks.19.mlp.l3._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.22.mlp.l3._extra_state', 'blocks.36.mlp.l2._extra_state', 'blocks.37.out_filter_dense._extra_state', 'blocks.39.mlp.l1._extra_state', 'blocks.44.mlp.l2._extra_state', 'blocks.32.mlp.l1._extra_state', 'blocks.4.mlp.l3._extra_state', 'blocks.11.mlp.l2._extra_state', 'blocks.28.mlp.l1._extra_state', 'blocks.16.mlp.l2._extra_state', 'blocks.24.inner_mha_cls.Wqkv._extra_state', 'blocks.13.out_filter_dense._extra_state', 'blocks.40.mlp.l2._extra_state', 'blocks.44.out_filter_dense._extra_state', 'blocks.42.mlp.l3._extra_state', 'blocks.14.out_filter_dense._extra_state', 'blocks.24.mlp.l2._extra_state', 'blocks.25.mlp.l2._extra_state', 'blocks.8.mlp.l2._extra_state', 'blocks.18.mlp.l2._extra_state', 'blocks.0.out_filter_dense._extra_state', 'blocks.21.mlp.l1._extra_state', 'blocks.3.inner_mha_cls.Wqkv._extra_state', 'blocks.5.mlp.l2._extra_state', 'blocks.12.mlp.l1._extra_state', 'blocks.11.out_filter_dense._extra_state', 'blocks.42.mixer.attn._extra_state', 'blocks.43.mlp.l3._extra_state', 'blocks.28.out_filter_dense._extra_state', 'blocks.17.mlp.l1._extra_state', 'unembed.weight', 'blocks.5.out_filter_dense._extra_state', 'blocks.34.mlp.l1._extra_state', 'blocks.7.mlp.l2._extra_state', 'blocks.2.mlp.l1._extra_state', 'blocks.7.mlp.l1._extra_state', 'blocks.42.mlp.l2._extra_state', 'blocks.47.out_filter_dense._extra_state', 'blocks.21.out_filter_dense._extra_state', 'blocks.7.out_filter_dense._extra_state', 'blocks.25.mlp.l1._extra_state', 'blocks.34.mlp.l3._extra_state', 'blocks.15.mlp.l2._extra_state', 'blocks.47.mlp.l1._extra_state', 'blocks.49.inner_mha_cls.Wqkv._extra_state', 'blocks.23.mlp.l2._extra_state', 'blocks.30.mlp.l2._extra_state', 'blocks.2.out_filter_dense._extra_state', 'blocks.4.out_filter_dense._extra_state', 'blocks.24.mlp.l1._extra_state', 'blocks.43.mlp.l2._extra_state', 'blocks.30.mlp.l1._extra_state', 'blocks.29.out_filter_dense._extra_state', 'blocks.18.mlp.l3._extra_state', 'blocks.24.mlp.l3._extra_state', 'blocks.4.mlp.l2._extra_state', 'blocks.45.mlp.l2._extra_state', 'blocks.41.mlp.l1._extra_state', 'blocks.13.mlp.l1._extra_state', 'blocks.14.mlp.l3._extra_state', 'blocks.19.mlp.l2._extra_state', 'blocks.5.mlp.l1._extra_state', 'blocks.23.mlp.l3._extra_state', 'blocks.25.mlp.l3._extra_state', 'blocks.37.mlp.l3._extra_state', 'blocks.45.out_filter_dense._extra_state', 'blocks.10.mlp.l3._extra_state', 'blocks.43.out_filter_dense._extra_state', 'blocks.20.mlp.l1._extra_state', 'blocks.31.inner_mha_cls.Wqkv._extra_state', 'blocks.44.mlp.l1._extra_state', 'blocks.3.mixer.attn._extra_state', 'blocks.8.mlp.l3._extra_state', 'blocks.20.out_filter_dense._extra_state', 'blocks.1.mlp.l2._extra_state', 'blocks.46.mlp.l2._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.23.out_filter_dense._extra_state', 'blocks.1.out_filter_dense._extra_state', 'blocks.6.mlp.l3._extra_state', 'blocks.45.mlp.l1._extra_state', 'blocks.5.mlp.l3._extra_state', 'blocks.9.out_filter_dense._extra_state', 'blocks.49.mlp.l1._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.19.out_filter_dense._extra_state', 'blocks.13.mlp.l2._extra_state', 'blocks.9.mlp.l1._extra_state', 'blocks.12.mlp.l2._extra_state', 'blocks.42.inner_mha_cls.Wqkv._extra_state', 'blocks.40.mlp.l1._extra_state', 'blocks.1.mlp.l1._extra_state', 'blocks.27.mlp.l2._extra_state', 'blocks.42.mixer.dense._extra_state', 'blocks.2.mlp.l3._extra_state', 'blocks.13.mlp.l3._extra_state', 'blocks.37.mlp.l2._extra_state', 'blocks.34.mlp.l2._extra_state', 'blocks.36.out_filter_dense._extra_state', 'blocks.10.inner_mha_cls.Wqkv._extra_state', 'blocks.45.mlp.l3._extra_state', 'blocks.0.mlp.l1._extra_state', 'blocks.41.mlp.l3._extra_state', 'blocks.36.mlp.l3._extra_state', 'blocks.11.mlp.l3._extra_state', 'blocks.20.mlp.l3._extra_state', 'blocks.26.mlp.l1._extra_state', 'blocks.10.mlp.l1._extra_state', 'blocks.48.mlp.l2._extra_state', 'blocks.1.mlp.l3._extra_state', 'blocks.7.mlp.l3._extra_state', 'blocks.27.out_filter_dense._extra_state', 'blocks.40.out_filter_dense._extra_state', 'blocks.48.mlp.l3._extra_state', 'blocks.22.mlp.l1._extra_state', 'blocks.3.mlp.l3._extra_state', 'blocks.33.mlp.l1._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.18.out_filter_dense._extra_state', 'blocks.33.mlp.l3._extra_state', 'blocks.39.out_filter_dense._extra_state', 'blocks.12.mlp.l3._extra_state', 'blocks.46.mlp.l3._extra_state', 'blocks.41.mlp.l2._extra_state', 'blocks.38.mlp.l2._extra_state', 'blocks.18.mlp.l1._extra_state', 'blocks.38.mlp.l1._extra_state', 'blocks.17.mixer.attn._extra_state', 'blocks.47.mlp.l3._extra_state', 'blocks.15.mlp.l3._extra_state', 'blocks.41.out_filter_dense._extra_state', 'blocks.27.mlp.l1._extra_state', 'blocks.49.mixer.attn._extra_state', 'blocks.3.mixer.dense._extra_state', 'blocks.10.mixer.attn._extra_state', 'blocks.31.mixer.attn._extra_state', 'blocks.35.mixer.attn._extra_state', 'blocks.26.out_filter_dense._extra_state'}
Oct 27  22:12:25.680
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:12:30.990
Extra keys in state_dict: {'blocks.22.out_filter_dense._extra_state', 'blocks.31.mlp.l1._extra_state', 'blocks.6.mlp.l2._extra_state', 'blocks.40.mlp.l1._extra_state', 'blocks.7.mlp.l3._extra_state', 'blocks.33.out_filter_dense._extra_state', 'blocks.48.out_filter_dense._extra_state', 'blocks.29.out_filter_dense._extra_state', 'blocks.7.mlp.l1._extra_state', 'blocks.27.mlp.l1._extra_state', 'blocks.18.mlp.l3._extra_state', 'blocks.42.mixer.dense._extra_state', 'blocks.15.mlp.l1._extra_state', 'blocks.32.out_filter_dense._extra_state', 'blocks.15.mlp.l3._extra_state', 'blocks.49.mlp.l2._extra_state', 'blocks.30.mlp.l2._extra_state', 'blocks.20.mlp.l2._extra_state', 'blocks.3.mixer.dense._extra_state', 'blocks.11.mlp.l2._extra_state', 'blocks.26.mlp.l1._extra_state', 'blocks.0.mlp.l2._extra_state', 'blocks.41.mlp.l2._extra_state', 'blocks.3.mlp.l2._extra_state', 'blocks.19.out_filter_dense._extra_state', 'blocks.44.mlp.l1._extra_state', 'blocks.45.mlp.l3._extra_state', 'blocks.13.mlp.l1._extra_state', 'blocks.28.mlp.l1._extra_state', 'blocks.27.mlp.l2._extra_state', 'blocks.46.out_filter_dense._extra_state', 'blocks.43.out_filter_dense._extra_state', 'blocks.5.mlp.l1._extra_state', 'blocks.9.mlp.l2._extra_state', 'blocks.1.mlp.l2._extra_state', 'blocks.22.mlp.l3._extra_state', 'blocks.23.mlp.l1._extra_state', 'blocks.24.mlp.l2._extra_state', 'blocks.14.mlp.l2._extra_state', 'blocks.10.mixer.attn._extra_state', 'blocks.13.mlp.l3._extra_state', 'blocks.30.out_filter_dense._extra_state', 'blocks.2.mlp.l1._extra_state', 'blocks.4.mlp.l3._extra_state', 'blocks.22.mlp.l1._extra_state', 'blocks.2.mlp.l2._extra_state', 'blocks.32.mlp.l2._extra_state', 'blocks.9.out_filter_dense._extra_state', 'blocks.9.mlp.l3._extra_state', 'blocks.37.mlp.l3._extra_state', 'blocks.43.mlp.l1._extra_state', 'blocks.47.mlp.l2._extra_state', 'blocks.1.mlp.l1._extra_state', 'blocks.35.mlp.l3._extra_state', 'blocks.21.mlp.l1._extra_state', 'blocks.38.mlp.l1._extra_state', 'blocks.0.mlp.l3._extra_state', 'blocks.16.mlp.l2._extra_state', 'blocks.25.mlp.l1._extra_state', 'blocks.42.mixer.attn._extra_state', 'blocks.10.inner_mha_cls.Wqkv._extra_state', 'blocks.48.mlp.l3._extra_state', 'blocks.28.out_filter_dense._extra_state', 'blocks.7.mlp.l2._extra_state', 'blocks.45.out_filter_dense._extra_state', 'blocks.5.mlp.l2._extra_state', 'blocks.42.mlp.l2._extra_state', 'blocks.42.mlp.l1._extra_state', 'blocks.43.mlp.l3._extra_state', 'blocks.21.out_filter_dense._extra_state', 'blocks.24.mlp.l3._extra_state', 'blocks.24.inner_mha_cls.Wqkv._extra_state', 'blocks.32.mlp.l1._extra_state', 'blocks.35.inner_mha_cls.Wqkv._extra_state', 'blocks.46.mlp.l3._extra_state', 'blocks.28.mlp.l3._extra_state', 'blocks.40.out_filter_dense._extra_state', 'blocks.32.mlp.l3._extra_state', 'blocks.4.mlp.l2._extra_state', 'blocks.30.mlp.l1._extra_state', 'blocks.20.mlp.l3._extra_state', 'blocks.16.mlp.l3._extra_state', 'blocks.12.mlp.l3._extra_state', 'blocks.10.mlp.l1._extra_state', 'blocks.33.mlp.l2._extra_state', 'blocks.40.mlp.l2._extra_state', 'blocks.48.mlp.l2._extra_state', 'blocks.25.mlp.l2._extra_state', 'blocks.19.mlp.l1._extra_state', 'blocks.34.mlp.l3._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.31.mixer.attn._extra_state', 'blocks.15.out_filter_dense._extra_state', 'blocks.27.out_filter_dense._extra_state', 'blocks.4.mlp.l1._extra_state', 'blocks.35.mlp.l2._extra_state', 'blocks.31.inner_mha_cls.Wqkv._extra_state', 'blocks.8.out_filter_dense._extra_state', 'blocks.40.mlp.l3._extra_state', 'blocks.36.mlp.l2._extra_state', 'blocks.19.mlp.l3._extra_state', 'blocks.3.mixer.attn._extra_state', 'blocks.49.inner_mha_cls.Wqkv._extra_state', 'blocks.23.out_filter_dense._extra_state', 'blocks.37.mlp.l2._extra_state', 'blocks.18.mlp.l2._extra_state', 'blocks.8.mlp.l2._extra_state', 'blocks.16.out_filter_dense._extra_state', 'blocks.2.out_filter_dense._extra_state', 'blocks.21.mlp.l3._extra_state', 'blocks.14.mlp.l3._extra_state', 'blocks.47.mlp.l1._extra_state', 'blocks.17.mlp.l3._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.46.mlp.l1._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.5.out_filter_dense._extra_state', 'blocks.49.mlp.l3._extra_state', 'blocks.43.mlp.l2._extra_state', 'blocks.4.out_filter_dense._extra_state', 'blocks.29.mlp.l3._extra_state', 'blocks.14.out_filter_dense._extra_state', 'blocks.22.mlp.l2._extra_state', 'blocks.9.mlp.l1._extra_state', 'blocks.26.mlp.l2._extra_state', 'blocks.49.mlp.l1._extra_state', 'blocks.3.mlp.l3._extra_state', 'blocks.48.mlp.l1._extra_state', 'blocks.34.mlp.l1._extra_state', 'blocks.38.out_filter_dense._extra_state', 'blocks.31.mlp.l2._extra_state', 'blocks.6.out_filter_dense._extra_state', 'blocks.29.mlp.l1._extra_state', 'blocks.19.mlp.l2._extra_state', 'blocks.39.mlp.l3._extra_state', 'blocks.28.mlp.l2._extra_state', 'blocks.42.inner_mha_cls.Wqkv._extra_state', 'blocks.44.out_filter_dense._extra_state', 'blocks.11.mlp.l3._extra_state', 'blocks.10.mlp.l3._extra_state', 'blocks.37.mlp.l1._extra_state', 'blocks.35.mixer.dense._extra_state', 'blocks.17.mlp.l2._extra_state', 'blocks.39.mlp.l2._extra_state', 'unembed.weight', 'blocks.35.mlp.l1._extra_state', 'blocks.29.mlp.l2._extra_state', 'blocks.49.mixer.attn._extra_state', 'blocks.18.out_filter_dense._extra_state', 'blocks.6.mlp.l1._extra_state', 'blocks.23.mlp.l2._extra_state', 'blocks.8.mlp.l1._extra_state', 'blocks.20.mlp.l1._extra_state', 'blocks.36.out_filter_dense._extra_state', 'blocks.35.mixer.attn._extra_state', 'blocks.49.mixer.dense._extra_state', 'blocks.39.out_filter_dense._extra_state', 'blocks.16.mlp.l1._extra_state', 'blocks.5.mlp.l3._extra_state', 'blocks.12.out_filter_dense._extra_state', 'blocks.11.mlp.l1._extra_state', 'blocks.23.mlp.l3._extra_state', 'blocks.47.mlp.l3._extra_state', 'blocks.3.mlp.l1._extra_state', 'blocks.39.mlp.l1._extra_state', 'blocks.36.mlp.l1._extra_state', 'blocks.21.mlp.l2._extra_state', 'blocks.2.mlp.l3._extra_state', 'blocks.41.mlp.l1._extra_state', 'blocks.6.mlp.l3._extra_state', 'blocks.17.inner_mha_cls.Wqkv._extra_state', 'blocks.36.mlp.l3._extra_state', 'blocks.14.mlp.l1._extra_state', 'blocks.34.out_filter_dense._extra_state', 'blocks.38.mlp.l2._extra_state', 'blocks.1.out_filter_dense._extra_state', 'blocks.47.out_filter_dense._extra_state', 'blocks.45.mlp.l2._extra_state', 'blocks.15.mlp.l2._extra_state', 'blocks.10.mlp.l2._extra_state', 'blocks.17.mlp.l1._extra_state', 'blocks.46.mlp.l2._extra_state', 'blocks.0.out_filter_dense._extra_state', 'blocks.24.mlp.l1._extra_state', 'blocks.42.mlp.l3._extra_state', 'blocks.13.mlp.l2._extra_state', 'blocks.34.mlp.l2._extra_state', 'blocks.33.mlp.l3._extra_state', 'blocks.27.mlp.l3._extra_state', 'blocks.31.mlp.l3._extra_state', 'blocks.12.mlp.l1._extra_state', 'blocks.0.mlp.l1._extra_state', 'blocks.44.mlp.l3._extra_state', 'blocks.11.out_filter_dense._extra_state', 'blocks.26.out_filter_dense._extra_state', 'blocks.20.out_filter_dense._extra_state', 'blocks.45.mlp.l1._extra_state', 'blocks.1.mlp.l3._extra_state', 'blocks.33.mlp.l1._extra_state', 'blocks.30.mlp.l3._extra_state', 'blocks.37.out_filter_dense._extra_state', 'blocks.41.mlp.l3._extra_state', 'blocks.3.inner_mha_cls.Wqkv._extra_state', 'blocks.8.mlp.l3._extra_state', 'blocks.41.out_filter_dense._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.18.mlp.l1._extra_state', 'blocks.7.out_filter_dense._extra_state', 'blocks.38.mlp.l3._extra_state', 'blocks.12.mlp.l2._extra_state', 'blocks.13.out_filter_dense._extra_state', 'blocks.17.mixer.attn._extra_state', 'blocks.25.mlp.l3._extra_state', 'blocks.44.mlp.l2._extra_state', 'blocks.26.mlp.l3._extra_state', 'blocks.25.out_filter_dense._extra_state'}
Oct 27  22:12:31.044
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:12:32.067
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:12:32.701
Extra keys in state_dict: {'blocks.3.mlp.l3._extra_state', 'blocks.37.mlp.l3._extra_state', 'blocks.36.mlp.l1._extra_state', 'blocks.20.out_filter_dense._extra_state', 'blocks.44.out_filter_dense._extra_state', 'blocks.13.out_filter_dense._extra_state', 'blocks.5.mlp.l3._extra_state', 'blocks.4.mlp.l1._extra_state', 'blocks.32.out_filter_dense._extra_state', 'blocks.16.mlp.l1._extra_state', 'blocks.9.mlp.l3._extra_state', 'blocks.2.mlp.l3._extra_state', 'blocks.31.mixer.attn._extra_state', 'blocks.23.out_filter_dense._extra_state', 'blocks.34.mlp.l2._extra_state', 'blocks.21.out_filter_dense._extra_state', 'blocks.45.mlp.l2._extra_state', 'blocks.3.inner_mha_cls.Wqkv._extra_state', 'blocks.14.mlp.l3._extra_state', 'blocks.35.mlp.l1._extra_state', 'blocks.24.mlp.l1._extra_state', 'blocks.26.out_filter_dense._extra_state', 'blocks.25.mlp.l2._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.32.mlp.l1._extra_state', 'blocks.30.mlp.l3._extra_state', 'blocks.1.mlp.l2._extra_state', 'blocks.12.mlp.l3._extra_state', 'blocks.7.out_filter_dense._extra_state', 'blocks.8.mlp.l3._extra_state', 'blocks.48.mlp.l2._extra_state', 'blocks.3.mixer.attn._extra_state', 'blocks.7.mlp.l1._extra_state', 'blocks.49.mlp.l3._extra_state', 'blocks.19.mlp.l1._extra_state', 'blocks.49.inner_mha_cls.Wqkv._extra_state', 'blocks.31.mlp.l1._extra_state', 'blocks.32.mlp.l2._extra_state', 'blocks.37.out_filter_dense._extra_state', 'blocks.41.mlp.l3._extra_state', 'blocks.43.out_filter_dense._extra_state', 'blocks.49.mlp.l1._extra_state', 'blocks.44.mlp.l3._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.6.mlp.l3._extra_state', 'blocks.43.mlp.l3._extra_state', 'blocks.48.mlp.l1._extra_state', 'blocks.26.mlp.l1._extra_state', 'blocks.27.mlp.l1._extra_state', 'blocks.36.mlp.l2._extra_state', 'blocks.7.mlp.l2._extra_state', 'blocks.4.mlp.l3._extra_state', 'blocks.27.mlp.l2._extra_state', 'blocks.38.out_filter_dense._extra_state', 'blocks.9.mlp.l2._extra_state', 'blocks.25.mlp.l1._extra_state', 'blocks.0.out_filter_dense._extra_state', 'blocks.1.mlp.l3._extra_state', 'blocks.15.out_filter_dense._extra_state', 'blocks.33.out_filter_dense._extra_state', 'blocks.25.out_filter_dense._extra_state', 'blocks.18.out_filter_dense._extra_state', 'blocks.30.mlp.l2._extra_state', 'blocks.29.out_filter_dense._extra_state', 'blocks.19.mlp.l3._extra_state', 'blocks.0.mlp.l1._extra_state', 'blocks.47.out_filter_dense._extra_state', 'blocks.48.out_filter_dense._extra_state', 'blocks.16.mlp.l3._extra_state', 'blocks.11.mlp.l3._extra_state', 'blocks.18.mlp.l1._extra_state', 'blocks.43.mlp.l1._extra_state', 'blocks.36.mlp.l3._extra_state', 'blocks.14.out_filter_dense._extra_state', 'blocks.27.out_filter_dense._extra_state', 'blocks.0.mlp.l2._extra_state', 'blocks.3.mixer.dense._extra_state', 'blocks.10.inner_mha_cls.Wqkv._extra_state', 'blocks.44.mlp.l1._extra_state', 'blocks.2.out_filter_dense._extra_state', 'blocks.16.out_filter_dense._extra_state', 'blocks.35.mlp.l3._extra_state', 'blocks.6.mlp.l2._extra_state', 'blocks.42.mixer.dense._extra_state', 'blocks.26.mlp.l2._extra_state', 'blocks.7.mlp.l3._extra_state', 'blocks.38.mlp.l2._extra_state', 'blocks.19.mlp.l2._extra_state', 'unembed.weight', 'blocks.14.mlp.l1._extra_state', 'blocks.11.mlp.l2._extra_state', 'blocks.41.out_filter_dense._extra_state', 'blocks.22.mlp.l3._extra_state', 'blocks.22.out_filter_dense._extra_state', 'blocks.9.out_filter_dense._extra_state', 'blocks.45.mlp.l1._extra_state', 'blocks.34.out_filter_dense._extra_state', 'blocks.42.mlp.l1._extra_state', 'blocks.44.mlp.l2._extra_state', 'blocks.30.mlp.l1._extra_state', 'blocks.29.mlp.l2._extra_state', 'blocks.23.mlp.l1._extra_state', 'blocks.30.out_filter_dense._extra_state', 'blocks.0.mlp.l3._extra_state', 'blocks.31.mlp.l3._extra_state', 'blocks.15.mlp.l3._extra_state', 'blocks.15.mlp.l2._extra_state', 'blocks.38.mlp.l3._extra_state', 'blocks.11.mlp.l1._extra_state', 'blocks.2.mlp.l2._extra_state', 'blocks.4.out_filter_dense._extra_state', 'blocks.39.out_filter_dense._extra_state', 'blocks.16.mlp.l2._extra_state', 'blocks.2.mlp.l1._extra_state', 'blocks.39.mlp.l1._extra_state', 'blocks.1.out_filter_dense._extra_state', 'blocks.46.mlp.l2._extra_state', 'blocks.9.mlp.l1._extra_state', 'blocks.12.mlp.l1._extra_state', 'blocks.8.mlp.l1._extra_state', 'blocks.40.mlp.l1._extra_state', 'blocks.12.mlp.l2._extra_state', 'blocks.38.mlp.l1._extra_state', 'blocks.40.mlp.l2._extra_state', 'blocks.49.mixer.dense._extra_state', 'blocks.20.mlp.l2._extra_state', 'blocks.32.mlp.l3._extra_state', 'blocks.17.inner_mha_cls.Wqkv._extra_state', 'blocks.29.mlp.l1._extra_state', 'blocks.14.mlp.l2._extra_state', 'blocks.23.mlp.l3._extra_state', 'blocks.10.mlp.l3._extra_state', 'blocks.35.mixer.attn._extra_state', 'blocks.28.out_filter_dense._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.35.mlp.l2._extra_state', 'blocks.8.mlp.l2._extra_state', 'blocks.19.out_filter_dense._extra_state', 'blocks.49.mlp.l2._extra_state', 'blocks.1.mlp.l1._extra_state', 'blocks.25.mlp.l3._extra_state', 'blocks.43.mlp.l2._extra_state', 'blocks.6.mlp.l1._extra_state', 'blocks.17.mlp.l1._extra_state', 'blocks.17.mixer.attn._extra_state', 'blocks.13.mlp.l1._extra_state', 'blocks.18.mlp.l3._extra_state', 'blocks.21.mlp.l1._extra_state', 'blocks.24.mlp.l3._extra_state', 'blocks.42.inner_mha_cls.Wqkv._extra_state', 'blocks.20.mlp.l1._extra_state', 'blocks.37.mlp.l1._extra_state', 'blocks.39.mlp.l3._extra_state', 'blocks.35.mixer.dense._extra_state', 'blocks.5.out_filter_dense._extra_state', 'blocks.29.mlp.l3._extra_state', 'blocks.47.mlp.l3._extra_state', 'blocks.10.mlp.l2._extra_state', 'blocks.26.mlp.l3._extra_state', 'blocks.31.mlp.l2._extra_state', 'blocks.22.mlp.l2._extra_state', 'blocks.4.mlp.l2._extra_state', 'blocks.11.out_filter_dense._extra_state', 'blocks.45.mlp.l3._extra_state', 'blocks.36.out_filter_dense._extra_state', 'blocks.46.mlp.l3._extra_state', 'blocks.24.inner_mha_cls.Wqkv._extra_state', 'blocks.20.mlp.l3._extra_state', 'blocks.12.out_filter_dense._extra_state', 'blocks.28.mlp.l2._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.21.mlp.l3._extra_state', 'blocks.48.mlp.l3._extra_state', 'blocks.45.out_filter_dense._extra_state', 'blocks.21.mlp.l2._extra_state', 'blocks.41.mlp.l1._extra_state', 'blocks.31.inner_mha_cls.Wqkv._extra_state', 'blocks.3.mlp.l2._extra_state', 'blocks.28.mlp.l3._extra_state', 'blocks.28.mlp.l1._extra_state', 'blocks.5.mlp.l2._extra_state', 'blocks.33.mlp.l3._extra_state', 'blocks.17.mlp.l2._extra_state', 'blocks.23.mlp.l2._extra_state', 'blocks.47.mlp.l2._extra_state', 'blocks.35.inner_mha_cls.Wqkv._extra_state', 'blocks.17.mlp.l3._extra_state', 'blocks.6.out_filter_dense._extra_state', 'blocks.8.out_filter_dense._extra_state', 'blocks.34.mlp.l1._extra_state', 'blocks.47.mlp.l1._extra_state', 'blocks.5.mlp.l1._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.10.mlp.l1._extra_state', 'blocks.46.out_filter_dense._extra_state', 'blocks.10.mixer.attn._extra_state', 'blocks.18.mlp.l2._extra_state', 'blocks.39.mlp.l2._extra_state', 'blocks.40.out_filter_dense._extra_state', 'blocks.34.mlp.l3._extra_state', 'blocks.33.mlp.l1._extra_state', 'blocks.42.mlp.l3._extra_state', 'blocks.41.mlp.l2._extra_state', 'blocks.37.mlp.l2._extra_state', 'blocks.27.mlp.l3._extra_state', 'blocks.46.mlp.l1._extra_state', 'blocks.49.mixer.attn._extra_state', 'blocks.13.mlp.l3._extra_state', 'blocks.15.mlp.l1._extra_state', 'blocks.33.mlp.l2._extra_state', 'blocks.42.mixer.attn._extra_state', 'blocks.42.mlp.l2._extra_state', 'blocks.3.mlp.l1._extra_state', 'blocks.40.mlp.l3._extra_state', 'blocks.24.mlp.l2._extra_state', 'blocks.22.mlp.l1._extra_state', 'blocks.13.mlp.l2._extra_state'}
Oct 27  22:12:32.747
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:12:33.048
Extra keys in state_dict: {'blocks.27.mixer.mixer.filter.t', 'blocks.17.mixer.dense._extra_state', 'blocks.2.mixer.mixer.filter.t', 'unembed.weight', 'blocks.10.mixer.attn._extra_state', 'blocks.13.mixer.mixer.filter.t', 'blocks.17.mixer.attn._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.30.mixer.mixer.filter.t', 'blocks.23.mixer.mixer.filter.t', 'blocks.31.mixer.attn._extra_state', 'blocks.3.mixer.attn._extra_state', 'blocks.20.mixer.mixer.filter.t', 'blocks.3.mixer.dense._extra_state', 'blocks.16.mixer.mixer.filter.t', 'blocks.6.mixer.mixer.filter.t', 'blocks.10.mixer.dense._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.9.mixer.mixer.filter.t'}
Oct 27  22:12:33.062
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:12:33.794
Extra keys in state_dict: {'blocks.10.mixer.attn._extra_state', 'blocks.23.mixer.mixer.filter.t', 'blocks.13.mixer.mixer.filter.t', 'blocks.31.mixer.attn._extra_state', 'unembed.weight', 'blocks.31.mixer.dense._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.6.mixer.mixer.filter.t', 'blocks.3.mixer.dense._extra_state', 'blocks.16.mixer.mixer.filter.t', 'blocks.30.mixer.mixer.filter.t', 'blocks.3.mixer.attn._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.9.mixer.mixer.filter.t', 'blocks.17.mixer.dense._extra_state', 'blocks.20.mixer.mixer.filter.t', 'blocks.24.mixer.dense._extra_state', 'blocks.2.mixer.mixer.filter.t', 'blocks.27.mixer.mixer.filter.t', 'blocks.17.mixer.attn._extra_state'}
Oct 27  22:12:33.810
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:12:34.690
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:12:35.654
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:12:37.563
2025-10-28 02:12:37.557 | INFO     | main:load_model_and_api:455 - üéâ Evo2 7B model loaded successfully!
Oct 27  22:12:38.447
2025-10-28 02:12:38.440 | INFO     | main:load_model_and_api:455 - üéâ Evo2 7B model loaded successfully!
Oct 27  22:12:40.811
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:12:41.651
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.89s/it]
Oct 27  22:12:41.750
   POST /score_delta -> 200 OK  (duration: 83.2 s, execution: 3.98 s)
Oct 27  22:12:41.838
2025-10-28 02:12:41.831 | INFO     | main:load_model_and_api:69 - üéâ Evo2 model loaded successfully!
Oct 27  22:12:41.969
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:12:42.824
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:12:42.862
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]
Oct 27  22:12:42.903
   POST /score_delta -> 200 OK  (duration: 84.3 s, execution: 1.11 s)
Oct 27  22:12:42.940
   POST /score_delta -> 200 OK  (duration: 84.3 s, execution: 4.32 s)
Oct 27  22:12:43.990
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:12:44.079
   POST /score_delta -> 200 OK  (duration: 85.5 s, execution: 1.12 s)
Oct 27  22:12:44.978
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.02it/s]
Oct 27  22:12:45.066
   POST /score_delta -> 200 OK  (duration: 86.4 s, execution: 2.07 s)
Oct 27  22:12:50.059
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.45s/it]
Oct 27  22:12:50.127
   POST /score_delta -> 200 OK  (duration: 91.1 s, execution: 5.02 s)
Oct 27  22:12:50.311
2025-10-28 02:12:41.976 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08<00:00,  4.16s/it]
2025-10-28 02:12:50.305 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:12:50.347
   POST /score_delta -> 200 OK  (duration: 91.9 s, execution: 8.37 s)
Oct 27  22:12:51.227
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:12:51.304
   POST /score_delta -> 200 OK  (duration: 46.3 s, execution: 1.11 s)
Oct 27  22:12:51.791
2025-10-28 02:12:51.785 | INFO     | main:load_model_and_api:69 - üéâ Evo2 model loaded successfully!
Oct 27  22:12:51.932
2025-10-28 02:12:51.926 | INFO     | main:load_model_and_api:69 - üéâ Evo2 model loaded successfully!
Oct 27  22:12:52.028
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.93s/it]
Oct 27  22:12:52.107
   POST /score_delta -> 200 OK  (duration: 93.2 s, execution: 7.98 s)
Oct 27  22:12:52.420
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:12:52.498
   POST /score_delta -> 200 OK  (duration: 34.1 s, execution: 1.14 s)
Oct 27  22:12:53.624
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:12:53.702
   POST /score_delta -> 200 OK  (duration: 1.23 s, execution: 1.11 s)
Oct 27  22:12:56.393
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.07it/s]
Oct 27  22:12:56.487
   POST /score_delta -> 200 OK  (duration: 2.15 s, execution: 2.04 s)
Oct 27  22:12:59.258
2025-10-28 02:12:50.362 | INFO     | main:score_delta:97 - /score_delta called | ref_len=16385 alt_len=16385
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08<00:00,  4.44s/it]
2025-10-28 02:12:59.252 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:12:59.289
   POST /score_delta -> 200 OK  (duration: 100.8 s, execution: 8.92 s)
Oct 27  22:12:59.837
2025-10-28 02:12:52.172 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.83s/it]
2025-10-28 02:12:59.832 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:12:59.903
   POST /score_delta -> 200 OK  (duration: 101.2 s, execution: 7.81 s)
Oct 27  22:13:01.638
2025-10-28 02:12:59.309 | INFO     | main:score_delta:97 - /score_delta called | ref_len=50001 alt_len=50001
  0%|          | 0/2 [00:02<?, ?it/s]
2025-10-28 02:13:01.632 | ERROR    | main:score_delta:112 - Scoring failed: Error during sequence scoring: CUDA out of memory. Tried to allocate 24.42 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.00 GiB is free. Process 1 has 70.17 GiB memory in use. Of the allocated memory 68.90 GiB is allocated by PyTorch, and 602.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Oct 27  22:13:01.669
   POST /score_delta -> 500 Internal Server Error  (duration: 102.6 s, execution: 2.35 s)
Oct 27  22:13:01.969
2025-10-28 02:13:01.963 | INFO     | main:score_variant_exon:278 - /score_variant_exon called | 7:140753336 T>A flank=25000
Oct 27  22:13:02.097
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.35s/it]
Oct 27  22:13:02.186
   POST /score_delta -> 200 OK  (duration: 4.99 s, execution: 4.88 s)
Oct 27  22:13:03.311
   POST /score_variant_exon -> 400 Bad Request  (duration: 1.44 s, execution: 1.38 s)
Oct 27  22:13:06.788
2025-10-28 02:13:04.374 | INFO     | main:score_delta:97 - /score_delta called | ref_len=50001 alt_len=50001
  0%|          | 0/2 [00:02<?, ?it/s]
2025-10-28 02:13:06.781 | ERROR    | main:score_delta:112 - Scoring failed: Error during sequence scoring: CUDA out of memory. Tried to allocate 24.42 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.02 GiB is free. Process 1 has 70.15 GiB memory in use. Of the allocated memory 68.90 GiB is allocated by PyTorch, and 582.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Oct 27  22:13:06.842
   POST /score_delta -> 500 Internal Server Error  (duration: 2.68 s, execution: 2.63 s)
Oct 27  22:13:11.071
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.83s/it]
Oct 27  22:13:11.144
   POST /score_delta -> 200 OK  (duration: 7.98 s, execution: 7.91 s)
Oct 27  22:13:16.157
2025-10-28 02:12:52.065 | INFO     | main:score_delta:97 - /score_delta called | ref_len=32769 alt_len=32769
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:24<00:00, 12.04s/it]
2025-10-28 02:13:16.151 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:13:16.235
   POST /score_delta -> 200 OK  (duration: 117.7 s, execution: 24.3 s)
Oct 27  22:13:16.307
2025-10-28 02:13:11.905 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.20s/it]
2025-10-28 02:13:16.301 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:13:16.346
   POST /score_delta -> 200 OK  (duration: 4.50 s, execution: 4.44 s)
Oct 27  22:13:21.493
2025-10-28 02:13:17.084 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.20s/it]
2025-10-28 02:13:21.488 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:13:21.561
   POST /score_delta -> 200 OK  (duration: 4.56 s, execution: 4.47 s)
Oct 27  22:13:31.056
2025-10-28 02:13:22.729 | INFO     | main:score_delta:97 - /score_delta called | ref_len=16385 alt_len=16385
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08<00:00,  4.16s/it]
2025-10-28 02:13:31.050 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:13:31.131
   POST /score_delta -> 200 OK  (duration: 8.53 s, execution: 8.47 s)
Oct 27  22:13:33.695
2025-10-28 02:13:32.361 | INFO     | main:score_delta:97 - /score_delta called | ref_len=32769 alt_len=32769
  0%|          | 0/2 [00:01<?, ?it/s]
2025-10-28 02:13:33.689 | ERROR    | main:score_delta:112 - Scoring failed: Error during sequence scoring: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.39 GiB is free. Process 1 has 65.78 GiB memory in use. Of the allocated memory 64.48 GiB is allocated by PyTorch, and 629.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Oct 27  22:13:33.730
   POST /score_delta -> 500 Internal Server Error  (duration: 1.66 s, execution: 1.58 s)
Oct 27  22:13:33.994
2025-10-28 02:13:33.988 | INFO     | main:score_variant_exon:278 - /score_variant_exon called | 7:140753336 T>A flank=16384
Oct 27  22:13:34.654
   POST /score_variant_exon -> 400 Bad Request  (duration: 769.4 ms, execution: 670.8 ms)
Oct 27  22:13:58.085
2025-10-28 02:13:36.527 | INFO     | main:score_delta:97 - /score_delta called | ref_len=32769 alt_len=32769
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:21<00:00, 10.78s/it]
2025-10-28 02:13:58.080 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:13:58.159
   POST /score_delta -> 200 OK  (duration: 21.8 s, execution: 21.8 s)
Oct 27  22:14:00.813
2025-10-28 02:13:59.359 | INFO     | main:score_delta:97 - /score_delta called | ref_len=50001 alt_len=50001
  0%|          | 0/2 [00:01<?, ?it/s]
2025-10-28 02:14:00.807 | ERROR    | main:score_delta:112 - Scoring failed: Error during sequence scoring: CUDA out of memory. Tried to allocate 15.41 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.75 GiB is free. Process 1 has 69.42 GiB memory in use. Of the allocated memory 68.14 GiB is allocated by PyTorch, and 606.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Oct 27  22:14:00.860
   POST /score_delta -> 500 Internal Server Error  (duration: 1.74 s, execution: 1.69 s)
Oct 27  22:14:05.830
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:14:05.909
   POST /score_delta -> 200 OK  (duration: 1.21 s, execution: 1.12 s)
Oct 27  22:14:09.179
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:14:09.254
   POST /score_delta -> 200 OK  (duration: 1.20 s, execution: 1.12 s)
Oct 27  22:14:11.036
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:14:11.141
   POST /score_delta -> 200 OK  (duration: 1.23 s, execution: 1.15 s)
Streaming
Modal logo
¬© 2025
About
Status
Changelog
Documentation
Slack Community
Pricing
Examples
App Details - crispro | Modal

Log Context
Oct 27, 2025, 22:11:22
Function

Filter by function
EvoService1B.*
Log Type

Filter by source
stdout
Function Call ID
‚Äî
Container ID

Filter by container
ta-01K8M9B35FXCSNYB3E1H6HB5TM

Copy

Full Log
View in context

==========
== CUDA ==
==========
Modal

crispro
Starter
/

main

Credits Remaining: $2,219.48
Limit hit
Slack Community
Docs
User avatar
Apps
Logs
Secrets
Storage
Notebooks
New

Overview


Deployment History


App Logs

Search functions

EvoService.*
Containers: 3 live
Calls: 0 running

EvoService1B.*
Containers: 2 live
Calls: 0 running

EvoService7B.*
Containers: 2 live
Calls: 0 running
evo-service / App Logs

Shift ‚Üê (A)
Toggle Pause/Play (T)
Shift ‚Üí (D)

1d
Oct 26, 10:15 PM ‚Äì now

Zoom out (Z)
Add filter
Expand logs
Search logs (‚åòK)
Timestamp
Content
Settings
Oct 27  16:03:56.425

==========
== CUDA ==
==========
Oct 27  16:03:56.447

CUDA Version 12.4.0
Oct 27  16:03:56.454

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  16:03:56.461

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  16:03:56.518

Oct 27  16:04:07.454
2025-10-27 20:04:07.447 | INFO     | main:load_model_and_api:707 - üöÄ Loading Evo2 model: evo2_1b_base ...
Oct 27  16:04:18.701
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:11<00:00,  2.80s/it]
Oct 27  16:04:18.704
Found complete file in repo: evo2_1b_base.pt
Oct 27  16:04:19.146
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 110.27it/s]
Oct 27  16:04:20.561
Extra keys in state_dict: {'blocks.17.mixer.dense._extra_state', 'unembed.weight', 'blocks.3.mixer.dense._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.24.mixer.dense._extra_state'}
Oct 27  16:04:20.566
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  16:04:20.847
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  16:04:21.000
2025-10-27 20:04:20.994 | INFO     | main:load_model_and_api:709 - üéâ Evo2 1B model loaded successfully!
Oct 27  16:04:25.138
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  2.00s/it]
Oct 27  16:04:25.189
   POST /score_delta -> 200 OK  (duration: 30.9 s, execution: 4.03 s)
Oct 27  16:07:53.297
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.16it/s]
Oct 27  16:07:53.348
   POST /score_delta -> 200 OK  (duration: 439.2 ms, execution: 373.9 ms)
Oct 27  16:07:55.147
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.16it/s]
Oct 27  16:07:55.199
   POST /score_delta -> 200 OK  (duration: 406.7 ms, execution: 357.3 ms)
Oct 27  16:07:58.262

==========
== CUDA ==
==========
Oct 27  16:07:58.282

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  16:07:58.293

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  16:07:58.341

Oct 27  16:08:06.726
2025-10-27 20:08:06.720 | INFO     | main:load_model_and_api:453 - üöÄ Loading Evo2 model: evo2_7b ...
Oct 27  16:08:58.252
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:51<00:00, 12.87s/it]
Oct 27  16:08:58.253
Found complete file in repo: evo2_7b.pt
Oct 27  16:08:58.772
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 101.82it/s]
Oct 27  16:09:06.585
Extra keys in state_dict: {'blocks.24.mixer.dense._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.27.mixer.mixer.filter.t', 'blocks.17.mixer.attn._extra_state', 'blocks.23.mixer.mixer.filter.t', 'blocks.10.mixer.attn._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.2.mixer.mixer.filter.t', 'blocks.3.mixer.dense._extra_state', 'unembed.weight', 'blocks.9.mixer.mixer.filter.t', 'blocks.6.mixer.mixer.filter.t', 'blocks.3.mixer.attn._extra_state', 'blocks.13.mixer.mixer.filter.t', 'blocks.16.mixer.mixer.filter.t', 'blocks.20.mixer.mixer.filter.t', 'blocks.31.mixer.attn._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.30.mixer.mixer.filter.t'}
Oct 27  16:09:06.603
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  16:09:08.377
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  16:09:11.330
2025-10-27 20:09:11.324 | INFO     | main:load_model_and_api:455 - üéâ Evo2 7B model loaded successfully!
Oct 27  16:09:14.817
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.65s/it]
Oct 27  16:09:14.914
   POST /score_delta -> 200 OK  (duration: 79.2 s, execution: 3.39 s)
Oct 27  16:09:18.705

==========
== CUDA ==
==========
Oct 27  16:09:18.727

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  16:09:18.740

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  16:09:18.791

Oct 27  16:09:33.164
2025-10-27 20:09:33.157 | INFO     | main:load_model_and_api:67 - üöÄ Loading Evo2 model: evo2_40b ...
Oct 27  16:09:33.164
Found existing merged file: /root/.cache/huggingface/evo2_40b.pt
Oct 27  16:09:35.532
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 27.32it/s]
Oct 27  16:10:32.558
Extra keys in state_dict: {'blocks.36.out_filter_dense._extra_state', 'blocks.5.mlp.l1._extra_state', 'blocks.36.mlp.l3._extra_state', 'blocks.46.out_filter_dense._extra_state', 'blocks.27.mlp.l3._extra_state', 'blocks.42.mlp.l2._extra_state', 'blocks.20.mlp.l3._extra_state', 'blocks.38.mlp.l3._extra_state', 'blocks.35.mlp.l1._extra_state', 'blocks.41.mlp.l3._extra_state', 'blocks.39.mlp.l3._extra_state', 'blocks.38.mlp.l2._extra_state', 'blocks.21.out_filter_dense._extra_state', 'blocks.7.mlp.l3._extra_state', 'blocks.44.out_filter_dense._extra_state', 'blocks.31.mlp.l1._extra_state', 'blocks.27.out_filter_dense._extra_state', 'blocks.15.out_filter_dense._extra_state', 'blocks.9.mlp.l1._extra_state', 'blocks.37.mlp.l1._extra_state', 'blocks.46.mlp.l1._extra_state', 'blocks.16.out_filter_dense._extra_state', 'blocks.34.mlp.l1._extra_state', 'blocks.14.mlp.l2._extra_state', 'blocks.8.out_filter_dense._extra_state', 'blocks.47.mlp.l3._extra_state', 'blocks.44.mlp.l3._extra_state', 'blocks.29.mlp.l3._extra_state', 'blocks.16.mlp.l2._extra_state', 'blocks.33.mlp.l2._extra_state', 'blocks.2.mlp.l3._extra_state', 'blocks.3.inner_mha_cls.Wqkv._extra_state', 'blocks.34.out_filter_dense._extra_state', 'blocks.10.mlp.l2._extra_state', 'blocks.6.mlp.l2._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.24.inner_mha_cls.Wqkv._extra_state', 'blocks.19.mlp.l3._extra_state', 'blocks.9.mlp.l3._extra_state', 'blocks.23.mlp.l2._extra_state', 'blocks.4.mlp.l2._extra_state', 'blocks.28.mlp.l1._extra_state', 'blocks.1.mlp.l2._extra_state', 'blocks.17.mlp.l2._extra_state', 'blocks.43.out_filter_dense._extra_state', 'blocks.14.out_filter_dense._extra_state', 'blocks.44.mlp.l1._extra_state', 'blocks.3.mlp.l1._extra_state', 'blocks.25.mlp.l1._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.5.mlp.l2._extra_state', 'blocks.5.mlp.l3._extra_state', 'blocks.8.mlp.l1._extra_state', 'blocks.27.mlp.l2._extra_state', 'blocks.32.mlp.l1._extra_state', 'blocks.38.mlp.l1._extra_state', 'blocks.46.mlp.l2._extra_state', 'blocks.31.mlp.l3._extra_state', 'blocks.40.mlp.l1._extra_state', 'blocks.32.mlp.l3._extra_state', 'blocks.14.mlp.l1._extra_state', 'blocks.35.mlp.l2._extra_state', 'blocks.45.mlp.l3._extra_state', 'blocks.30.mlp.l1._extra_state', 'blocks.17.mlp.l3._extra_state', 'blocks.49.mixer.attn._extra_state', 'blocks.6.mlp.l3._extra_state', 'blocks.33.out_filter_dense._extra_state', 'blocks.33.mlp.l3._extra_state', 'blocks.20.mlp.l1._extra_state', 'blocks.3.mixer.dense._extra_state', 'blocks.47.mlp.l2._extra_state', 'blocks.10.inner_mha_cls.Wqkv._extra_state', 'blocks.1.out_filter_dense._extra_state', 'blocks.14.mlp.l3._extra_state', 'blocks.33.mlp.l1._extra_state', 'blocks.31.mixer.attn._extra_state', 'blocks.22.mlp.l2._extra_state', 'blocks.23.mlp.l1._extra_state', 'blocks.29.mlp.l2._extra_state', 'blocks.3.mlp.l2._extra_state', 'blocks.43.mlp.l3._extra_state', 'blocks.10.mlp.l3._extra_state', 'blocks.20.out_filter_dense._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.47.mlp.l1._extra_state', 'blocks.19.mlp.l1._extra_state', 'blocks.7.mlp.l1._extra_state', 'blocks.17.mlp.l1._extra_state', 'blocks.26.out_filter_dense._extra_state', 'blocks.42.mlp.l1._extra_state', 'blocks.15.mlp.l1._extra_state', 'blocks.31.inner_mha_cls.Wqkv._extra_state', 'blocks.6.out_filter_dense._extra_state', 'unembed.weight', 'blocks.49.mlp.l1._extra_state', 'blocks.2.out_filter_dense._extra_state', 'blocks.10.mlp.l1._extra_state', 'blocks.9.out_filter_dense._extra_state', 'blocks.24.mlp.l1._extra_state', 'blocks.34.mlp.l2._extra_state', 'blocks.28.mlp.l2._extra_state', 'blocks.21.mlp.l1._extra_state', 'blocks.37.mlp.l3._extra_state', 'blocks.40.mlp.l3._extra_state', 'blocks.32.mlp.l2._extra_state', 'blocks.15.mlp.l2._extra_state', 'blocks.12.mlp.l1._extra_state', 'blocks.0.mlp.l1._extra_state', 'blocks.17.mixer.attn._extra_state', 'blocks.29.mlp.l1._extra_state', 'blocks.2.mlp.l1._extra_state', 'blocks.38.out_filter_dense._extra_state', 'blocks.16.mlp.l1._extra_state', 'blocks.18.mlp.l1._extra_state', 'blocks.39.out_filter_dense._extra_state', 'blocks.11.mlp.l1._extra_state', 'blocks.36.mlp.l2._extra_state', 'blocks.39.mlp.l1._extra_state', 'blocks.1.mlp.l3._extra_state', 'blocks.18.mlp.l3._extra_state', 'blocks.11.mlp.l3._extra_state', 'blocks.0.mlp.l2._extra_state', 'blocks.45.out_filter_dense._extra_state', 'blocks.4.mlp.l3._extra_state', 'blocks.7.mlp.l2._extra_state', 'blocks.40.mlp.l2._extra_state', 'blocks.47.out_filter_dense._extra_state', 'blocks.44.mlp.l2._extra_state', 'blocks.35.mixer.attn._extra_state', 'blocks.45.mlp.l1._extra_state', 'blocks.42.inner_mha_cls.Wqkv._extra_state', 'blocks.11.mlp.l2._extra_state', 'blocks.35.mixer.dense._extra_state', 'blocks.43.mlp.l1._extra_state', 'blocks.25.out_filter_dense._extra_state', 'blocks.30.mlp.l2._extra_state', 'blocks.19.mlp.l2._extra_state', 'blocks.12.mlp.l2._extra_state', 'blocks.10.mixer.attn._extra_state', 'blocks.25.mlp.l2._extra_state', 'blocks.3.mlp.l3._extra_state', 'blocks.37.mlp.l2._extra_state', 'blocks.49.mlp.l3._extra_state', 'blocks.22.mlp.l1._extra_state', 'blocks.13.out_filter_dense._extra_state', 'blocks.41.mlp.l1._extra_state', 'blocks.9.mlp.l2._extra_state', 'blocks.49.inner_mha_cls.Wqkv._extra_state', 'blocks.17.inner_mha_cls.Wqkv._extra_state', 'blocks.42.mlp.l3._extra_state', 'blocks.0.out_filter_dense._extra_state', 'blocks.22.out_filter_dense._extra_state', 'blocks.26.mlp.l1._extra_state', 'blocks.28.mlp.l3._extra_state', 'blocks.36.mlp.l1._extra_state', 'blocks.2.mlp.l2._extra_state', 'blocks.4.mlp.l1._extra_state', 'blocks.43.mlp.l2._extra_state', 'blocks.40.out_filter_dense._extra_state', 'blocks.26.mlp.l2._extra_state', 'blocks.32.out_filter_dense._extra_state', 'blocks.16.mlp.l3._extra_state', 'blocks.42.mixer.dense._extra_state', 'blocks.49.mlp.l2._extra_state', 'blocks.49.mixer.dense._extra_state', 'blocks.31.mlp.l2._extra_state', 'blocks.29.out_filter_dense._extra_state', 'blocks.24.mlp.l2._extra_state', 'blocks.8.mlp.l2._extra_state', 'blocks.1.mlp.l1._extra_state', 'blocks.18.out_filter_dense._extra_state', 'blocks.42.mixer.attn._extra_state', 'blocks.41.mlp.l2._extra_state', 'blocks.46.mlp.l3._extra_state', 'blocks.21.mlp.l2._extra_state', 'blocks.23.mlp.l3._extra_state', 'blocks.20.mlp.l2._extra_state', 'blocks.12.mlp.l3._extra_state', 'blocks.25.mlp.l3._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.26.mlp.l3._extra_state', 'blocks.13.mlp.l1._extra_state', 'blocks.30.mlp.l3._extra_state', 'blocks.3.mixer.attn._extra_state', 'blocks.24.mlp.l3._extra_state', 'blocks.34.mlp.l3._extra_state', 'blocks.7.out_filter_dense._extra_state', 'blocks.41.out_filter_dense._extra_state', 'blocks.6.mlp.l1._extra_state', 'blocks.4.out_filter_dense._extra_state', 'blocks.0.mlp.l3._extra_state', 'blocks.30.out_filter_dense._extra_state', 'blocks.28.out_filter_dense._extra_state', 'blocks.13.mlp.l2._extra_state', 'blocks.48.out_filter_dense._extra_state', 'blocks.48.mlp.l2._extra_state', 'blocks.15.mlp.l3._extra_state', 'blocks.45.mlp.l2._extra_state', 'blocks.48.mlp.l1._extra_state', 'blocks.22.mlp.l3._extra_state', 'blocks.8.mlp.l3._extra_state', 'blocks.12.out_filter_dense._extra_state', 'blocks.18.mlp.l2._extra_state', 'blocks.39.mlp.l2._extra_state', 'blocks.35.mlp.l3._extra_state', 'blocks.48.mlp.l3._extra_state', 'blocks.5.out_filter_dense._extra_state', 'blocks.23.out_filter_dense._extra_state', 'blocks.37.out_filter_dense._extra_state', 'blocks.35.inner_mha_cls.Wqkv._extra_state', 'blocks.21.mlp.l3._extra_state', 'blocks.19.out_filter_dense._extra_state', 'blocks.11.out_filter_dense._extra_state', 'blocks.27.mlp.l1._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.13.mlp.l3._extra_state'}
Oct 27  16:10:32.607
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  16:10:43.518
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  16:10:55.108
2025-10-27 20:10:55.102 | INFO     | main:load_model_and_api:69 - üéâ Evo2 model loaded successfully!
Oct 27  16:11:03.898
2025-10-27 20:10:55.264 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08<00:00,  4.31s/it]
2025-10-27 20:11:03.893 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  16:11:03.928
   POST /score_delta -> 200 OK  (duration: 108.6 s, execution: 8.68 s)
Oct 27  16:11:35.214
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.17it/s]
Oct 27  16:11:35.254
   POST /score_delta -> 200 OK  (duration: 428.6 ms, execution: 370.8 ms)
Oct 27  16:11:36.924
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]
Oct 27  16:11:36.991
   POST /score_delta -> 200 OK  (duration: 1.28 s, execution: 1.17 s)
Oct 27  16:11:41.855
2025-10-27 20:11:37.506 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.17s/it]
2025-10-27 20:11:41.849 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  16:11:41.887
   POST /score_delta -> 200 OK  (duration: 4.43 s, execution: 4.37 s)
Oct 27  16:11:46.298
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]
Oct 27  16:11:46.366
   POST /score_delta -> 200 OK  (duration: 1.17 s, execution: 1.11 s)
Oct 27  16:11:47.927
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]
Oct 27  16:11:47.990
   POST /score_delta -> 200 OK  (duration: 1.23 s, execution: 1.12 s)
Oct 27  16:11:49.693
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]
Oct 27  16:11:49.762
   POST /score_delta -> 200 OK  (duration: 1.25 s, execution: 1.15 s)
Oct 27  16:21:22.965

==========
== CUDA ==
==========
Oct 27  16:21:22.986

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  16:21:22.997

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  16:21:23.048

Oct 27  16:21:33.634
2025-10-27 20:21:33.628 | INFO     | main:load_model_and_api:707 - üöÄ Loading Evo2 model: evo2_1b_base ...
Oct 27  16:21:46.619
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:12<00:00,  3.21s/it]
Oct 27  16:21:46.621
Found complete file in repo: evo2_1b_base.pt
Oct 27  16:21:47.093
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 119.74it/s]
Oct 27  16:21:48.572
Extra keys in state_dict: {'blocks.3.mixer.dense._extra_state', 'blocks.17.mixer.dense._extra_state', 'unembed.weight', 'blocks.10.mixer.dense._extra_state', 'blocks.24.mixer.dense._extra_state'}
Oct 27  16:21:48.577
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  16:21:48.863
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  16:21:49.026
2025-10-27 20:21:49.020 | INFO     | main:load_model_and_api:709 - üéâ Evo2 1B model loaded successfully!
Oct 27  16:21:52.988
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.88s/it]
Oct 27  16:21:53.113
   POST /score_delta -> 200 OK  (duration: 32.9 s, execution: 3.87 s)
Oct 27  22:11:20.805

==========
== CUDA ==
==========
Oct 27  22:11:20.913

CUDA Version 12.4.0
Oct 27  22:11:20.955

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:21.001

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:21.182

Oct 27  22:11:21.791

==========
== CUDA ==
==========
Oct 27  22:11:21.804

==========
== CUDA ==
==========
Oct 27  22:11:21.826

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:21.838

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:21.842

CUDA Version 12.4.0
Oct 27  22:11:21.855

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:21.863

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:21.894

Oct 27  22:11:21.956

Oct 27  22:11:22.052

==========
== CUDA ==
==========
Oct 27  22:11:22.073

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:22.085

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:22.135

Oct 27  22:11:22.292

==========
== CUDA ==
==========
Oct 27  22:11:22.325

CUDA Version 12.4.0
Oct 27  22:11:22.333

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:22.339

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:22.453

Oct 27  22:11:22.738

==========
== CUDA ==
==========
Oct 27  22:11:22.762

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:22.773

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:22.829

Oct 27  22:11:22.918

==========
== CUDA ==
==========
Oct 27  22:11:22.939

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Oct 27  22:11:22.952

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Oct 27  22:11:23.015

Oct 27  22:11:31.358
2025-10-28 02:11:31.352 | INFO     | main:load_model_and_api:453 - üöÄ Loading Evo2 model: evo2_7b ...
Oct 27  22:11:33.071
2025-10-28 02:11:33.065 | INFO     | main:load_model_and_api:707 - üöÄ Loading Evo2 model: evo2_1b_base ...
Oct 27  22:11:34.053
Found existing merged file: /root/.cache/huggingface/evo2_40b.pt
Oct 27  22:11:34.053
2025-10-28 02:11:34.045 | INFO     | main:load_model_and_api:67 - üöÄ Loading Evo2 model: evo2_40b ...
Oct 27  22:11:34.425
2025-10-28 02:11:34.419 | INFO     | main:load_model_and_api:67 - üöÄ Loading Evo2 model: evo2_40b ...
Oct 27  22:11:34.426
Found existing merged file: /root/.cache/huggingface/evo2_40b.pt
Oct 27  22:11:34.463
2025-10-28 02:11:34.457 | INFO     | main:load_model_and_api:453 - üöÄ Loading Evo2 model: evo2_7b ...
Oct 27  22:11:35.252
2025-10-28 02:11:35.246 | INFO     | main:load_model_and_api:707 - üöÄ Loading Evo2 model: evo2_1b_base ...
Oct 27  22:11:35.590
Found existing merged file: /root/.cache/huggingface/evo2_40b.pt
Oct 27  22:11:35.591
2025-10-28 02:11:35.584 | INFO     | main:load_model_and_api:67 - üöÄ Loading Evo2 model: evo2_40b ...
Oct 27  22:11:36.013
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 39.07it/s]
Oct 27  22:11:36.518
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:02<00:00, 24.47it/s]
Oct 27  22:11:37.613
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 29.80it/s]
Oct 27  22:11:45.514
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:12<00:00,  3.07s/it]
Oct 27  22:11:45.514
Found complete file in repo: evo2_1b_base.pt
Oct 27  22:11:46.188
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 68.79it/s]
Oct 27  22:11:46.583
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:11<00:00,  2.80s/it]
Oct 27  22:11:46.584
Found complete file in repo: evo2_1b_base.pt
Oct 27  22:11:47.115
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 125.61it/s]
Oct 27  22:11:47.646
Extra keys in state_dict: {'blocks.24.mixer.dense._extra_state', 'unembed.weight', 'blocks.10.mixer.dense._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.3.mixer.dense._extra_state'}
Oct 27  22:11:47.651
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:11:47.943
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:11:48.128
2025-10-28 02:11:48.122 | INFO     | main:load_model_and_api:709 - üéâ Evo2 1B model loaded successfully!
Oct 27  22:11:48.541
Extra keys in state_dict: {'unembed.weight', 'blocks.10.mixer.dense._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.3.mixer.dense._extra_state', 'blocks.17.mixer.dense._extra_state'}
Oct 27  22:11:48.547
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:11:48.834
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:11:48.990
2025-10-28 02:11:48.984 | INFO     | main:load_model_and_api:709 - üéâ Evo2 1B model loaded successfully!
Oct 27  22:11:52.368
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.02s/it]
Oct 27  22:11:52.466
   POST /score_delta -> 200 OK  (duration: 33.6 s, execution: 4.15 s)
Oct 27  22:11:52.844
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.81s/it]
Oct 27  22:11:52.929
   POST /score_delta -> 200 OK  (duration: 34.1 s, execution: 3.77 s)
Oct 27  22:11:54.065
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.31it/s]
Oct 27  22:11:54.152
   POST /score_delta -> 200 OK  (duration: 35.2 s, execution: 1.64 s)
Oct 27  22:11:54.537
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.15it/s]
Oct 27  22:11:54.604
   POST /score_delta -> 200 OK  (duration: 34.9 s, execution: 407.8 ms)
Oct 27  22:11:55.395
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.19s/it]
Oct 27  22:11:55.472
   POST /score_delta -> 200 OK  (duration: 36.4 s, execution: 2.50 s)
Oct 27  22:11:55.648
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.15it/s]
Oct 27  22:11:55.722
   POST /score_delta -> 200 OK  (duration: 485.3 ms, execution: 412.7 ms)
Oct 27  22:11:58.175
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.55it/s]
Oct 27  22:11:58.253
   POST /score_delta -> 200 OK  (duration: 1.11 s, execution: 1.03 s)
Oct 27  22:12:00.008
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.40it/s]
Oct 27  22:12:00.723
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.40it/s]
Oct 27  22:12:00.815
   POST /score_delta -> 200 OK  (duration: 1.79 s, execution: 1.71 s)
Oct 27  22:12:04.299
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.13s/it]
Oct 27  22:12:04.375
   POST /score_delta -> 200 OK  (duration: 2.67 s, execution: 2.58 s)
Oct 27  22:12:22.998
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:51<00:00, 12.87s/it]
Oct 27  22:12:22.999
Found complete file in repo: evo2_7b.pt
Oct 27  22:12:23.283
Fetching 4 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:48<00:00, 12.17s/it]
Oct 27  22:12:23.284
Found complete file in repo: evo2_7b.pt
Oct 27  22:12:23.895
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 55.97it/s]
Oct 27  22:12:23.896
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 93.91it/s]
Oct 27  22:12:25.645
Extra keys in state_dict: {'blocks.16.mlp.l1._extra_state', 'blocks.21.mlp.l2._extra_state', 'blocks.49.mixer.dense._extra_state', 'blocks.35.mlp.l1._extra_state', 'blocks.16.out_filter_dense._extra_state', 'blocks.12.out_filter_dense._extra_state', 'blocks.15.out_filter_dense._extra_state', 'blocks.17.inner_mha_cls.Wqkv._extra_state', 'blocks.29.mlp.l3._extra_state', 'blocks.33.mlp.l2._extra_state', 'blocks.3.mlp.l1._extra_state', 'blocks.19.mlp.l1._extra_state', 'blocks.31.mlp.l3._extra_state', 'blocks.21.mlp.l3._extra_state', 'blocks.27.mlp.l3._extra_state', 'blocks.16.mlp.l3._extra_state', 'blocks.49.mlp.l3._extra_state', 'blocks.0.mlp.l2._extra_state', 'blocks.22.out_filter_dense._extra_state', 'blocks.46.out_filter_dense._extra_state', 'blocks.22.mlp.l2._extra_state', 'blocks.34.out_filter_dense._extra_state', 'blocks.38.mlp.l3._extra_state', 'blocks.17.mlp.l2._extra_state', 'blocks.28.mlp.l3._extra_state', 'blocks.15.mlp.l1._extra_state', 'blocks.38.out_filter_dense._extra_state', 'blocks.40.mlp.l3._extra_state', 'blocks.32.mlp.l3._extra_state', 'blocks.9.mlp.l3._extra_state', 'blocks.35.mlp.l2._extra_state', 'blocks.0.mlp.l3._extra_state', 'blocks.20.mlp.l2._extra_state', 'blocks.2.mlp.l2._extra_state', 'blocks.3.mlp.l2._extra_state', 'blocks.31.mlp.l1._extra_state', 'blocks.6.mlp.l1._extra_state', 'blocks.10.mlp.l2._extra_state', 'blocks.39.mlp.l2._extra_state', 'blocks.36.mlp.l1._extra_state', 'blocks.30.mlp.l3._extra_state', 'blocks.6.mlp.l2._extra_state', 'blocks.35.mixer.dense._extra_state', 'blocks.35.inner_mha_cls.Wqkv._extra_state', 'blocks.44.mlp.l3._extra_state', 'blocks.8.out_filter_dense._extra_state', 'blocks.48.mlp.l1._extra_state', 'blocks.4.mlp.l1._extra_state', 'blocks.25.out_filter_dense._extra_state', 'blocks.46.mlp.l1._extra_state', 'blocks.23.mlp.l1._extra_state', 'blocks.9.mlp.l2._extra_state', 'blocks.17.mlp.l3._extra_state', 'blocks.26.mlp.l2._extra_state', 'blocks.42.mlp.l1._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.49.mlp.l2._extra_state', 'blocks.39.mlp.l3._extra_state', 'blocks.33.out_filter_dense._extra_state', 'blocks.14.mlp.l1._extra_state', 'blocks.26.mlp.l3._extra_state', 'blocks.31.mlp.l2._extra_state', 'blocks.48.out_filter_dense._extra_state', 'blocks.30.out_filter_dense._extra_state', 'blocks.28.mlp.l2._extra_state', 'blocks.37.mlp.l1._extra_state', 'blocks.43.mlp.l1._extra_state', 'blocks.29.mlp.l2._extra_state', 'blocks.14.mlp.l2._extra_state', 'blocks.6.out_filter_dense._extra_state', 'blocks.32.mlp.l2._extra_state', 'blocks.47.mlp.l2._extra_state', 'blocks.35.mlp.l3._extra_state', 'blocks.32.out_filter_dense._extra_state', 'blocks.11.mlp.l1._extra_state', 'blocks.8.mlp.l1._extra_state', 'blocks.29.mlp.l1._extra_state', 'blocks.19.mlp.l3._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.22.mlp.l3._extra_state', 'blocks.36.mlp.l2._extra_state', 'blocks.37.out_filter_dense._extra_state', 'blocks.39.mlp.l1._extra_state', 'blocks.44.mlp.l2._extra_state', 'blocks.32.mlp.l1._extra_state', 'blocks.4.mlp.l3._extra_state', 'blocks.11.mlp.l2._extra_state', 'blocks.28.mlp.l1._extra_state', 'blocks.16.mlp.l2._extra_state', 'blocks.24.inner_mha_cls.Wqkv._extra_state', 'blocks.13.out_filter_dense._extra_state', 'blocks.40.mlp.l2._extra_state', 'blocks.44.out_filter_dense._extra_state', 'blocks.42.mlp.l3._extra_state', 'blocks.14.out_filter_dense._extra_state', 'blocks.24.mlp.l2._extra_state', 'blocks.25.mlp.l2._extra_state', 'blocks.8.mlp.l2._extra_state', 'blocks.18.mlp.l2._extra_state', 'blocks.0.out_filter_dense._extra_state', 'blocks.21.mlp.l1._extra_state', 'blocks.3.inner_mha_cls.Wqkv._extra_state', 'blocks.5.mlp.l2._extra_state', 'blocks.12.mlp.l1._extra_state', 'blocks.11.out_filter_dense._extra_state', 'blocks.42.mixer.attn._extra_state', 'blocks.43.mlp.l3._extra_state', 'blocks.28.out_filter_dense._extra_state', 'blocks.17.mlp.l1._extra_state', 'unembed.weight', 'blocks.5.out_filter_dense._extra_state', 'blocks.34.mlp.l1._extra_state', 'blocks.7.mlp.l2._extra_state', 'blocks.2.mlp.l1._extra_state', 'blocks.7.mlp.l1._extra_state', 'blocks.42.mlp.l2._extra_state', 'blocks.47.out_filter_dense._extra_state', 'blocks.21.out_filter_dense._extra_state', 'blocks.7.out_filter_dense._extra_state', 'blocks.25.mlp.l1._extra_state', 'blocks.34.mlp.l3._extra_state', 'blocks.15.mlp.l2._extra_state', 'blocks.47.mlp.l1._extra_state', 'blocks.49.inner_mha_cls.Wqkv._extra_state', 'blocks.23.mlp.l2._extra_state', 'blocks.30.mlp.l2._extra_state', 'blocks.2.out_filter_dense._extra_state', 'blocks.4.out_filter_dense._extra_state', 'blocks.24.mlp.l1._extra_state', 'blocks.43.mlp.l2._extra_state', 'blocks.30.mlp.l1._extra_state', 'blocks.29.out_filter_dense._extra_state', 'blocks.18.mlp.l3._extra_state', 'blocks.24.mlp.l3._extra_state', 'blocks.4.mlp.l2._extra_state', 'blocks.45.mlp.l2._extra_state', 'blocks.41.mlp.l1._extra_state', 'blocks.13.mlp.l1._extra_state', 'blocks.14.mlp.l3._extra_state', 'blocks.19.mlp.l2._extra_state', 'blocks.5.mlp.l1._extra_state', 'blocks.23.mlp.l3._extra_state', 'blocks.25.mlp.l3._extra_state', 'blocks.37.mlp.l3._extra_state', 'blocks.45.out_filter_dense._extra_state', 'blocks.10.mlp.l3._extra_state', 'blocks.43.out_filter_dense._extra_state', 'blocks.20.mlp.l1._extra_state', 'blocks.31.inner_mha_cls.Wqkv._extra_state', 'blocks.44.mlp.l1._extra_state', 'blocks.3.mixer.attn._extra_state', 'blocks.8.mlp.l3._extra_state', 'blocks.20.out_filter_dense._extra_state', 'blocks.1.mlp.l2._extra_state', 'blocks.46.mlp.l2._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.23.out_filter_dense._extra_state', 'blocks.1.out_filter_dense._extra_state', 'blocks.6.mlp.l3._extra_state', 'blocks.45.mlp.l1._extra_state', 'blocks.5.mlp.l3._extra_state', 'blocks.9.out_filter_dense._extra_state', 'blocks.49.mlp.l1._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.19.out_filter_dense._extra_state', 'blocks.13.mlp.l2._extra_state', 'blocks.9.mlp.l1._extra_state', 'blocks.12.mlp.l2._extra_state', 'blocks.42.inner_mha_cls.Wqkv._extra_state', 'blocks.40.mlp.l1._extra_state', 'blocks.1.mlp.l1._extra_state', 'blocks.27.mlp.l2._extra_state', 'blocks.42.mixer.dense._extra_state', 'blocks.2.mlp.l3._extra_state', 'blocks.13.mlp.l3._extra_state', 'blocks.37.mlp.l2._extra_state', 'blocks.34.mlp.l2._extra_state', 'blocks.36.out_filter_dense._extra_state', 'blocks.10.inner_mha_cls.Wqkv._extra_state', 'blocks.45.mlp.l3._extra_state', 'blocks.0.mlp.l1._extra_state', 'blocks.41.mlp.l3._extra_state', 'blocks.36.mlp.l3._extra_state', 'blocks.11.mlp.l3._extra_state', 'blocks.20.mlp.l3._extra_state', 'blocks.26.mlp.l1._extra_state', 'blocks.10.mlp.l1._extra_state', 'blocks.48.mlp.l2._extra_state', 'blocks.1.mlp.l3._extra_state', 'blocks.7.mlp.l3._extra_state', 'blocks.27.out_filter_dense._extra_state', 'blocks.40.out_filter_dense._extra_state', 'blocks.48.mlp.l3._extra_state', 'blocks.22.mlp.l1._extra_state', 'blocks.3.mlp.l3._extra_state', 'blocks.33.mlp.l1._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.18.out_filter_dense._extra_state', 'blocks.33.mlp.l3._extra_state', 'blocks.39.out_filter_dense._extra_state', 'blocks.12.mlp.l3._extra_state', 'blocks.46.mlp.l3._extra_state', 'blocks.41.mlp.l2._extra_state', 'blocks.38.mlp.l2._extra_state', 'blocks.18.mlp.l1._extra_state', 'blocks.38.mlp.l1._extra_state', 'blocks.17.mixer.attn._extra_state', 'blocks.47.mlp.l3._extra_state', 'blocks.15.mlp.l3._extra_state', 'blocks.41.out_filter_dense._extra_state', 'blocks.27.mlp.l1._extra_state', 'blocks.49.mixer.attn._extra_state', 'blocks.3.mixer.dense._extra_state', 'blocks.10.mixer.attn._extra_state', 'blocks.31.mixer.attn._extra_state', 'blocks.35.mixer.attn._extra_state', 'blocks.26.out_filter_dense._extra_state'}
Oct 27  22:12:25.680
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:12:30.990
Extra keys in state_dict: {'blocks.22.out_filter_dense._extra_state', 'blocks.31.mlp.l1._extra_state', 'blocks.6.mlp.l2._extra_state', 'blocks.40.mlp.l1._extra_state', 'blocks.7.mlp.l3._extra_state', 'blocks.33.out_filter_dense._extra_state', 'blocks.48.out_filter_dense._extra_state', 'blocks.29.out_filter_dense._extra_state', 'blocks.7.mlp.l1._extra_state', 'blocks.27.mlp.l1._extra_state', 'blocks.18.mlp.l3._extra_state', 'blocks.42.mixer.dense._extra_state', 'blocks.15.mlp.l1._extra_state', 'blocks.32.out_filter_dense._extra_state', 'blocks.15.mlp.l3._extra_state', 'blocks.49.mlp.l2._extra_state', 'blocks.30.mlp.l2._extra_state', 'blocks.20.mlp.l2._extra_state', 'blocks.3.mixer.dense._extra_state', 'blocks.11.mlp.l2._extra_state', 'blocks.26.mlp.l1._extra_state', 'blocks.0.mlp.l2._extra_state', 'blocks.41.mlp.l2._extra_state', 'blocks.3.mlp.l2._extra_state', 'blocks.19.out_filter_dense._extra_state', 'blocks.44.mlp.l1._extra_state', 'blocks.45.mlp.l3._extra_state', 'blocks.13.mlp.l1._extra_state', 'blocks.28.mlp.l1._extra_state', 'blocks.27.mlp.l2._extra_state', 'blocks.46.out_filter_dense._extra_state', 'blocks.43.out_filter_dense._extra_state', 'blocks.5.mlp.l1._extra_state', 'blocks.9.mlp.l2._extra_state', 'blocks.1.mlp.l2._extra_state', 'blocks.22.mlp.l3._extra_state', 'blocks.23.mlp.l1._extra_state', 'blocks.24.mlp.l2._extra_state', 'blocks.14.mlp.l2._extra_state', 'blocks.10.mixer.attn._extra_state', 'blocks.13.mlp.l3._extra_state', 'blocks.30.out_filter_dense._extra_state', 'blocks.2.mlp.l1._extra_state', 'blocks.4.mlp.l3._extra_state', 'blocks.22.mlp.l1._extra_state', 'blocks.2.mlp.l2._extra_state', 'blocks.32.mlp.l2._extra_state', 'blocks.9.out_filter_dense._extra_state', 'blocks.9.mlp.l3._extra_state', 'blocks.37.mlp.l3._extra_state', 'blocks.43.mlp.l1._extra_state', 'blocks.47.mlp.l2._extra_state', 'blocks.1.mlp.l1._extra_state', 'blocks.35.mlp.l3._extra_state', 'blocks.21.mlp.l1._extra_state', 'blocks.38.mlp.l1._extra_state', 'blocks.0.mlp.l3._extra_state', 'blocks.16.mlp.l2._extra_state', 'blocks.25.mlp.l1._extra_state', 'blocks.42.mixer.attn._extra_state', 'blocks.10.inner_mha_cls.Wqkv._extra_state', 'blocks.48.mlp.l3._extra_state', 'blocks.28.out_filter_dense._extra_state', 'blocks.7.mlp.l2._extra_state', 'blocks.45.out_filter_dense._extra_state', 'blocks.5.mlp.l2._extra_state', 'blocks.42.mlp.l2._extra_state', 'blocks.42.mlp.l1._extra_state', 'blocks.43.mlp.l3._extra_state', 'blocks.21.out_filter_dense._extra_state', 'blocks.24.mlp.l3._extra_state', 'blocks.24.inner_mha_cls.Wqkv._extra_state', 'blocks.32.mlp.l1._extra_state', 'blocks.35.inner_mha_cls.Wqkv._extra_state', 'blocks.46.mlp.l3._extra_state', 'blocks.28.mlp.l3._extra_state', 'blocks.40.out_filter_dense._extra_state', 'blocks.32.mlp.l3._extra_state', 'blocks.4.mlp.l2._extra_state', 'blocks.30.mlp.l1._extra_state', 'blocks.20.mlp.l3._extra_state', 'blocks.16.mlp.l3._extra_state', 'blocks.12.mlp.l3._extra_state', 'blocks.10.mlp.l1._extra_state', 'blocks.33.mlp.l2._extra_state', 'blocks.40.mlp.l2._extra_state', 'blocks.48.mlp.l2._extra_state', 'blocks.25.mlp.l2._extra_state', 'blocks.19.mlp.l1._extra_state', 'blocks.34.mlp.l3._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.31.mixer.attn._extra_state', 'blocks.15.out_filter_dense._extra_state', 'blocks.27.out_filter_dense._extra_state', 'blocks.4.mlp.l1._extra_state', 'blocks.35.mlp.l2._extra_state', 'blocks.31.inner_mha_cls.Wqkv._extra_state', 'blocks.8.out_filter_dense._extra_state', 'blocks.40.mlp.l3._extra_state', 'blocks.36.mlp.l2._extra_state', 'blocks.19.mlp.l3._extra_state', 'blocks.3.mixer.attn._extra_state', 'blocks.49.inner_mha_cls.Wqkv._extra_state', 'blocks.23.out_filter_dense._extra_state', 'blocks.37.mlp.l2._extra_state', 'blocks.18.mlp.l2._extra_state', 'blocks.8.mlp.l2._extra_state', 'blocks.16.out_filter_dense._extra_state', 'blocks.2.out_filter_dense._extra_state', 'blocks.21.mlp.l3._extra_state', 'blocks.14.mlp.l3._extra_state', 'blocks.47.mlp.l1._extra_state', 'blocks.17.mlp.l3._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.46.mlp.l1._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.5.out_filter_dense._extra_state', 'blocks.49.mlp.l3._extra_state', 'blocks.43.mlp.l2._extra_state', 'blocks.4.out_filter_dense._extra_state', 'blocks.29.mlp.l3._extra_state', 'blocks.14.out_filter_dense._extra_state', 'blocks.22.mlp.l2._extra_state', 'blocks.9.mlp.l1._extra_state', 'blocks.26.mlp.l2._extra_state', 'blocks.49.mlp.l1._extra_state', 'blocks.3.mlp.l3._extra_state', 'blocks.48.mlp.l1._extra_state', 'blocks.34.mlp.l1._extra_state', 'blocks.38.out_filter_dense._extra_state', 'blocks.31.mlp.l2._extra_state', 'blocks.6.out_filter_dense._extra_state', 'blocks.29.mlp.l1._extra_state', 'blocks.19.mlp.l2._extra_state', 'blocks.39.mlp.l3._extra_state', 'blocks.28.mlp.l2._extra_state', 'blocks.42.inner_mha_cls.Wqkv._extra_state', 'blocks.44.out_filter_dense._extra_state', 'blocks.11.mlp.l3._extra_state', 'blocks.10.mlp.l3._extra_state', 'blocks.37.mlp.l1._extra_state', 'blocks.35.mixer.dense._extra_state', 'blocks.17.mlp.l2._extra_state', 'blocks.39.mlp.l2._extra_state', 'unembed.weight', 'blocks.35.mlp.l1._extra_state', 'blocks.29.mlp.l2._extra_state', 'blocks.49.mixer.attn._extra_state', 'blocks.18.out_filter_dense._extra_state', 'blocks.6.mlp.l1._extra_state', 'blocks.23.mlp.l2._extra_state', 'blocks.8.mlp.l1._extra_state', 'blocks.20.mlp.l1._extra_state', 'blocks.36.out_filter_dense._extra_state', 'blocks.35.mixer.attn._extra_state', 'blocks.49.mixer.dense._extra_state', 'blocks.39.out_filter_dense._extra_state', 'blocks.16.mlp.l1._extra_state', 'blocks.5.mlp.l3._extra_state', 'blocks.12.out_filter_dense._extra_state', 'blocks.11.mlp.l1._extra_state', 'blocks.23.mlp.l3._extra_state', 'blocks.47.mlp.l3._extra_state', 'blocks.3.mlp.l1._extra_state', 'blocks.39.mlp.l1._extra_state', 'blocks.36.mlp.l1._extra_state', 'blocks.21.mlp.l2._extra_state', 'blocks.2.mlp.l3._extra_state', 'blocks.41.mlp.l1._extra_state', 'blocks.6.mlp.l3._extra_state', 'blocks.17.inner_mha_cls.Wqkv._extra_state', 'blocks.36.mlp.l3._extra_state', 'blocks.14.mlp.l1._extra_state', 'blocks.34.out_filter_dense._extra_state', 'blocks.38.mlp.l2._extra_state', 'blocks.1.out_filter_dense._extra_state', 'blocks.47.out_filter_dense._extra_state', 'blocks.45.mlp.l2._extra_state', 'blocks.15.mlp.l2._extra_state', 'blocks.10.mlp.l2._extra_state', 'blocks.17.mlp.l1._extra_state', 'blocks.46.mlp.l2._extra_state', 'blocks.0.out_filter_dense._extra_state', 'blocks.24.mlp.l1._extra_state', 'blocks.42.mlp.l3._extra_state', 'blocks.13.mlp.l2._extra_state', 'blocks.34.mlp.l2._extra_state', 'blocks.33.mlp.l3._extra_state', 'blocks.27.mlp.l3._extra_state', 'blocks.31.mlp.l3._extra_state', 'blocks.12.mlp.l1._extra_state', 'blocks.0.mlp.l1._extra_state', 'blocks.44.mlp.l3._extra_state', 'blocks.11.out_filter_dense._extra_state', 'blocks.26.out_filter_dense._extra_state', 'blocks.20.out_filter_dense._extra_state', 'blocks.45.mlp.l1._extra_state', 'blocks.1.mlp.l3._extra_state', 'blocks.33.mlp.l1._extra_state', 'blocks.30.mlp.l3._extra_state', 'blocks.37.out_filter_dense._extra_state', 'blocks.41.mlp.l3._extra_state', 'blocks.3.inner_mha_cls.Wqkv._extra_state', 'blocks.8.mlp.l3._extra_state', 'blocks.41.out_filter_dense._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.18.mlp.l1._extra_state', 'blocks.7.out_filter_dense._extra_state', 'blocks.38.mlp.l3._extra_state', 'blocks.12.mlp.l2._extra_state', 'blocks.13.out_filter_dense._extra_state', 'blocks.17.mixer.attn._extra_state', 'blocks.25.mlp.l3._extra_state', 'blocks.44.mlp.l2._extra_state', 'blocks.26.mlp.l3._extra_state', 'blocks.25.out_filter_dense._extra_state'}
Oct 27  22:12:31.044
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:12:32.067
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:12:32.701
Extra keys in state_dict: {'blocks.3.mlp.l3._extra_state', 'blocks.37.mlp.l3._extra_state', 'blocks.36.mlp.l1._extra_state', 'blocks.20.out_filter_dense._extra_state', 'blocks.44.out_filter_dense._extra_state', 'blocks.13.out_filter_dense._extra_state', 'blocks.5.mlp.l3._extra_state', 'blocks.4.mlp.l1._extra_state', 'blocks.32.out_filter_dense._extra_state', 'blocks.16.mlp.l1._extra_state', 'blocks.9.mlp.l3._extra_state', 'blocks.2.mlp.l3._extra_state', 'blocks.31.mixer.attn._extra_state', 'blocks.23.out_filter_dense._extra_state', 'blocks.34.mlp.l2._extra_state', 'blocks.21.out_filter_dense._extra_state', 'blocks.45.mlp.l2._extra_state', 'blocks.3.inner_mha_cls.Wqkv._extra_state', 'blocks.14.mlp.l3._extra_state', 'blocks.35.mlp.l1._extra_state', 'blocks.24.mlp.l1._extra_state', 'blocks.26.out_filter_dense._extra_state', 'blocks.25.mlp.l2._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.32.mlp.l1._extra_state', 'blocks.30.mlp.l3._extra_state', 'blocks.1.mlp.l2._extra_state', 'blocks.12.mlp.l3._extra_state', 'blocks.7.out_filter_dense._extra_state', 'blocks.8.mlp.l3._extra_state', 'blocks.48.mlp.l2._extra_state', 'blocks.3.mixer.attn._extra_state', 'blocks.7.mlp.l1._extra_state', 'blocks.49.mlp.l3._extra_state', 'blocks.19.mlp.l1._extra_state', 'blocks.49.inner_mha_cls.Wqkv._extra_state', 'blocks.31.mlp.l1._extra_state', 'blocks.32.mlp.l2._extra_state', 'blocks.37.out_filter_dense._extra_state', 'blocks.41.mlp.l3._extra_state', 'blocks.43.out_filter_dense._extra_state', 'blocks.49.mlp.l1._extra_state', 'blocks.44.mlp.l3._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.6.mlp.l3._extra_state', 'blocks.43.mlp.l3._extra_state', 'blocks.48.mlp.l1._extra_state', 'blocks.26.mlp.l1._extra_state', 'blocks.27.mlp.l1._extra_state', 'blocks.36.mlp.l2._extra_state', 'blocks.7.mlp.l2._extra_state', 'blocks.4.mlp.l3._extra_state', 'blocks.27.mlp.l2._extra_state', 'blocks.38.out_filter_dense._extra_state', 'blocks.9.mlp.l2._extra_state', 'blocks.25.mlp.l1._extra_state', 'blocks.0.out_filter_dense._extra_state', 'blocks.1.mlp.l3._extra_state', 'blocks.15.out_filter_dense._extra_state', 'blocks.33.out_filter_dense._extra_state', 'blocks.25.out_filter_dense._extra_state', 'blocks.18.out_filter_dense._extra_state', 'blocks.30.mlp.l2._extra_state', 'blocks.29.out_filter_dense._extra_state', 'blocks.19.mlp.l3._extra_state', 'blocks.0.mlp.l1._extra_state', 'blocks.47.out_filter_dense._extra_state', 'blocks.48.out_filter_dense._extra_state', 'blocks.16.mlp.l3._extra_state', 'blocks.11.mlp.l3._extra_state', 'blocks.18.mlp.l1._extra_state', 'blocks.43.mlp.l1._extra_state', 'blocks.36.mlp.l3._extra_state', 'blocks.14.out_filter_dense._extra_state', 'blocks.27.out_filter_dense._extra_state', 'blocks.0.mlp.l2._extra_state', 'blocks.3.mixer.dense._extra_state', 'blocks.10.inner_mha_cls.Wqkv._extra_state', 'blocks.44.mlp.l1._extra_state', 'blocks.2.out_filter_dense._extra_state', 'blocks.16.out_filter_dense._extra_state', 'blocks.35.mlp.l3._extra_state', 'blocks.6.mlp.l2._extra_state', 'blocks.42.mixer.dense._extra_state', 'blocks.26.mlp.l2._extra_state', 'blocks.7.mlp.l3._extra_state', 'blocks.38.mlp.l2._extra_state', 'blocks.19.mlp.l2._extra_state', 'unembed.weight', 'blocks.14.mlp.l1._extra_state', 'blocks.11.mlp.l2._extra_state', 'blocks.41.out_filter_dense._extra_state', 'blocks.22.mlp.l3._extra_state', 'blocks.22.out_filter_dense._extra_state', 'blocks.9.out_filter_dense._extra_state', 'blocks.45.mlp.l1._extra_state', 'blocks.34.out_filter_dense._extra_state', 'blocks.42.mlp.l1._extra_state', 'blocks.44.mlp.l2._extra_state', 'blocks.30.mlp.l1._extra_state', 'blocks.29.mlp.l2._extra_state', 'blocks.23.mlp.l1._extra_state', 'blocks.30.out_filter_dense._extra_state', 'blocks.0.mlp.l3._extra_state', 'blocks.31.mlp.l3._extra_state', 'blocks.15.mlp.l3._extra_state', 'blocks.15.mlp.l2._extra_state', 'blocks.38.mlp.l3._extra_state', 'blocks.11.mlp.l1._extra_state', 'blocks.2.mlp.l2._extra_state', 'blocks.4.out_filter_dense._extra_state', 'blocks.39.out_filter_dense._extra_state', 'blocks.16.mlp.l2._extra_state', 'blocks.2.mlp.l1._extra_state', 'blocks.39.mlp.l1._extra_state', 'blocks.1.out_filter_dense._extra_state', 'blocks.46.mlp.l2._extra_state', 'blocks.9.mlp.l1._extra_state', 'blocks.12.mlp.l1._extra_state', 'blocks.8.mlp.l1._extra_state', 'blocks.40.mlp.l1._extra_state', 'blocks.12.mlp.l2._extra_state', 'blocks.38.mlp.l1._extra_state', 'blocks.40.mlp.l2._extra_state', 'blocks.49.mixer.dense._extra_state', 'blocks.20.mlp.l2._extra_state', 'blocks.32.mlp.l3._extra_state', 'blocks.17.inner_mha_cls.Wqkv._extra_state', 'blocks.29.mlp.l1._extra_state', 'blocks.14.mlp.l2._extra_state', 'blocks.23.mlp.l3._extra_state', 'blocks.10.mlp.l3._extra_state', 'blocks.35.mixer.attn._extra_state', 'blocks.28.out_filter_dense._extra_state', 'blocks.17.mixer.dense._extra_state', 'blocks.35.mlp.l2._extra_state', 'blocks.8.mlp.l2._extra_state', 'blocks.19.out_filter_dense._extra_state', 'blocks.49.mlp.l2._extra_state', 'blocks.1.mlp.l1._extra_state', 'blocks.25.mlp.l3._extra_state', 'blocks.43.mlp.l2._extra_state', 'blocks.6.mlp.l1._extra_state', 'blocks.17.mlp.l1._extra_state', 'blocks.17.mixer.attn._extra_state', 'blocks.13.mlp.l1._extra_state', 'blocks.18.mlp.l3._extra_state', 'blocks.21.mlp.l1._extra_state', 'blocks.24.mlp.l3._extra_state', 'blocks.42.inner_mha_cls.Wqkv._extra_state', 'blocks.20.mlp.l1._extra_state', 'blocks.37.mlp.l1._extra_state', 'blocks.39.mlp.l3._extra_state', 'blocks.35.mixer.dense._extra_state', 'blocks.5.out_filter_dense._extra_state', 'blocks.29.mlp.l3._extra_state', 'blocks.47.mlp.l3._extra_state', 'blocks.10.mlp.l2._extra_state', 'blocks.26.mlp.l3._extra_state', 'blocks.31.mlp.l2._extra_state', 'blocks.22.mlp.l2._extra_state', 'blocks.4.mlp.l2._extra_state', 'blocks.11.out_filter_dense._extra_state', 'blocks.45.mlp.l3._extra_state', 'blocks.36.out_filter_dense._extra_state', 'blocks.46.mlp.l3._extra_state', 'blocks.24.inner_mha_cls.Wqkv._extra_state', 'blocks.20.mlp.l3._extra_state', 'blocks.12.out_filter_dense._extra_state', 'blocks.28.mlp.l2._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.21.mlp.l3._extra_state', 'blocks.48.mlp.l3._extra_state', 'blocks.45.out_filter_dense._extra_state', 'blocks.21.mlp.l2._extra_state', 'blocks.41.mlp.l1._extra_state', 'blocks.31.inner_mha_cls.Wqkv._extra_state', 'blocks.3.mlp.l2._extra_state', 'blocks.28.mlp.l3._extra_state', 'blocks.28.mlp.l1._extra_state', 'blocks.5.mlp.l2._extra_state', 'blocks.33.mlp.l3._extra_state', 'blocks.17.mlp.l2._extra_state', 'blocks.23.mlp.l2._extra_state', 'blocks.47.mlp.l2._extra_state', 'blocks.35.inner_mha_cls.Wqkv._extra_state', 'blocks.17.mlp.l3._extra_state', 'blocks.6.out_filter_dense._extra_state', 'blocks.8.out_filter_dense._extra_state', 'blocks.34.mlp.l1._extra_state', 'blocks.47.mlp.l1._extra_state', 'blocks.5.mlp.l1._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.10.mlp.l1._extra_state', 'blocks.46.out_filter_dense._extra_state', 'blocks.10.mixer.attn._extra_state', 'blocks.18.mlp.l2._extra_state', 'blocks.39.mlp.l2._extra_state', 'blocks.40.out_filter_dense._extra_state', 'blocks.34.mlp.l3._extra_state', 'blocks.33.mlp.l1._extra_state', 'blocks.42.mlp.l3._extra_state', 'blocks.41.mlp.l2._extra_state', 'blocks.37.mlp.l2._extra_state', 'blocks.27.mlp.l3._extra_state', 'blocks.46.mlp.l1._extra_state', 'blocks.49.mixer.attn._extra_state', 'blocks.13.mlp.l3._extra_state', 'blocks.15.mlp.l1._extra_state', 'blocks.33.mlp.l2._extra_state', 'blocks.42.mixer.attn._extra_state', 'blocks.42.mlp.l2._extra_state', 'blocks.3.mlp.l1._extra_state', 'blocks.40.mlp.l3._extra_state', 'blocks.24.mlp.l2._extra_state', 'blocks.22.mlp.l1._extra_state', 'blocks.13.mlp.l2._extra_state'}
Oct 27  22:12:32.747
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:12:33.048
Extra keys in state_dict: {'blocks.27.mixer.mixer.filter.t', 'blocks.17.mixer.dense._extra_state', 'blocks.2.mixer.mixer.filter.t', 'unembed.weight', 'blocks.10.mixer.attn._extra_state', 'blocks.13.mixer.mixer.filter.t', 'blocks.17.mixer.attn._extra_state', 'blocks.31.mixer.dense._extra_state', 'blocks.30.mixer.mixer.filter.t', 'blocks.23.mixer.mixer.filter.t', 'blocks.31.mixer.attn._extra_state', 'blocks.3.mixer.attn._extra_state', 'blocks.20.mixer.mixer.filter.t', 'blocks.3.mixer.dense._extra_state', 'blocks.16.mixer.mixer.filter.t', 'blocks.6.mixer.mixer.filter.t', 'blocks.10.mixer.dense._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.24.mixer.dense._extra_state', 'blocks.9.mixer.mixer.filter.t'}
Oct 27  22:12:33.062
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:12:33.794
Extra keys in state_dict: {'blocks.10.mixer.attn._extra_state', 'blocks.23.mixer.mixer.filter.t', 'blocks.13.mixer.mixer.filter.t', 'blocks.31.mixer.attn._extra_state', 'unembed.weight', 'blocks.31.mixer.dense._extra_state', 'blocks.10.mixer.dense._extra_state', 'blocks.6.mixer.mixer.filter.t', 'blocks.3.mixer.dense._extra_state', 'blocks.16.mixer.mixer.filter.t', 'blocks.30.mixer.mixer.filter.t', 'blocks.3.mixer.attn._extra_state', 'blocks.24.mixer.attn._extra_state', 'blocks.9.mixer.mixer.filter.t', 'blocks.17.mixer.dense._extra_state', 'blocks.20.mixer.mixer.filter.t', 'blocks.24.mixer.dense._extra_state', 'blocks.2.mixer.mixer.filter.t', 'blocks.27.mixer.mixer.filter.t', 'blocks.17.mixer.attn._extra_state'}
Oct 27  22:12:33.810
/usr/local/lib/python3.11/site-packages/transformer_engine/pytorch/module/base.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location="cuda")
Oct 27  22:12:34.690
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:12:35.654
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:12:37.563
2025-10-28 02:12:37.557 | INFO     | main:load_model_and_api:455 - üéâ Evo2 7B model loaded successfully!
Oct 27  22:12:38.447
2025-10-28 02:12:38.440 | INFO     | main:load_model_and_api:455 - üéâ Evo2 7B model loaded successfully!
Oct 27  22:12:40.811
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:12:41.651
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.89s/it]
Oct 27  22:12:41.750
   POST /score_delta -> 200 OK  (duration: 83.2 s, execution: 3.98 s)
Oct 27  22:12:41.838
2025-10-28 02:12:41.831 | INFO     | main:load_model_and_api:69 - üéâ Evo2 model loaded successfully!
Oct 27  22:12:41.969
/evo2/vortex/vortex/model/utils.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch_load(state, map_location=device)
Oct 27  22:12:42.824
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:12:42.862
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]
Oct 27  22:12:42.903
   POST /score_delta -> 200 OK  (duration: 84.3 s, execution: 1.11 s)
Oct 27  22:12:42.940
   POST /score_delta -> 200 OK  (duration: 84.3 s, execution: 4.32 s)
Oct 27  22:12:43.990
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:12:44.079
   POST /score_delta -> 200 OK  (duration: 85.5 s, execution: 1.12 s)
Oct 27  22:12:44.978
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.02it/s]
Oct 27  22:12:45.066
   POST /score_delta -> 200 OK  (duration: 86.4 s, execution: 2.07 s)
Oct 27  22:12:50.059
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.45s/it]
Oct 27  22:12:50.127
   POST /score_delta -> 200 OK  (duration: 91.1 s, execution: 5.02 s)
Oct 27  22:12:50.311
2025-10-28 02:12:41.976 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08<00:00,  4.16s/it]
2025-10-28 02:12:50.305 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:12:50.347
   POST /score_delta -> 200 OK  (duration: 91.9 s, execution: 8.37 s)
Oct 27  22:12:51.227
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:12:51.304
   POST /score_delta -> 200 OK  (duration: 46.3 s, execution: 1.11 s)
Oct 27  22:12:51.791
2025-10-28 02:12:51.785 | INFO     | main:load_model_and_api:69 - üéâ Evo2 model loaded successfully!
Oct 27  22:12:51.932
2025-10-28 02:12:51.926 | INFO     | main:load_model_and_api:69 - üéâ Evo2 model loaded successfully!
Oct 27  22:12:52.028
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.93s/it]
Oct 27  22:12:52.107
   POST /score_delta -> 200 OK  (duration: 93.2 s, execution: 7.98 s)
Oct 27  22:12:52.420
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:12:52.498
   POST /score_delta -> 200 OK  (duration: 34.1 s, execution: 1.14 s)
Oct 27  22:12:53.624
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:12:53.702
   POST /score_delta -> 200 OK  (duration: 1.23 s, execution: 1.11 s)
Oct 27  22:12:56.393
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.07it/s]
Oct 27  22:12:56.487
   POST /score_delta -> 200 OK  (duration: 2.15 s, execution: 2.04 s)
Oct 27  22:12:59.258
2025-10-28 02:12:50.362 | INFO     | main:score_delta:97 - /score_delta called | ref_len=16385 alt_len=16385
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08<00:00,  4.44s/it]
2025-10-28 02:12:59.252 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:12:59.289
   POST /score_delta -> 200 OK  (duration: 100.8 s, execution: 8.92 s)
Oct 27  22:12:59.837
2025-10-28 02:12:52.172 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.83s/it]
2025-10-28 02:12:59.832 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:12:59.903
   POST /score_delta -> 200 OK  (duration: 101.2 s, execution: 7.81 s)
Oct 27  22:13:01.638
2025-10-28 02:12:59.309 | INFO     | main:score_delta:97 - /score_delta called | ref_len=50001 alt_len=50001
  0%|          | 0/2 [00:02<?, ?it/s]
2025-10-28 02:13:01.632 | ERROR    | main:score_delta:112 - Scoring failed: Error during sequence scoring: CUDA out of memory. Tried to allocate 24.42 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.00 GiB is free. Process 1 has 70.17 GiB memory in use. Of the allocated memory 68.90 GiB is allocated by PyTorch, and 602.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Oct 27  22:13:01.669
   POST /score_delta -> 500 Internal Server Error  (duration: 102.6 s, execution: 2.35 s)
Oct 27  22:13:01.969
2025-10-28 02:13:01.963 | INFO     | main:score_variant_exon:278 - /score_variant_exon called | 7:140753336 T>A flank=25000
Oct 27  22:13:02.097
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.35s/it]
Oct 27  22:13:02.186
   POST /score_delta -> 200 OK  (duration: 4.99 s, execution: 4.88 s)
Oct 27  22:13:03.311
   POST /score_variant_exon -> 400 Bad Request  (duration: 1.44 s, execution: 1.38 s)
Oct 27  22:13:06.788
2025-10-28 02:13:04.374 | INFO     | main:score_delta:97 - /score_delta called | ref_len=50001 alt_len=50001
  0%|          | 0/2 [00:02<?, ?it/s]
2025-10-28 02:13:06.781 | ERROR    | main:score_delta:112 - Scoring failed: Error during sequence scoring: CUDA out of memory. Tried to allocate 24.42 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.02 GiB is free. Process 1 has 70.15 GiB memory in use. Of the allocated memory 68.90 GiB is allocated by PyTorch, and 582.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Oct 27  22:13:06.842
   POST /score_delta -> 500 Internal Server Error  (duration: 2.68 s, execution: 2.63 s)
Oct 27  22:13:11.071
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.83s/it]
Oct 27  22:13:11.144
   POST /score_delta -> 200 OK  (duration: 7.98 s, execution: 7.91 s)
Oct 27  22:13:16.157
2025-10-28 02:12:52.065 | INFO     | main:score_delta:97 - /score_delta called | ref_len=32769 alt_len=32769
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:24<00:00, 12.04s/it]
2025-10-28 02:13:16.151 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:13:16.235
   POST /score_delta -> 200 OK  (duration: 117.7 s, execution: 24.3 s)
Oct 27  22:13:16.307
2025-10-28 02:13:11.905 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.20s/it]
2025-10-28 02:13:16.301 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:13:16.346
   POST /score_delta -> 200 OK  (duration: 4.50 s, execution: 4.44 s)
Oct 27  22:13:21.493
2025-10-28 02:13:17.084 | INFO     | main:score_delta:97 - /score_delta called | ref_len=8193 alt_len=8193
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.20s/it]
2025-10-28 02:13:21.488 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:13:21.561
   POST /score_delta -> 200 OK  (duration: 4.56 s, execution: 4.47 s)
Oct 27  22:13:31.056
2025-10-28 02:13:22.729 | INFO     | main:score_delta:97 - /score_delta called | ref_len=16385 alt_len=16385
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08<00:00,  4.16s/it]
2025-10-28 02:13:31.050 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:13:31.131
   POST /score_delta -> 200 OK  (duration: 8.53 s, execution: 8.47 s)
Oct 27  22:13:33.695
2025-10-28 02:13:32.361 | INFO     | main:score_delta:97 - /score_delta called | ref_len=32769 alt_len=32769
  0%|          | 0/2 [00:01<?, ?it/s]
2025-10-28 02:13:33.689 | ERROR    | main:score_delta:112 - Scoring failed: Error during sequence scoring: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.39 GiB is free. Process 1 has 65.78 GiB memory in use. Of the allocated memory 64.48 GiB is allocated by PyTorch, and 629.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Oct 27  22:13:33.730
   POST /score_delta -> 500 Internal Server Error  (duration: 1.66 s, execution: 1.58 s)
Oct 27  22:13:33.994
2025-10-28 02:13:33.988 | INFO     | main:score_variant_exon:278 - /score_variant_exon called | 7:140753336 T>A flank=16384
Oct 27  22:13:34.654
   POST /score_variant_exon -> 400 Bad Request  (duration: 769.4 ms, execution: 670.8 ms)
Oct 27  22:13:58.085
2025-10-28 02:13:36.527 | INFO     | main:score_delta:97 - /score_delta called | ref_len=32769 alt_len=32769
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:21<00:00, 10.78s/it]
2025-10-28 02:13:58.080 | INFO     | main:score_delta:105 - /score_delta done | delta=0.0000
Oct 27  22:13:58.159
   POST /score_delta -> 200 OK  (duration: 21.8 s, execution: 21.8 s)
Oct 27  22:14:00.813
2025-10-28 02:13:59.359 | INFO     | main:score_delta:97 - /score_delta called | ref_len=50001 alt_len=50001
  0%|          | 0/2 [00:01<?, ?it/s]
2025-10-28 02:14:00.807 | ERROR    | main:score_delta:112 - Scoring failed: Error during sequence scoring: CUDA out of memory. Tried to allocate 15.41 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.75 GiB is free. Process 1 has 69.42 GiB memory in use. Of the allocated memory 68.14 GiB is allocated by PyTorch, and 606.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Oct 27  22:14:00.860
   POST /score_delta -> 500 Internal Server Error  (duration: 1.74 s, execution: 1.69 s)
Oct 27  22:14:05.830
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:14:05.909
   POST /score_delta -> 200 OK  (duration: 1.21 s, execution: 1.12 s)
Oct 27  22:14:09.179
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:14:09.254
   POST /score_delta -> 200 OK  (duration: 1.20 s, execution: 1.12 s)
Oct 27  22:14:11.036
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.94it/s]
Oct 27  22:14:11.141
   POST /score_delta -> 200 OK  (duration: 1.23 s, execution: 1.15 s)
Streaming
Modal logo
¬© 2025
About
Status
Changelog
Documentation
Slack Community
Pricing
Examples
App Details - crispro | Modal

Log Context
Oct 27, 2025, 22:11:22
Function

Filter by function
EvoService1B.*
Log Type

Filter by source
stdout
Function Call ID
‚Äî
Container ID

Filter by container
ta-01K8M9B35FXCSNYB3E1H6HB5TM

Copy

Full Log
View in context

==========
== CUDA ==
==========
