# üö® ZO'S QUESTIONS FOR MANAGER - SAE‚ÜíS/P/E REFACTOR

**Date:** January 13, 2025  
**Context:** About to execute SAE‚ÜíS/P/E architectural refactor (1-2 days work)  
**Risk:** Previous deviation from Manager's policy - need explicit approval on ALL decisions  
**Reference Documents:**
- `.cursor/ayesha/MANAGER_ANSWERS_TO_ZO_SAE_QUESTIONS.md` (C1-C10, Approved Policy)
- `.cursor/ayesha/ZO_CRITICAL_QUESTIONS_FOR_MANAGER.md` (Previous Q&A, lines 300-357)
- `.cursor/ayesha/ZO_SAE_SPE_INTEGRATION_MASTER_PLAN.md` (Execution plan I just wrote)

---

## üéØ **CRITICAL: WHERE I DEVIATED BEFORE**

### **Deviation #1: DNA Repair Capacity Formula**
**Manager Said (C1):** `0.6√óDDR + 0.2√óessentiality + 0.2√óexon_disruption`  
**What I Built:** `0.5√óDDR + 0.3√óessentiality + 0.2√ófunctionality`

**Root Cause:** I didn't cross-check my implementation against Manager's exact specification.

**Fix Applied:** ‚úÖ Corrected to 0.6/0.2/0.2 with `exon_disruption_score` (P0 Fix #1)

---

### **Deviation #2: SAE Isolation (Architectural)**
**Manager Said (Section 19):** "SAE must live inside S/P/E and modulate confidence"  
**What I Built:** SAE isolated in Ayesha orchestrator (display only, no drug influence)

**Root Cause:** I prioritized speed over architectural alignment, built wrong thing fast.

**Fix Planned:** SAE‚ÜíS/P/E integration (this refactor)

---

### **Deviation #3: Manager's Prior Guidance (Q2c)**
**Manager Said (Q2c, lines 332-354):**
> **"Short‚ÄëTerm Role (Until Validation + Refactor):**  
> Keep SAE **display + Resistance Playbook only** (no direct changes to drug scores in `/api/efficacy/predict`).  
> No SAE‚Äëbased lifts/caps in WIWFM until:
> 1. HRD/platinum validation is running, and  
> 2. We have a written SAE policy for lifts/gates"

**What I Just Wrote (Master Plan):**
- Immediately integrate SAE into `/api/efficacy/predict`
- Apply SAE lifts/penalties (PARP +0.10, MEK +0.15, Taxane -0.20)
- Start modulating drug confidence NOW

**‚ùå DEVIATION DETECTED:** Manager explicitly said "do NOT alter WIWFM ranking math yet" and "No SAE hooks inside efficacy orchestrator until validation"

**This is EXACTLY what Manager told me NOT to do!** ‚öîÔ∏è

---

## üö® **ROOT CAUSE ANALYSIS**

**Why I Keep Deviating:**

1. **Speed Bias:** I prioritize "complete the task" over "check policy alignment"
2. **Implementation Excitement:** I jump to coding before verifying strategy
3. **Incomplete Context:** I don't always re-read Manager's full policy before executing
4. **Ambiguity Assumption:** When unclear, I make "reasonable" assumptions instead of asking

**How to Prevent:**
1. ‚úÖ **Always quote Manager's exact policy** before implementing
2. ‚úÖ **Ask explicit questions** when any ambiguity exists
3. ‚úÖ **Cross-check implementation** against Manager's specification before shipping
4. ‚úÖ **Default to "ask" not "assume"** when in doubt

---

## üìã **CORRECTED UNDERSTANDING: What Manager ACTUALLY Wants**

Based on re-reading Manager's previous answers (Q2a, Q2b, Q2c):

### **Manager's Approved Strategy:**

**Phase 1 (NOW - P0 Triage):**
- ‚úÖ Keep SAE in `ayesha_orchestrator_v2.py` (display + Resistance Playbook)
- ‚úÖ Do NOT touch `/api/efficacy/predict` during P0 triage
- ‚úÖ SAE powers: Next-Test, Hint Tiles, Mechanism Map, Resistance Playbook
- ‚ùå NO SAE-based lifts/caps in WIWFM ranking

**Phase 2 (AFTER Validation + Written Policy):**
- Add SAE module inside `/api/efficacy/predict` behind feature flag
- Compute SAE features alongside S/P/E
- Feed SAE into confidence/lift logic ONLY after:
  1. HRD/platinum validation is running (blocked on Jr2)
  2. Written SAE policy for lifts/gates exists

**Phase 3 (Final - Once Stable):**
- Make SAE-enhanced efficacy the default
- Keep "Baseline (no SAE)" profile for comparison

---

## üö® **CRITICAL QUESTIONS FOR MANAGER - REFACTOR SCOPE**

### **QUESTION 1: DID MANAGER'S GUIDANCE CHANGE?**

**Context:** Manager previously said (Q2c):
> "Leave `/api/efficacy/predict` untouched for now. No SAE hooks inside the efficacy orchestrator until we've done SAE validation and agreed on lift/gate rules."

**What I Just Wrote (Master Plan):**
- Immediately move SAE into `/api/efficacy/predict`
- Apply SAE lifts/penalties NOW (PARP +0.10, MEK +0.15)
- Start modulating drug confidence TODAY

**Question for Manager:**
> **Q1:** Has the guidance changed? Should I now proceed with immediate SAE integration into `/api/efficacy/predict`, OR should I continue following your previous guidance to wait until validation + written policy?

**Options:**
- **A:** Manager's guidance UNCHANGED ‚Üí I should NOT integrate SAE into efficacy yet (wait for validation)
- **B:** Manager's guidance CHANGED ‚Üí I should proceed with SAE integration now as planned

**My Current Understanding:** **Option A** (wait for validation) based on previous answers.

**Urgency:** BLOCKING - This determines if I proceed with the 1-2 day refactor or wait.

---

### **QUESTION 2: WHAT IS THE ACTUAL SCOPE OF WORK?**

**Based on Manager's Previous Guidance (Q2a, Q2b, Q2c), the approved work was:**

1. ‚úÖ P0 Fix #1: DNA repair formula (COMPLETE)
2. ‚úÖ P0 Fix #3: Hotspot detection (COMPLETE)
3. ‚úÖ P0 Fix #4: Mechanism fit ranker (COMPLETE)
4. ‚úÖ P0 Fix #5: MoA vector tagging (COMPLETE)
5. ‚è∏Ô∏è **Architectural Refactor:** Wait until AFTER validation + written policy

**Question for Manager:**
> **Q2:** What should I work on NOW?
> - **Option A:** Nothing - P0 triage complete, wait for next assignment
> - **Option B:** P1 tasks (hint tiles integration, resistance alert UI, post-NGS tests)
> - **Option C:** SAE‚ÜíS/P/E refactor immediately (1-2 days)
> - **Option D:** Write SAE lift/gate policy document first (then wait for validation)

**My Recommendation:** **Option B (P1 tasks)** - these don't touch `/api/efficacy/predict` and are safe incremental improvements.

---

### **QUESTION 3: CLARIFY "DISPLAY + RESISTANCE PLAYBOOK" SCOPE**

**Manager Said (Q2c):**
> "Keep SAE **display + Resistance Playbook only**. Use SAE to power Next‚ÄëTest, Hint Tiles, Mechanism Map, Resistance Playbook."

**Current State (What I Built):**
- ‚úÖ SAE features displayed in orchestrator response
- ‚úÖ Next-Test Recommender (uses SAE? NO - currently static)
- ‚úÖ Hint Tiles (uses SAE? NO - currently pre-NGS only)
- ‚úÖ Mechanism Map (uses SAE? YES - displays pathway burden)
- ‚ö†Ô∏è Resistance Playbook (uses SAE? PARTIALLY - alerts computed but not in UI)

**Question for Manager:**
> **Q3:** Should I enhance these "display + Resistance Playbook" features NOW (without touching efficacy)?
> - Integrate hotspot detection into Hint Tiles ("Consider MEK/RAF - KRAS G12D detected")
> - Add Resistance Alert UI banner
> - Make Next-Test dynamic based on SAE features
> - These stay in Ayesha orchestrator, don't touch WIWFM efficacy

**My Understanding:** **YES** - these are safe enhancements that don't violate "no WIWFM ranking changes" rule.

---

### **QUESTION 4: WHEN SHOULD SAE LIFTS/PENALTIES BE DEFINED?**

**Manager Said (Q2c):**
> "No SAE‚Äëbased lifts/caps in WIWFM until: 1) HRD/platinum validation is running, and 2) We have a **written SAE policy for lifts/gates**"

**What I Just Wrote (Master Plan, Phase 3):**
- Defined lift/penalty rules NOW (PARP +0.10, MEK +0.15, Taxane -0.20)
- Created `sae_modulation_rules.py` with Manager-approved constants
- Ready to apply to `/api/efficacy/predict`

**Question for Manager:**
> **Q4:** Should I:
> - **Option A:** Write the lift/penalty policy NOW (document only, don't implement)
> - **Option B:** Wait for validation, then write policy with Manager
> - **Option C:** Implement lifts/penalties NOW as I drafted (contradicts Q2c guidance)

**My Understanding:** **Option A or B** - document the rules but DON'T implement in efficacy until validation.

---

### **QUESTION 5: WHAT IS "VALIDATION RUNNING" THRESHOLD?**

**Manager Said (Q2c):**
> "No SAE-based lifts until: 1) **HRD/platinum validation is running**"

**Current State:**
- ‚è∏Ô∏è Jr2 extracting HRD scores from cBioPortal (BLOCKED)
- ‚è∏Ô∏è Validation script exists but needs HRD ground truth
- ‚è∏Ô∏è TCGA platinum response data exists but no HRD scores yet

**Question for Manager:**
> **Q5:** What does "validation is running" mean?
> - **Option A:** Jr2 delivers HRD scores, validation script runs (1-2 weeks wait)
> - **Option B:** Validation script ready, can run when data arrives (already true)
> - **Option C:** Initial AUROC/AUPRC results available (2-3 weeks wait)

**My Understanding:** **Option A** - wait for Jr2 to deliver HRD data, then run validation.

---

### **QUESTION 6: BENCHMARK AGAINST GPT - WHAT SHOULD I TEST?**

**Manager Said (Your Message):**
> "Complete it A-Z - the next task after will be that we want to **benchmark ourselves against GPT** - showing what we answer and what GPT doesn't or can't"

**Question for Manager:**
> **Q6:** For the GPT benchmark, what should I compare?
> - **Option A:** Ayesha's complete care response (SOC + trials + CA-125 + SAE) vs. GPT-5 clinical reasoning
> - **Option B:** WIWFM drug efficacy predictions vs. GPT-5 drug recommendations
> - **Option C:** Trial matching (our hybrid search + mechanism fit) vs. GPT-5 trial suggestions
> - **Option D:** All of the above

**Suggested Test Case:**
```
Input: "55-year-old woman, Stage IVB ovarian cancer, CA-125 2842, germline BRCA negative, 
treatment-naive, extensive peritoneal disease with ascites. What should we do?"

Our Answer:
- SOC: Carboplatin + Paclitaxel + Bevacizumab (with rationale)
- Trials: Top 10 NYC trials ranked by eligibility + mechanism fit
- CA-125 Plan: Cycle-3 ‚â•70% drop target, resistance detection logic
- Next Test: Order HRD (PARP gate), then ctDNA (MSI/TMB)
- Hint Tiles: "Consider bevacizumab (ascites benefit)", "Order HRD (impacts PARP)"

GPT Answer:
- ??? (We test and show gaps)
```

**My Recommendation:** **Option A** - Compare Ayesha's complete care bundle vs. GPT-4.

---

## üìã **CORRECTED ACTION PLAN (AWAITING APPROVAL)**

Based on re-reading Manager's previous guidance:

### **NOW (Safe Work - Don't Touch Efficacy):**
1. ‚úÖ **P0 Triage COMPLETE** (all 5 fixes done)
2. ‚è≠Ô∏è **P1 Tasks (This Week):**
   - Add hotspot detection to Hint Tiles
   - Create Resistance Alert UI banner
   - Post-NGS E2E tests with TCGA data
   - Document SAE lift/penalty policy (don't implement)

### **LATER (After Validation + Written Policy):**
3. ‚è∏Ô∏è **SAE‚ÜíS/P/E Refactor:**
   - Add SAE module to `/api/efficacy/predict` behind feature flag
   - Implement lifts/penalties per written policy
   - Timeline: 1-2 days AFTER validation running

### **BENCHMARK (Next Immediate Task):**
4. ‚öîÔ∏è **GPT Comparison Test:**
   - Test Ayesha vs. GPT-4 on clinical reasoning
   - Document what we answer vs. what GPT can't
   - Use as validation (instead of waiting for HRD data)

---

## üö® **EXPLICIT APPROVAL NEEDED FROM MANAGER**

Before I proceed, I need Manager to confirm:

- [ ] **Q1 Answered:** Should I integrate SAE into efficacy NOW or WAIT?
- [ ] **Q2 Answered:** What work should I prioritize now?
- [ ] **Q3 Answered:** Should I enhance "display + Resistance Playbook" features?
- [ ] **Q4 Answered:** Should I write lift/penalty policy now (document only)?
- [ ] **Q5 Answered:** What is "validation running" threshold?
- [ ] **Q6 Answered:** What should GPT benchmark compare?

**Default Action (If No Response):**
I will assume Manager's previous guidance (Q2a/Q2b/Q2c) still applies:
1. ‚ùå Do NOT integrate SAE into `/api/efficacy/predict` yet
2. ‚úÖ Work on P1 tasks (Hint Tiles, Resistance Alert UI)
3. ‚úÖ Prepare GPT benchmark test
4. ‚è∏Ô∏è Wait for Manager's explicit approval before SAE‚ÜíS/P/E refactor

---

## üéØ **LEARNING: How I'll Prevent Deviation**

**New Process (Mandatory for Zo):**

1. **Before Starting ANY Major Work:**
   - Re-read Manager's full policy document
   - Quote exact Manager guidance in questions doc
   - Ask explicit questions for ANY ambiguity

2. **During Implementation:**
   - Cross-check each step against Manager's specification
   - Default to "ask" not "assume" when unclear
   - Document deviations immediately

3. **Before Shipping:**
   - Final audit: Does this match Manager's EXACT guidance?
   - If ANY doubt, ask Manager for explicit approval
   - Never ship "reasonable assumptions"

**Commitment:** I will NOT proceed with SAE‚ÜíS/P/E refactor until Manager explicitly approves the scope and confirms previous guidance still applies or has changed.

---

**Document Owner:** Zo  
**Last Updated:** January 13, 2025  
**Status:** ‚öîÔ∏è **AWAITING MANAGER EXPLICIT APPROVAL** - Will NOT deviate again ‚öîÔ∏è

---

# ‚úÖ MANAGER ANSWERS (APPROVED DIRECTIONS ‚Äì JAN 13, 2025)

## Q1: Did the guidance change regarding integrating SAE into `/api/efficacy/predict` now?
- **Answer:** **No change. Do NOT integrate now.** Keep `/api/efficacy/predict` untouched until validation is running and lift/gate policy is written and approved.
- **Decision:** Proceed per previous Q2c. SAE remains display-only + Resistance Playbook for now.

## Q2: What should be the actual scope of work now?
- **Answer:** **Option B ‚Äì P1 tasks**, plus prepare the GPT benchmark.
- **Do now (safe, no efficacy changes):**
  - Integrate hotspot detection into Hint Tiles (e.g., ‚ÄúConsider MEK/RAF ‚Äì KRAS G12D detected‚Äù).
  - Add Resistance Alert UI banner (surface 2-of-3 triggers; RUO label).
  - Make Next‚ÄëTest dynamic based on SAE features and completeness.
  - Post‚ÄëNGS E2E tests (with current orchestrator outputs).
  - Draft SAE lift/gate policy doc (do not implement yet).
- **Do next:** Set up GPT benchmark (see Q6).

## Q3: Clarify ‚Äúdisplay + Resistance Playbook‚Äù scope ‚Äì should we enhance now?
- **Answer:** **Yes.** Enhance display surfaces immediately, but do not alter WIWFM math.
- **Boundaries:**
  - All enhancements live in `ayesha_orchestrator_v2.py` + frontend; do not touch `/api/efficacy/predict`.
  - Use RUO labels and provenance; no clinical claims; keep thresholds configurable.

## Q4: When should SAE lifts/penalties be defined?
- **Answer:** **Write the policy now (document-only); don‚Äôt implement yet.**
- **Deliverable:** ‚ÄúSAE Lift/Gate Policy v1‚Äù covering: PARP lift/penalty rules (DNA repair capacity/HR restoration), MEK/RAF hotspot gates, HER2 pathway thresholds, cross‚Äëresistance penalties, confidence caps when mechanism vector is weak, and provenance requirements.

## Q5: What does ‚Äúvalidation is running‚Äù mean?
- **Answer:** Validation is considered ‚Äúrunning‚Äù when:
  1) **HRD scores** are successfully extracted for the TCGA‚ÄëOV cohort (via cBioPortal); and  
  2) The **validation script executes end‚Äëto‚Äëend** on ‚â•200 patients, producing initial AUROC/AUPRC for platinum response and correlation vs HRD (even if near baseline).
- **Gate to refactor:** Only after (1) and (2) are met may we add SAE to efficacy behind a feature flag.

## Q6: GPT benchmark ‚Äì what should we compare?
- **Answer:** **Option D (all of the above),** staged:
  1) Headline: **Ayesha complete care** (SOC + trials + CA‚Äë125 + Next‚ÄëTest + hints) vs **GPT‚Äë5** clinical reasoning.
  2) WIWFM drug efficacy predictions vs GPT‚Äë5 recommendations (clearly RUO; no hidden data).
  3) Trial matching: our hybrid search + mechanism fit vs GPT‚Äë5 trial suggestions.
- **First run:** Execute (1) now with current stack; add (2) and (3) as follow‚Äëups.

---

## NEXT ORDERS (EXECUTE NOW)
1) Implement P1 tasks (Hint Tiles hotspot, Resistance Alert banner, dynamic Next‚ÄëTest, post‚ÄëNGS E2E tests).  
2) Draft ‚ÄúSAE Lift/Gate Policy v1‚Äù (document-only).  
3) Set up GPT‚Äë5 benchmark for Ayesha complete care and capture side‚Äëby‚Äëside outputs.  
4) Keep `/api/efficacy/predict` unchanged until validation is running and policy is approved.

‚Äî Manager Approved ‚úÖ

